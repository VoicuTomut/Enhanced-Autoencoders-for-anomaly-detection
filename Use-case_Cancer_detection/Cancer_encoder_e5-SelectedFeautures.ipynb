{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomut\\anaconda3\\envs\\qhack2022\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\tomut\\anaconda3\\envs\\qhack2022\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from graphs import plot_correlation_matrix\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "#quanutm lib\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "\n",
    "from pennylane.optimize import AdamOptimizer\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path\n",
    "\n",
    "from qencode.initialize import setAB_amplitude, setAux, setEnt\n",
    "from qencode.encoders import e5_patch\n",
    "from qencode.training_circuits import swap_t\n",
    "from qencode.qubits_arrangement import QubitsArrangement\n",
    "\n",
    "from qencode.utils.mnist import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"cancer.csv\", nrows=500)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## malign and benign aee reverted !!!!!!!!!!!!!\n",
    "\n",
    "diagnosis=[]\n",
    "for d in df.diagnosis:\n",
    "    if d==\"M\":\n",
    "        diagnosis.append(1.0)\n",
    "    else:\n",
    "        diagnosis.append(0.0)\n",
    "df[\"diagnosis\"]=diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malign:  305\n",
      "Benign:  195\n"
     ]
    }
   ],
   "source": [
    "print('Malign: ', df['diagnosis'].value_counts()[0])\n",
    "print('Benign: ', df['diagnosis'].value_counts()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       500 non-null    int64  \n",
      " 1   diagnosis                500 non-null    float64\n",
      " 2   radius_mean              500 non-null    float64\n",
      " 3   texture_mean             500 non-null    float64\n",
      " 4   perimeter_mean           500 non-null    float64\n",
      " 5   area_mean                500 non-null    float64\n",
      " 6   smoothness_mean          500 non-null    float64\n",
      " 7   compactness_mean         500 non-null    float64\n",
      " 8   concavity_mean           500 non-null    float64\n",
      " 9   concave points_mean      500 non-null    float64\n",
      " 10  symmetry_mean            500 non-null    float64\n",
      " 11  fractal_dimension_mean   500 non-null    float64\n",
      " 12  radius_se                500 non-null    float64\n",
      " 13  texture_se               500 non-null    float64\n",
      " 14  perimeter_se             500 non-null    float64\n",
      " 15  area_se                  500 non-null    float64\n",
      " 16  smoothness_se            500 non-null    float64\n",
      " 17  compactness_se           500 non-null    float64\n",
      " 18  concavity_se             500 non-null    float64\n",
      " 19  concave points_se        500 non-null    float64\n",
      " 20  symmetry_se              500 non-null    float64\n",
      " 21  fractal_dimension_se     500 non-null    float64\n",
      " 22  radius_worst             500 non-null    float64\n",
      " 23  texture_worst            500 non-null    float64\n",
      " 24  perimeter_worst          500 non-null    float64\n",
      " 25  area_worst               500 non-null    float64\n",
      " 26  smoothness_worst         500 non-null    float64\n",
      " 27  compactness_worst        500 non-null    float64\n",
      " 28  concavity_worst          500 non-null    float64\n",
      " 29  concave points_worst     500 non-null    float64\n",
      " 30  symmetry_worst           500 non-null    float64\n",
      " 31  fractal_dimension_worst  500 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(32), int64(1)\n",
      "memory usage: 129.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.263049e+07</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>14.224206</td>\n",
       "      <td>19.086320</td>\n",
       "      <td>92.606620</td>\n",
       "      <td>662.844800</td>\n",
       "      <td>0.095978</td>\n",
       "      <td>0.103948</td>\n",
       "      <td>0.089941</td>\n",
       "      <td>0.049446</td>\n",
       "      <td>...</td>\n",
       "      <td>25.508500</td>\n",
       "      <td>108.258320</td>\n",
       "      <td>896.003200</td>\n",
       "      <td>0.131972</td>\n",
       "      <td>0.256324</td>\n",
       "      <td>0.276420</td>\n",
       "      <td>0.115980</td>\n",
       "      <td>0.292212</td>\n",
       "      <td>0.083778</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.326933e+08</td>\n",
       "      <td>0.488238</td>\n",
       "      <td>3.476809</td>\n",
       "      <td>4.164842</td>\n",
       "      <td>23.983476</td>\n",
       "      <td>349.357241</td>\n",
       "      <td>0.013666</td>\n",
       "      <td>0.053096</td>\n",
       "      <td>0.080259</td>\n",
       "      <td>0.038875</td>\n",
       "      <td>...</td>\n",
       "      <td>6.063133</td>\n",
       "      <td>33.312706</td>\n",
       "      <td>571.074422</td>\n",
       "      <td>0.022739</td>\n",
       "      <td>0.159147</td>\n",
       "      <td>0.209012</td>\n",
       "      <td>0.065896</td>\n",
       "      <td>0.063366</td>\n",
       "      <td>0.018108</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.062510</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.667040e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.807500</td>\n",
       "      <td>16.070000</td>\n",
       "      <td>75.995000</td>\n",
       "      <td>430.550000</td>\n",
       "      <td>0.085992</td>\n",
       "      <td>0.063622</td>\n",
       "      <td>0.028885</td>\n",
       "      <td>0.020245</td>\n",
       "      <td>...</td>\n",
       "      <td>21.017500</td>\n",
       "      <td>84.567500</td>\n",
       "      <td>522.600000</td>\n",
       "      <td>0.116200</td>\n",
       "      <td>0.145925</td>\n",
       "      <td>0.114475</td>\n",
       "      <td>0.063302</td>\n",
       "      <td>0.251700</td>\n",
       "      <td>0.071270</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.014320e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.435000</td>\n",
       "      <td>18.680000</td>\n",
       "      <td>86.735000</td>\n",
       "      <td>556.150000</td>\n",
       "      <td>0.095825</td>\n",
       "      <td>0.091280</td>\n",
       "      <td>0.064315</td>\n",
       "      <td>0.033870</td>\n",
       "      <td>...</td>\n",
       "      <td>25.240000</td>\n",
       "      <td>97.980000</td>\n",
       "      <td>691.750000</td>\n",
       "      <td>0.131250</td>\n",
       "      <td>0.214850</td>\n",
       "      <td>0.231400</td>\n",
       "      <td>0.100650</td>\n",
       "      <td>0.283100</td>\n",
       "      <td>0.079900</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.910808e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.115000</td>\n",
       "      <td>21.562500</td>\n",
       "      <td>106.225000</td>\n",
       "      <td>800.775000</td>\n",
       "      <td>0.105100</td>\n",
       "      <td>0.130500</td>\n",
       "      <td>0.132150</td>\n",
       "      <td>0.074928</td>\n",
       "      <td>...</td>\n",
       "      <td>29.350000</td>\n",
       "      <td>127.150000</td>\n",
       "      <td>1150.750000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.343525</td>\n",
       "      <td>0.389450</td>\n",
       "      <td>0.166850</td>\n",
       "      <td>0.320050</td>\n",
       "      <td>0.092065</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.144700</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id   diagnosis  radius_mean  texture_mean  perimeter_mean  \\\n",
       "count  5.000000e+02  500.000000   500.000000    500.000000      500.000000   \n",
       "mean   3.263049e+07    0.390000    14.224206     19.086320       92.606620   \n",
       "std    1.326933e+08    0.488238     3.476809      4.164842       23.983476   \n",
       "min    8.670000e+03    0.000000     6.981000      9.710000       43.790000   \n",
       "25%    8.667040e+05    0.000000    11.807500     16.070000       75.995000   \n",
       "50%    9.014320e+05    0.000000    13.435000     18.680000       86.735000   \n",
       "75%    8.910808e+06    1.000000    16.115000     21.562500      106.225000   \n",
       "max    9.113205e+08    1.000000    28.110000     39.280000      188.500000   \n",
       "\n",
       "         area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "count   500.000000       500.000000        500.000000      500.000000   \n",
       "mean    662.844800         0.095978          0.103948        0.089941   \n",
       "std     349.357241         0.013666          0.053096        0.080259   \n",
       "min     143.500000         0.062510          0.019380        0.000000   \n",
       "25%     430.550000         0.085992          0.063622        0.028885   \n",
       "50%     556.150000         0.095825          0.091280        0.064315   \n",
       "75%     800.775000         0.105100          0.130500        0.132150   \n",
       "max    2501.000000         0.144700          0.345400        0.426800   \n",
       "\n",
       "       concave points_mean  ...  texture_worst  perimeter_worst   area_worst  \\\n",
       "count           500.000000  ...     500.000000       500.000000   500.000000   \n",
       "mean              0.049446  ...      25.508500       108.258320   896.003200   \n",
       "std               0.038875  ...       6.063133        33.312706   571.074422   \n",
       "min               0.000000  ...      12.020000        50.410000   185.200000   \n",
       "25%               0.020245  ...      21.017500        84.567500   522.600000   \n",
       "50%               0.033870  ...      25.240000        97.980000   691.750000   \n",
       "75%               0.074928  ...      29.350000       127.150000  1150.750000   \n",
       "max               0.201200  ...      49.540000       251.200000  4254.000000   \n",
       "\n",
       "       smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "count        500.000000         500.000000       500.000000   \n",
       "mean           0.131972           0.256324         0.276420   \n",
       "std            0.022739           0.159147         0.209012   \n",
       "min            0.071170           0.027290         0.000000   \n",
       "25%            0.116200           0.145925         0.114475   \n",
       "50%            0.131250           0.214850         0.231400   \n",
       "75%            0.146000           0.343525         0.389450   \n",
       "max            0.222600           1.058000         1.252000   \n",
       "\n",
       "       concave points_worst  symmetry_worst  fractal_dimension_worst  \\\n",
       "count            500.000000      500.000000               500.000000   \n",
       "mean               0.115980        0.292212                 0.083778   \n",
       "std                0.065896        0.063366                 0.018108   \n",
       "min                0.000000        0.156500                 0.055040   \n",
       "25%                0.063302        0.251700                 0.071270   \n",
       "50%                0.100650        0.283100                 0.079900   \n",
       "75%                0.166850        0.320050                 0.092065   \n",
       "max                0.291000        0.663800                 0.207500   \n",
       "\n",
       "       Unnamed: 32  \n",
       "count          0.0  \n",
       "mean           NaN  \n",
       "std            NaN  \n",
       "min            NaN  \n",
       "25%            NaN  \n",
       "50%            NaN  \n",
       "75%            NaN  \n",
       "max            NaN  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data seams pretty clean  without any nan value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "      <th>over_average</th>\n",
       "      <th>under_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302        1.0        17.99         10.38          122.80     1001.0   \n",
       "1    842517        1.0        20.57         17.77          132.90     1326.0   \n",
       "2  84300903        1.0        19.69         21.25          130.00     1203.0   \n",
       "3  84348301        1.0        11.42         20.38           77.58      386.1   \n",
       "4  84358402        1.0        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0  ...      2019.0            0.1622             0.6656           0.7119   \n",
       "1  ...      1956.0            0.1238             0.1866           0.2416   \n",
       "2  ...      1709.0            0.1444             0.4245           0.4504   \n",
       "3  ...       567.7            0.2098             0.8663           0.6869   \n",
       "4  ...      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  Unnamed: 32  \\\n",
       "0                0.2654          0.4601                  0.11890          NaN   \n",
       "1                0.1860          0.2750                  0.08902          NaN   \n",
       "2                0.2430          0.3613                  0.08758          NaN   \n",
       "3                0.2575          0.6638                  0.17300          NaN   \n",
       "4                0.1625          0.2364                  0.07678          NaN   \n",
       "\n",
       "   over_average  under_average  \n",
       "0            13             17  \n",
       "1             0             30  \n",
       "2             1             29  \n",
       "3            12             18  \n",
       "4             0             30  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## engineering two new features to have 32 feutures that can be encoded om 5 qubits.\n",
    "over_average = []\n",
    "under_average = []\n",
    "\n",
    "mean = {}\n",
    "std = {}\n",
    "for col in df:\n",
    "     if col not in [\"id\",\"diagnosis\" ]:\n",
    "        mean[col]=df[col].mean()\n",
    "        std[col]=df[col].std()\n",
    "\n",
    "for index,row in df.iterrows():\n",
    "    o_average=0\n",
    "    u_average=0\n",
    "    for col in df:\n",
    "        if col not in [\"id\",\"diagnosis\" ]:\n",
    "            if  row[col]> mean[col]+2* std[col]:\n",
    "                o_average = o_average + 1\n",
    "            if  row[col]< mean[col]+2* std[col]:\n",
    "                u_average= u_average + 1\n",
    "                \n",
    "    over_average.append(o_average)\n",
    "    under_average.append(u_average)\n",
    "\n",
    "df[\"over_average\"] = over_average\n",
    "df[\"under_average\"] = under_average\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "      <th>over_average</th>\n",
       "      <th>under_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>866674</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.790</td>\n",
       "      <td>25.12</td>\n",
       "      <td>130.40</td>\n",
       "      <td>1192.0</td>\n",
       "      <td>0.10150</td>\n",
       "      <td>0.15890</td>\n",
       "      <td>0.25450</td>\n",
       "      <td>0.11490</td>\n",
       "      <td>...</td>\n",
       "      <td>1589.0</td>\n",
       "      <td>0.1275</td>\n",
       "      <td>0.3861</td>\n",
       "      <td>0.5673</td>\n",
       "      <td>0.17320</td>\n",
       "      <td>0.3305</td>\n",
       "      <td>0.08465</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>86973701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.950</td>\n",
       "      <td>18.77</td>\n",
       "      <td>97.84</td>\n",
       "      <td>689.5</td>\n",
       "      <td>0.08138</td>\n",
       "      <td>0.11670</td>\n",
       "      <td>0.09050</td>\n",
       "      <td>0.03562</td>\n",
       "      <td>...</td>\n",
       "      <td>809.7</td>\n",
       "      <td>0.0997</td>\n",
       "      <td>0.2521</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.08405</td>\n",
       "      <td>0.2852</td>\n",
       "      <td>0.09218</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>873885</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.280</td>\n",
       "      <td>22.41</td>\n",
       "      <td>98.92</td>\n",
       "      <td>710.6</td>\n",
       "      <td>0.09057</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.05375</td>\n",
       "      <td>0.03263</td>\n",
       "      <td>...</td>\n",
       "      <td>973.1</td>\n",
       "      <td>0.1301</td>\n",
       "      <td>0.3299</td>\n",
       "      <td>0.3630</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.3175</td>\n",
       "      <td>0.09772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>911320501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.600</td>\n",
       "      <td>18.36</td>\n",
       "      <td>73.88</td>\n",
       "      <td>412.7</td>\n",
       "      <td>0.08508</td>\n",
       "      <td>0.05855</td>\n",
       "      <td>0.03367</td>\n",
       "      <td>0.01777</td>\n",
       "      <td>...</td>\n",
       "      <td>495.1</td>\n",
       "      <td>0.1342</td>\n",
       "      <td>0.1808</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.08288</td>\n",
       "      <td>0.3210</td>\n",
       "      <td>0.07863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>894329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.042</td>\n",
       "      <td>18.90</td>\n",
       "      <td>60.07</td>\n",
       "      <td>244.5</td>\n",
       "      <td>0.09968</td>\n",
       "      <td>0.19720</td>\n",
       "      <td>0.19750</td>\n",
       "      <td>0.04908</td>\n",
       "      <td>...</td>\n",
       "      <td>297.1</td>\n",
       "      <td>0.1221</td>\n",
       "      <td>0.3748</td>\n",
       "      <td>0.4609</td>\n",
       "      <td>0.11450</td>\n",
       "      <td>0.3135</td>\n",
       "      <td>0.10550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  diagnosis  radius_mean  texture_mean  perimeter_mean  \\\n",
       "129     866674        1.0       19.790         25.12          130.40   \n",
       "147   86973701        0.0       14.950         18.77           97.84   \n",
       "184     873885        1.0       15.280         22.41           98.92   \n",
       "463  911320501        0.0       11.600         18.36           73.88   \n",
       "318     894329        0.0        9.042         18.90           60.07   \n",
       "\n",
       "     area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "129     1192.0          0.10150           0.15890         0.25450   \n",
       "147      689.5          0.08138           0.11670         0.09050   \n",
       "184      710.6          0.09057           0.10520         0.05375   \n",
       "463      412.7          0.08508           0.05855         0.03367   \n",
       "318      244.5          0.09968           0.19720         0.19750   \n",
       "\n",
       "     concave points_mean  ...  area_worst  smoothness_worst  \\\n",
       "129              0.11490  ...      1589.0            0.1275   \n",
       "147              0.03562  ...       809.7            0.0997   \n",
       "184              0.03263  ...       973.1            0.1301   \n",
       "463              0.01777  ...       495.1            0.1342   \n",
       "318              0.04908  ...       297.1            0.1221   \n",
       "\n",
       "     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "129             0.3861           0.5673               0.17320          0.3305   \n",
       "147             0.2521           0.2500               0.08405          0.2852   \n",
       "184             0.3299           0.3630               0.12260          0.3175   \n",
       "463             0.1808           0.1860               0.08288          0.3210   \n",
       "318             0.3748           0.4609               0.11450          0.3135   \n",
       "\n",
       "     fractal_dimension_worst  Unnamed: 32  over_average  under_average  \n",
       "129                  0.08465          NaN             1             29  \n",
       "147                  0.09218          NaN             1             29  \n",
       "184                  0.09772          NaN             0             30  \n",
       "463                  0.07863          NaN             0             30  \n",
       "318                  0.10550          NaN             4             26  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1)\n",
    "fraud_df = df.loc[df['diagnosis'] == 0]\n",
    "non_fraud_df = df.loc[df['diagnosis'] == 1][:195]\n",
    "normal_distributed_df = pd.concat([fraud_df, non_fraud_df])\n",
    "sub_sample_df = normal_distributed_df.sample(frac=1, random_state=42)\n",
    "\n",
    "sub_sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_sample_corr = sub_sample_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "      <th>over_average</th>\n",
       "      <th>under_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.263049e+07</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.506019</td>\n",
       "      <td>0.485904</td>\n",
       "      <td>0.491282</td>\n",
       "      <td>0.265032</td>\n",
       "      <td>0.663292</td>\n",
       "      <td>0.300949</td>\n",
       "      <td>0.210733</td>\n",
       "      <td>0.245754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.210626</td>\n",
       "      <td>0.592867</td>\n",
       "      <td>0.242273</td>\n",
       "      <td>0.220783</td>\n",
       "      <td>0.398557</td>\n",
       "      <td>0.440211</td>\n",
       "      <td>0.403749</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.326933e+08</td>\n",
       "      <td>0.488238</td>\n",
       "      <td>0.123686</td>\n",
       "      <td>0.106030</td>\n",
       "      <td>0.127233</td>\n",
       "      <td>0.139687</td>\n",
       "      <td>0.094446</td>\n",
       "      <td>0.153722</td>\n",
       "      <td>0.188047</td>\n",
       "      <td>0.193216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134244</td>\n",
       "      <td>0.102153</td>\n",
       "      <td>0.150423</td>\n",
       "      <td>0.166943</td>\n",
       "      <td>0.226448</td>\n",
       "      <td>0.095459</td>\n",
       "      <td>0.087266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.140564</td>\n",
       "      <td>0.093709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.248346</td>\n",
       "      <td>0.247200</td>\n",
       "      <td>0.232308</td>\n",
       "      <td>0.057377</td>\n",
       "      <td>0.431997</td>\n",
       "      <td>0.056109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043535</td>\n",
       "      <td>0.319721</td>\n",
       "      <td>0.025794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235764</td>\n",
       "      <td>0.265253</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.667040e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420046</td>\n",
       "      <td>0.409114</td>\n",
       "      <td>0.403156</td>\n",
       "      <td>0.172151</td>\n",
       "      <td>0.594281</td>\n",
       "      <td>0.184199</td>\n",
       "      <td>0.067678</td>\n",
       "      <td>0.100621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122849</td>\n",
       "      <td>0.522013</td>\n",
       "      <td>0.137925</td>\n",
       "      <td>0.091434</td>\n",
       "      <td>0.217534</td>\n",
       "      <td>0.379180</td>\n",
       "      <td>0.343470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.014320e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.477944</td>\n",
       "      <td>0.475560</td>\n",
       "      <td>0.460133</td>\n",
       "      <td>0.222371</td>\n",
       "      <td>0.662232</td>\n",
       "      <td>0.264273</td>\n",
       "      <td>0.150691</td>\n",
       "      <td>0.168340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162612</td>\n",
       "      <td>0.589623</td>\n",
       "      <td>0.203072</td>\n",
       "      <td>0.184824</td>\n",
       "      <td>0.345876</td>\n",
       "      <td>0.426484</td>\n",
       "      <td>0.385060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.910808e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.573284</td>\n",
       "      <td>0.548943</td>\n",
       "      <td>0.563528</td>\n",
       "      <td>0.320182</td>\n",
       "      <td>0.726330</td>\n",
       "      <td>0.377823</td>\n",
       "      <td>0.309630</td>\n",
       "      <td>0.372403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270510</td>\n",
       "      <td>0.655885</td>\n",
       "      <td>0.324693</td>\n",
       "      <td>0.311062</td>\n",
       "      <td>0.573368</td>\n",
       "      <td>0.482148</td>\n",
       "      <td>0.443687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id   diagnosis  radius_mean  texture_mean  perimeter_mean  \\\n",
       "count  5.000000e+02  500.000000   500.000000    500.000000      500.000000   \n",
       "mean   3.263049e+07    0.390000     0.506019      0.485904        0.491282   \n",
       "std    1.326933e+08    0.488238     0.123686      0.106030        0.127233   \n",
       "min    8.670000e+03    0.000000     0.248346      0.247200        0.232308   \n",
       "25%    8.667040e+05    0.000000     0.420046      0.409114        0.403156   \n",
       "50%    9.014320e+05    0.000000     0.477944      0.475560        0.460133   \n",
       "75%    8.910808e+06    1.000000     0.573284      0.548943        0.563528   \n",
       "max    9.113205e+08    1.000000     1.000000      1.000000        1.000000   \n",
       "\n",
       "        area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "count  500.000000       500.000000        500.000000      500.000000   \n",
       "mean     0.265032         0.663292          0.300949        0.210733   \n",
       "std      0.139687         0.094446          0.153722        0.188047   \n",
       "min      0.057377         0.431997          0.056109        0.000000   \n",
       "25%      0.172151         0.594281          0.184199        0.067678   \n",
       "50%      0.222371         0.662232          0.264273        0.150691   \n",
       "75%      0.320182         0.726330          0.377823        0.309630   \n",
       "max      1.000000         1.000000          1.000000        1.000000   \n",
       "\n",
       "       concave points_mean  ...  area_worst  smoothness_worst  \\\n",
       "count           500.000000  ...  500.000000        500.000000   \n",
       "mean              0.245754  ...    0.210626          0.592867   \n",
       "std               0.193216  ...    0.134244          0.102153   \n",
       "min               0.000000  ...    0.043535          0.319721   \n",
       "25%               0.100621  ...    0.122849          0.522013   \n",
       "50%               0.168340  ...    0.162612          0.589623   \n",
       "75%               0.372403  ...    0.270510          0.655885   \n",
       "max               1.000000  ...    1.000000          1.000000   \n",
       "\n",
       "       compactness_worst  concavity_worst  concave points_worst  \\\n",
       "count         500.000000       500.000000            500.000000   \n",
       "mean            0.242273         0.220783              0.398557   \n",
       "std             0.150423         0.166943              0.226448   \n",
       "min             0.025794         0.000000              0.000000   \n",
       "25%             0.137925         0.091434              0.217534   \n",
       "50%             0.203072         0.184824              0.345876   \n",
       "75%             0.324693         0.311062              0.573368   \n",
       "max             1.000000         1.000000              1.000000   \n",
       "\n",
       "       symmetry_worst  fractal_dimension_worst  Unnamed: 32  over_average  \\\n",
       "count      500.000000               500.000000          0.0    500.000000   \n",
       "mean         0.440211                 0.403749          NaN      0.062500   \n",
       "std          0.095459                 0.087266          NaN      0.140564   \n",
       "min          0.235764                 0.265253          NaN      0.000000   \n",
       "25%          0.379180                 0.343470          NaN      0.000000   \n",
       "50%          0.426484                 0.385060          NaN      0.000000   \n",
       "75%          0.482148                 0.443687          NaN      0.050000   \n",
       "max          1.000000                 1.000000          NaN      1.000000   \n",
       "\n",
       "       under_average  \n",
       "count     500.000000  \n",
       "mean        0.958333  \n",
       "std         0.093709  \n",
       "min         0.333333  \n",
       "25%         0.966667  \n",
       "50%         1.000000  \n",
       "75%         1.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 35 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in df:\n",
    "    if col not in [\"id\",\"diagnosis\" ]:\n",
    "        df[col]=df[col]/df[col].max()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['concave points_worst', 'under_average', 'perimeter_worst', 'smoothness_se', 'radius_worst', 'symmetry_se', 'concave points_mean', 'texture_se'], [0.7943760186139814, -0.3566134023342226, 0.7802775126194338, -0.029789950321574808, 0.7740326821281197, -0.00018908153723505182, 0.7727922399366886, 0.0033709744170597627])\n"
     ]
    }
   ],
   "source": [
    "def find_strongest_correlations(dataframe, qubits):\n",
    "        \n",
    "    class_correlations = dataframe.loc['diagnosis', :]\n",
    "    class_correlations = class_correlations.drop(index = 'diagnosis')\n",
    "    \n",
    "    feature_list = list(class_correlations.index)\n",
    "    correlation_list = [class_correlations[x] for x in feature_list]\n",
    "    \n",
    "    features = []\n",
    "    correlations = []\n",
    "    \n",
    "    for i in range(int(qubits/2)):\n",
    "        \n",
    "        \n",
    "        correlations.append(max(correlation_list))\n",
    "        features.append(feature_list[correlation_list.index(max(correlation_list))])\n",
    "        \n",
    "        del feature_list[correlation_list.index(max(correlation_list))]\n",
    "        del correlation_list[correlation_list.index(max(correlation_list))]                        \n",
    "                                      \n",
    "        correlations.append(min(correlation_list))\n",
    "        features.append(feature_list[correlation_list.index(min(correlation_list))])\n",
    "        \n",
    "        del feature_list[correlation_list.index(min(correlation_list))]\n",
    "        del correlation_list[correlation_list.index(min(correlation_list))] \n",
    "    \n",
    "    return features, correlations\n",
    "    \n",
    "    \n",
    "print(find_strongest_correlations(sub_sample_corr, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list, correlations = find_strongest_correlations(sub_sample_corr, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>under_average</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>texture_se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.297595</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.357126</td>\n",
       "      <td>0.155927</td>\n",
       "      <td>0.391509</td>\n",
       "      <td>0.175554</td>\n",
       "      <td>0.112922</td>\n",
       "      <td>0.209826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.396907</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.367038</td>\n",
       "      <td>0.215837</td>\n",
       "      <td>0.367370</td>\n",
       "      <td>0.237112</td>\n",
       "      <td>0.188419</td>\n",
       "      <td>0.284545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>0.189313</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.329180</td>\n",
       "      <td>0.213685</td>\n",
       "      <td>0.351831</td>\n",
       "      <td>0.239899</td>\n",
       "      <td>0.074652</td>\n",
       "      <td>0.216786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>0.257216</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333161</td>\n",
       "      <td>0.210183</td>\n",
       "      <td>0.354051</td>\n",
       "      <td>0.233566</td>\n",
       "      <td>0.069781</td>\n",
       "      <td>0.331832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.499313</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.387460</td>\n",
       "      <td>0.174815</td>\n",
       "      <td>0.410655</td>\n",
       "      <td>0.166561</td>\n",
       "      <td>0.267445</td>\n",
       "      <td>0.272671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     concave points_worst  under_average  perimeter_worst  smoothness_se  \\\n",
       "74               0.297595            1.0         0.357126       0.155927   \n",
       "286              0.396907            1.0         0.367038       0.215837   \n",
       "304              0.189313            1.0         0.329180       0.213685   \n",
       "427              0.257216            1.0         0.333161       0.210183   \n",
       "396              0.499313            1.0         0.387460       0.174815   \n",
       "\n",
       "     radius_worst  symmetry_se  concave points_mean  texture_se  \n",
       "74       0.391509     0.175554             0.112922    0.209826  \n",
       "286      0.367370     0.237112             0.188419    0.284545  \n",
       "304      0.351831     0.239899             0.074652    0.216786  \n",
       "427      0.354051     0.233566             0.069781    0.331832  \n",
       "396      0.410655     0.166561             0.267445    0.272671  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malign=df[df[\"diagnosis\"]==0][feature_list]\n",
    "malign.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>under_average</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>texture_se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.698969</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.518710</td>\n",
       "      <td>0.279441</td>\n",
       "      <td>0.560211</td>\n",
       "      <td>0.189360</td>\n",
       "      <td>0.471123</td>\n",
       "      <td>0.219447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>0.537457</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.576831</td>\n",
       "      <td>0.340829</td>\n",
       "      <td>0.600721</td>\n",
       "      <td>0.276884</td>\n",
       "      <td>0.441650</td>\n",
       "      <td>0.368884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.500344</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.537022</td>\n",
       "      <td>0.180758</td>\n",
       "      <td>0.555216</td>\n",
       "      <td>0.243825</td>\n",
       "      <td>0.395278</td>\n",
       "      <td>0.168373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0.595189</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.505175</td>\n",
       "      <td>0.146579</td>\n",
       "      <td>0.514706</td>\n",
       "      <td>0.175807</td>\n",
       "      <td>0.449901</td>\n",
       "      <td>0.187779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.574914</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.444268</td>\n",
       "      <td>0.443302</td>\n",
       "      <td>0.454772</td>\n",
       "      <td>0.340595</td>\n",
       "      <td>0.324354</td>\n",
       "      <td>0.432344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     concave points_worst  under_average  perimeter_worst  smoothness_se  \\\n",
       "118              0.698969       0.900000         0.518710       0.279441   \n",
       "244              0.537457       1.000000         0.576831       0.340829   \n",
       "29               0.500344       1.000000         0.537022       0.180758   \n",
       "283              0.595189       1.000000         0.505175       0.146579   \n",
       "196              0.574914       0.966667         0.444268       0.443302   \n",
       "\n",
       "     radius_worst  symmetry_se  concave points_mean  texture_se  \n",
       "118      0.560211     0.189360             0.471123    0.219447  \n",
       "244      0.600721     0.276884             0.441650    0.368884  \n",
       "29       0.555216     0.243825             0.395278    0.168373  \n",
       "283      0.514706     0.175807             0.449901    0.187779  \n",
       "196      0.454772     0.340595             0.324354    0.432344  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benign=df[df[\"diagnosis\"]!=0][feature_list]\n",
    "benign.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2975945 , 1.        , 0.3571258 , ..., 0.17555415, 0.11292247,\n",
       "        0.209826  ],\n",
       "       [0.39690722, 1.        , 0.36703822, ..., 0.2371121 , 0.18841948,\n",
       "        0.28454452],\n",
       "       [0.18931271, 1.        , 0.32917994, ..., 0.23989867, 0.07465209,\n",
       "        0.21678608],\n",
       "       ...,\n",
       "       [0.24010309, 1.        , 0.37324841, ..., 0.16352122, 0.07321074,\n",
       "        0.12536336],\n",
       "       [0.19247423, 1.        , 0.36476911, ..., 0.33806206, 0.09279324,\n",
       "        0.36806551],\n",
       "       [0.44054983, 1.        , 0.39410828, ..., 0.20785307, 0.16819085,\n",
       "        0.27697032]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data=malign.to_numpy()\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qubits: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n"
     ]
    }
   ],
   "source": [
    "shots = 2500\n",
    "nr_trash=2\n",
    "nr_latent=2\n",
    "nr_ent=0\n",
    "\n",
    "trash_qubits1=[i for i in range(nr_trash)]\n",
    "latent_qubits1=[i for i in range(nr_trash,nr_trash+nr_latent)]\n",
    "trash_qubits2=[i for i in range(nr_trash+nr_latent,2*nr_trash+nr_latent)]\n",
    "latent_qubits2=[i for i in range(2*nr_trash+nr_latent,2*(nr_trash+nr_latent))]\n",
    "aux_qubits=[i for i in range(2*(nr_trash+nr_latent),2*(nr_trash+nr_latent)+2*nr_trash)]\n",
    "swap_qubit=[2*(nr_trash+nr_latent)+2*nr_trash]\n",
    "\n",
    "qubits=[*trash_qubits1, *latent_qubits1, *trash_qubits2, *latent_qubits2, *aux_qubits, *swap_qubit]\n",
    "\n",
    "\n",
    "print(\"Qubits:\", qubits)\n",
    "\n",
    "#set up the device \n",
    "dev = qml.device(\"default.qubit\", wires=qubits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev)\n",
    "def training_circuit_example(init_params, encoder_params, reinit_state, x):\n",
    "    # Initialization\n",
    "    \n",
    "    \n",
    "    qml.templates.embeddings.AmplitudeEmbedding(\n",
    "        init_params,\n",
    "        wires=[*trash_qubits1, *latent_qubits1],\n",
    "        normalize=True,\n",
    "        pad_with=0.0j,\n",
    "    )\n",
    "  \n",
    "    \n",
    "    qml.templates.embeddings.AngleEmbedding(\n",
    "        init_params[:4], wires=[*trash_qubits2, *latent_qubits2], rotation='X')\n",
    "    qml.templates.embeddings.AngleEmbedding(\n",
    "        init_params[:4], wires=[*trash_qubits2, *latent_qubits2], rotation='Z')\n",
    "    \n",
    "    qml.MottonenStatePreparation(reinit_state, wires=aux_qubits)\n",
    "\n",
    "    #encoder \n",
    "    e5_patch(*encoder_params[0],*encoder_params[1], [*trash_qubits1, *latent_qubits1], [*latent_qubits2, *trash_qubits2])\n",
    "\n",
    "    #swap test \n",
    "    trashes=[*trash_qubits1,*trash_qubits2]\n",
    "    qml.Hadamard(wires=swap_qubit[0])\n",
    "    for i in range(len(trashes)):\n",
    "        qml.CSWAP(wires=[swap_qubit[0], aux_qubits[i], trashes[i]])\n",
    "    qml.Hadamard(wires=swap_qubit[0])\n",
    "\n",
    "    return [qml.probs(i) for i in swap_qubit]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "learning_rate = 0.0003\n",
    "batch_size = 5\n",
    "num_samples = 0.8 # proportion of the data used for training \n",
    "\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "opt = AdamOptimizer(learning_rate, beta1=beta1, beta2=beta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fid_func(output):\n",
    "    # Implemented as the Fidelity Loss\n",
    "    # output[0] because we take the probability that the state after the \n",
    "    # SWAP test is ket(0), like the reference state\n",
    "    fidelity_loss = 1 / output[0]\n",
    "    return fidelity_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(encoder_params, X):\n",
    "    reinit_state = [0 for i in range(2 ** len(aux_qubits))]\n",
    "    reinit_state[0] = 1.0\n",
    "    loss = 0.0\n",
    "    for x in X:\n",
    "        output = training_circuit_example(init_params=x[0], encoder_params=encoder_params, reinit_state=reinit_state,x=x[0][1])[0]\n",
    "        f = fid_func(output)\n",
    "        loss = loss + f\n",
    "    return loss / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fidelity(encoder_params, X):\n",
    "    reinit_state = [0 for _ in range(2 ** len(aux_qubits))]\n",
    "    reinit_state[0] = 1.0\n",
    "    loss = 0.0\n",
    "    for x in X:\n",
    "        output =  training_circuit_example(init_params=x[0], encoder_params=encoder_params, reinit_state=reinit_state,x=x[0][1])[0]\n",
    "       \n",
    "        f = output[0]\n",
    "        loss = loss + f\n",
    "    return loss / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_batches(X, batch_size):\n",
    "    \n",
    "    random.shuffle(X)\n",
    "\n",
    "    batch_list = []\n",
    "    batch = []\n",
    "    for x in X:\n",
    "        if len(batch) < batch_size:\n",
    "            batch.append(x)\n",
    "\n",
    "        else:\n",
    "            batch_list.append(batch)\n",
    "            batch = []\n",
    "    if len(batch) != 0:\n",
    "        batch_list.append(batch)\n",
    "    return batch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomut\\AppData\\Local\\Temp/ipykernel_19892/3998820717.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_new.cpp:201.)\n",
      "  training_data = [ torch.tensor([input_data[i]]) for i in range(int(len(input_data)*num_samples))]\n"
     ]
    }
   ],
   "source": [
    "training_data = [ torch.tensor([input_data[i]]) for i in range(int(len(input_data)*num_samples))]\n",
    "test_data = [torch.tensor([input_data[i]]) for i in range(int(len(input_data)*num_samples),len(input_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches=iterate_batches(training_data, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training = training_data\n",
    "X_tes = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_encod_qubits = nr_trash + nr_latent\n",
    "nr_par_encoder =  15 * int(nr_encod_qubits*(nr_encod_qubits-1)/2)\n",
    "encoder_params = [np.random.uniform(size=(1, nr_par_encoder), requires_grad=True),np.random.uniform(size=(1, nr_par_encoder), requires_grad=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.99775073, 0.26644986, 0.56735113, 0.74680767, 0.68158349,\n",
       "          0.02910598, 0.8442973 , 0.1653875 , 0.03606143, 0.15015058,\n",
       "          0.99620722, 0.05033939, 0.02234858, 0.6440611 , 0.83408751,\n",
       "          0.34531755, 0.09259829, 0.38760431, 0.67229806, 0.06406358,\n",
       "          0.73600799, 0.42172811, 0.01707076, 0.94454366, 0.20368653,\n",
       "          0.62107646, 0.71294124, 0.40444618, 0.146103  , 0.98194342,\n",
       "          0.46114073, 0.72417976, 0.16351217, 0.07446152, 0.54769391,\n",
       "          0.09176107, 0.96841764, 0.02834377, 0.07627163, 0.25943585,\n",
       "          0.12660409, 0.09573493, 0.28977203, 0.75756616, 0.21471882,\n",
       "          0.78483644, 0.40080091, 0.91111941, 0.00440659, 0.62722022,\n",
       "          0.04742633, 0.32574007, 0.68302586, 0.85911413, 0.03455518,\n",
       "          0.20334273, 0.11807058, 0.86079946, 0.78565945, 0.68110714,\n",
       "          0.14926856, 0.81486876, 0.322483  , 0.38386581, 0.39228113,\n",
       "          0.56673683, 0.00493707, 0.03776855, 0.37123657, 0.48397906,\n",
       "          0.18025015, 0.26729139, 0.6371104 , 0.10163946, 0.06882223,\n",
       "          0.61209014, 0.40320179, 0.85970526, 0.4980242 , 0.10664251,\n",
       "          0.48234141, 0.6896355 , 0.04574457, 0.048629  , 0.30647434,\n",
       "          0.14756775, 0.71424748, 0.9123936 , 0.7764761 , 0.14268316]], requires_grad=True),\n",
       " tensor([[7.39638651e-01, 9.80139957e-01, 1.12355651e-02, 2.09618297e-01,\n",
       "          3.69202848e-02, 8.82502697e-02, 3.58921174e-01, 7.33803153e-01,\n",
       "          7.87274483e-01, 6.82082850e-01, 3.30709254e-01, 1.15780759e-01,\n",
       "          3.46377746e-01, 6.02829416e-01, 6.91241666e-01, 9.09187235e-01,\n",
       "          1.71860308e-01, 1.25897531e-01, 5.33072282e-01, 1.04329805e-01,\n",
       "          5.71396131e-01, 7.04692374e-01, 3.38994189e-01, 7.78687740e-01,\n",
       "          7.68334764e-01, 2.59032563e-01, 2.43520861e-01, 8.67260069e-01,\n",
       "          8.38590447e-01, 7.87314060e-01, 5.41303934e-01, 1.80657873e-01,\n",
       "          7.58373314e-01, 7.83538966e-01, 9.07527009e-01, 8.18583510e-01,\n",
       "          3.94151529e-01, 4.59500502e-01, 1.34994140e-01, 1.55872058e-01,\n",
       "          3.52255290e-02, 6.46724820e-01, 8.48025471e-01, 1.71179301e-01,\n",
       "          1.09518058e-01, 2.59324754e-01, 6.43742941e-01, 8.06416063e-01,\n",
       "          6.76256546e-01, 3.85324910e-01, 9.14792187e-01, 2.32666716e-01,\n",
       "          1.64522961e-01, 2.76652025e-01, 5.70332766e-02, 4.94061920e-01,\n",
       "          7.04265553e-01, 4.96156145e-01, 4.43710454e-01, 6.96496966e-01,\n",
       "          1.12630245e-01, 8.20637373e-01, 4.72846722e-01, 7.96705023e-02,\n",
       "          2.28949132e-01, 7.57685350e-01, 1.12833260e-01, 3.50954856e-01,\n",
       "          3.14212345e-01, 7.93973434e-01, 6.49616721e-04, 7.66490957e-01,\n",
       "          9.00315452e-02, 2.06484261e-01, 2.90198517e-01, 7.16452087e-01,\n",
       "          4.80851307e-01, 9.08102752e-01, 1.47112176e-01, 8.08455623e-01,\n",
       "          2.30350924e-01, 5.05886246e-01, 8.06123057e-01, 1.98796019e-01,\n",
       "          2.94964213e-01, 6.95613346e-01, 4.45676074e-01, 4.35564580e-01,\n",
       "          4.74361776e-01, 5.23731148e-01]], requires_grad=True)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.99775073, 0.26644986, 0.56735113, 0.74680767, 0.68158349,\n",
       "         0.02910598, 0.8442973 , 0.1653875 , 0.03606143, 0.15015058,\n",
       "         0.99620722, 0.05033939, 0.02234858, 0.6440611 , 0.83408751,\n",
       "         0.34531755, 0.09259829, 0.38760431, 0.67229806, 0.06406358,\n",
       "         0.73600799, 0.42172811, 0.01707076, 0.94454366, 0.20368653,\n",
       "         0.62107646, 0.71294124, 0.40444618, 0.146103  , 0.98194342,\n",
       "         0.46114073, 0.72417976, 0.16351217, 0.07446152, 0.54769391,\n",
       "         0.09176107, 0.96841764, 0.02834377, 0.07627163, 0.25943585,\n",
       "         0.12660409, 0.09573493, 0.28977203, 0.75756616, 0.21471882,\n",
       "         0.78483644, 0.40080091, 0.91111941, 0.00440659, 0.62722022,\n",
       "         0.04742633, 0.32574007, 0.68302586, 0.85911413, 0.03455518,\n",
       "         0.20334273, 0.11807058, 0.86079946, 0.78565945, 0.68110714,\n",
       "         0.14926856, 0.81486876, 0.322483  , 0.38386581, 0.39228113,\n",
       "         0.56673683, 0.00493707, 0.03776855, 0.37123657, 0.48397906,\n",
       "         0.18025015, 0.26729139, 0.6371104 , 0.10163946, 0.06882223,\n",
       "         0.61209014, 0.40320179, 0.85970526, 0.4980242 , 0.10664251,\n",
       "         0.48234141, 0.6896355 , 0.04574457, 0.048629  , 0.30647434,\n",
       "         0.14756775, 0.71424748, 0.9123936 , 0.7764761 , 0.14268316]], requires_grad=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_params[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_benign = benign.to_numpy()\n",
    "benign_data = [ torch.tensor([np_benign[i]]) for i in range(len(benign.to_numpy()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomut\\anaconda3\\envs\\qhack2022\\lib\\site-packages\\pennylane\\_grad.py:95: UserWarning: Starting with PennyLane v0.21.0, when using Autograd, inputs have to explicitly specify requires_grad=True (or the argnum argument must be passed) in order for trainable parameters to be identified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tomut\\anaconda3\\envs\\qhack2022\\lib\\site-packages\\pennylane\\math\\multi_dispatch.py:63: UserWarning: Contains tensors of types {'autograd', 'torch'}; dispatch will prioritize TensorFlow and PyTorch over autograd. Consider replacing Autograd with vanilla NumPy.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 | Loss:1.5924481081342123 | Fidelity:0.628531595103354\n",
      "Test-Epoch:0 | Loss:1.5969636386672466 | Fidelity:0.6266007728067973\n",
      "benign fid:0.6440651708746328\n",
      "Epoch:5 | Loss:1.2474109141947387 | Fidelity:0.801954668118029\n",
      "Test-Epoch:5 | Loss:1.2472541793495393 | Fidelity:0.8020110613549724\n",
      "benign fid:0.7675959458717292\n",
      "Epoch:10 | Loss:1.1741862017831595 | Fidelity:0.8518169555998609\n",
      "Test-Epoch:10 | Loss:1.1723584513558776 | Fidelity:0.8530857171908474\n",
      "benign fid:0.7992714953689056\n",
      "Epoch:15 | Loss:1.1578175647624431 | Fidelity:0.8638457078471741\n",
      "Test-Epoch:15 | Loss:1.1555135588939198 | Fidelity:0.8654861266152447\n",
      "benign fid:0.8063462016360717\n",
      "Epoch:20 | Loss:1.154087916554797 | Fidelity:0.8666428264598782\n",
      "Test-Epoch:20 | Loss:1.1516737406869726 | Fidelity:0.8683673733140377\n",
      "benign fid:0.8073167497713094\n",
      "Epoch:25 | Loss:1.152688899066236 | Fidelity:0.8677002369870335\n",
      "Test-Epoch:25 | Loss:1.1502702833777136 | Fidelity:0.8694254354148965\n",
      "benign fid:0.8074924608380878\n",
      "Epoch:30 | Loss:1.151875599981222 | Fidelity:0.8683165295094973\n",
      "Test-Epoch:30 | Loss:1.1494834767892 | Fidelity:0.8700215371619431\n",
      "benign fid:0.8075377473881227\n",
      "Epoch:35 | Loss:1.1513163920156129 | Fidelity:0.8687386964304793\n",
      "Test-Epoch:35 | Loss:1.1489748826398514 | Fidelity:0.8704065048040819\n",
      "benign fid:0.808222329991925\n",
      "Epoch:40 | Loss:1.1509330227041006 | Fidelity:0.869027579668456\n",
      "Test-Epoch:40 | Loss:1.1486475363470428 | Fidelity:0.8706551838390011\n",
      "benign fid:0.8086461184855972\n",
      "Epoch:45 | Loss:1.1506517414619144 | Fidelity:0.8692365075454491\n",
      "Test-Epoch:45 | Loss:1.1484251857207999 | Fidelity:0.8708233169456616\n",
      "benign fid:0.8096950197473984\n",
      "Epoch:50 | Loss:1.1504301265047692 | Fidelity:0.8694061683639017\n",
      "Test-Epoch:50 | Loss:1.148214165857987 | Fidelity:0.8709829392399752\n",
      "benign fid:0.8095029413619867\n",
      "Epoch:55 | Loss:1.1502338347584236 | Fidelity:0.8695511329951799\n",
      "Test-Epoch:55 | Loss:1.148078576937613 | Fidelity:0.8710867205714793\n",
      "benign fid:0.8099851504842442\n",
      "Epoch:60 | Loss:1.1500521535939023 | Fidelity:0.8696868637055317\n",
      "Test-Epoch:60 | Loss:1.1479502059924556 | Fidelity:0.8711823459704557\n",
      "benign fid:0.8103785109785133\n",
      "Epoch:65 | Loss:1.149865251358 | Fidelity:0.8698238144156892\n",
      "Test-Epoch:65 | Loss:1.14783268370524 | Fidelity:0.8712710461689211\n",
      "benign fid:0.811011962918409\n",
      "Epoch:70 | Loss:1.1497153827843445 | Fidelity:0.8699365645328694\n",
      "Test-Epoch:70 | Loss:1.1477369135758182 | Fidelity:0.8713459637835973\n",
      "benign fid:0.8108190992924625\n",
      "Epoch:75 | Loss:1.1494846014463043 | Fidelity:0.8701062089001586\n",
      "Test-Epoch:75 | Loss:1.1475443895514228 | Fidelity:0.8714891745607158\n",
      "benign fid:0.811762578483332\n",
      "Epoch:80 | Loss:1.149341008883775 | Fidelity:0.8702140885680655\n",
      "Test-Epoch:80 | Loss:1.1474148476981623 | Fidelity:0.8715899508957897\n",
      "benign fid:0.8116915333672087\n",
      "Epoch:85 | Loss:1.1491100079854093 | Fidelity:0.8703827791227368\n",
      "Test-Epoch:85 | Loss:1.1471934050676968 | Fidelity:0.871753791531734\n",
      "benign fid:0.8131286730987368\n",
      "Epoch:90 | Loss:1.1488958916615435 | Fidelity:0.8705403239128472\n",
      "Test-Epoch:90 | Loss:1.1470820766913958 | Fidelity:0.8718367305370436\n",
      "benign fid:0.8136840904717768\n",
      "Epoch:95 | Loss:1.1486841678490973 | Fidelity:0.8706972698837189\n",
      "Test-Epoch:95 | Loss:1.1469561165872557 | Fidelity:0.8719327631861444\n",
      "benign fid:0.8142016062350363\n",
      "Epoch:100 | Loss:1.1484812211444353 | Fidelity:0.8708463728737921\n",
      "Test-Epoch:100 | Loss:1.146737545891251 | Fidelity:0.8720973919051601\n",
      "benign fid:0.8153058057435679\n",
      "Epoch:105 | Loss:1.148267491831249 | Fidelity:0.8710040510062821\n",
      "Test-Epoch:105 | Loss:1.1466313819031018 | Fidelity:0.872176962714668\n",
      "benign fid:0.8158608994540517\n",
      "Epoch:110 | Loss:1.148071387896421 | Fidelity:0.871148437218022\n",
      "Test-Epoch:110 | Loss:1.1464548393187544 | Fidelity:0.8723101961504104\n",
      "benign fid:0.8168623391397662\n",
      "Epoch:115 | Loss:1.1478793844141013 | Fidelity:0.8712870564813798\n",
      "Test-Epoch:115 | Loss:1.1463683259829147 | Fidelity:0.8723742263503519\n",
      "benign fid:0.8181333560635518\n",
      "Epoch:120 | Loss:1.1477004715071226 | Fidelity:0.8714187291862129\n",
      "Test-Epoch:120 | Loss:1.1462274821302338 | Fidelity:0.8724796528095164\n",
      "benign fid:0.8187739449613893\n",
      "Epoch:125 | Loss:1.14751809140418 | Fidelity:0.8715571090786064\n",
      "Test-Epoch:125 | Loss:1.145966648703193 | Fidelity:0.8726798283745304\n",
      "benign fid:0.8183987491429764\n",
      "Epoch:130 | Loss:1.1473089329634405 | Fidelity:0.8717115928926544\n",
      "Test-Epoch:130 | Loss:1.1458336527371853 | Fidelity:0.8727798470117648\n",
      "benign fid:0.8191437543937076\n",
      "Epoch:135 | Loss:1.1471210918062007 | Fidelity:0.8718494109797275\n",
      "Test-Epoch:135 | Loss:1.1456762009653845 | Fidelity:0.8728997174958495\n",
      "benign fid:0.8200096754382314\n",
      "Epoch:140 | Loss:1.1469366373293999 | Fidelity:0.8719862609884685\n",
      "Test-Epoch:140 | Loss:1.1455141377749791 | Fidelity:0.8730221580581687\n",
      "benign fid:0.8206695756602405\n",
      "Epoch:145 | Loss:1.146786343114717 | Fidelity:0.8720975230411226\n",
      "Test-Epoch:145 | Loss:1.1454111595038634 | Fidelity:0.8731019839623437\n",
      "benign fid:0.821450468789764\n",
      "Epoch:150 | Loss:1.1466028656608396 | Fidelity:0.872233361853954\n",
      "Test-Epoch:150 | Loss:1.1451664573853955 | Fidelity:0.873285311775885\n",
      "benign fid:0.8222116048131115\n",
      "Epoch:155 | Loss:1.1464309684978296 | Fidelity:0.8723619290873751\n",
      "Test-Epoch:155 | Loss:1.1450986838010089 | Fidelity:0.8733365762447568\n",
      "benign fid:0.8229544701467137\n",
      "Epoch:160 | Loss:1.1462836227430055 | Fidelity:0.8724681147735627\n",
      "Test-Epoch:160 | Loss:1.14497596199246 | Fidelity:0.8734281476481663\n",
      "benign fid:0.8243834830731516\n",
      "Epoch:165 | Loss:1.1461163114753457 | Fidelity:0.8725978394479877\n",
      "Test-Epoch:165 | Loss:1.144807497930209 | Fidelity:0.8735581395329168\n",
      "benign fid:0.823980564850451\n",
      "Epoch:170 | Loss:1.1459953956188575 | Fidelity:0.8726879814392358\n",
      "Test-Epoch:170 | Loss:1.1446410758553414 | Fidelity:0.8736834522846031\n",
      "benign fid:0.8244895464915197\n",
      "Epoch:175 | Loss:1.1457937705201897 | Fidelity:0.8728388797431327\n",
      "Test-Epoch:175 | Loss:1.14450218318439 | Fidelity:0.8737901765146637\n",
      "benign fid:0.8254157275599029\n",
      "Epoch:180 | Loss:1.1456589347842832 | Fidelity:0.872940843878642\n",
      "Test-Epoch:180 | Loss:1.1443991832465203 | Fidelity:0.8738689449430728\n",
      "benign fid:0.8260566138616298\n",
      "Epoch:185 | Loss:1.1455007447781982 | Fidelity:0.873060672500881\n",
      "Test-Epoch:185 | Loss:1.1442961058654613 | Fidelity:0.8739465884695811\n",
      "benign fid:0.8264873284540271\n",
      "Epoch:190 | Loss:1.1453660271757442 | Fidelity:0.8731638697672903\n",
      "Test-Epoch:190 | Loss:1.1441741345841785 | Fidelity:0.8740415257490065\n",
      "benign fid:0.8267944449316669\n",
      "Epoch:195 | Loss:1.1452333391933314 | Fidelity:0.8732619764798569\n",
      "Test-Epoch:195 | Loss:1.1440737567983472 | Fidelity:0.8741189647376773\n",
      "benign fid:0.8279143028894345\n",
      "Epoch:200 | Loss:1.1450906188219374 | Fidelity:0.8733687269783094\n",
      "Test-Epoch:200 | Loss:1.1440076467732059 | Fidelity:0.8741654336443957\n",
      "benign fid:0.8285483836505884\n",
      "Epoch:205 | Loss:1.14490975320579 | Fidelity:0.873507269657703\n",
      "Test-Epoch:205 | Loss:1.1438371773098623 | Fidelity:0.874298914267718\n",
      "benign fid:0.8289514267046144\n",
      "Epoch:210 | Loss:1.144768328309551 | Fidelity:0.8736147869340547\n",
      "Test-Epoch:210 | Loss:1.1437266369135444 | Fidelity:0.8743829116854279\n",
      "benign fid:0.8293918448966208\n",
      "Epoch:215 | Loss:1.1446398152870336 | Fidelity:0.8737115856342744\n",
      "Test-Epoch:215 | Loss:1.1436010321427366 | Fidelity:0.8744782552768497\n",
      "benign fid:0.8301894513099211\n",
      "Epoch:220 | Loss:1.1444949407134186 | Fidelity:0.8738199240865557\n",
      "Test-Epoch:220 | Loss:1.1435550220934274 | Fidelity:0.8745131084286373\n",
      "benign fid:0.8312831853126931\n",
      "Epoch:225 | Loss:1.144343424527345 | Fidelity:0.8739371842071347\n",
      "Test-Epoch:225 | Loss:1.143387758015556 | Fidelity:0.8746411282176972\n",
      "benign fid:0.8311708789786199\n",
      "Epoch:230 | Loss:1.1441963618351378 | Fidelity:0.8740489200529149\n",
      "Test-Epoch:230 | Loss:1.1433144752154007 | Fidelity:0.8746979554261624\n",
      "benign fid:0.8320353158492234\n",
      "Epoch:235 | Loss:1.144088218211218 | Fidelity:0.8741304775216445\n",
      "Test-Epoch:235 | Loss:1.1432627839006193 | Fidelity:0.8747362923201608\n",
      "benign fid:0.8326535049853306\n",
      "Epoch:240 | Loss:1.1439677284209862 | Fidelity:0.8742250328382923\n",
      "Test-Epoch:240 | Loss:1.1430958654555115 | Fidelity:0.874864709063196\n",
      "benign fid:0.8323613469550607\n",
      "Epoch:245 | Loss:1.143831850846769 | Fidelity:0.8743261409979624\n",
      "Test-Epoch:245 | Loss:1.1430187415743946 | Fidelity:0.8749230833861117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benign fid:0.8336969873723499\n",
      "Epoch:250 | Loss:1.1436765458928495 | Fidelity:0.8744449370030933\n",
      "Test-Epoch:250 | Loss:1.1428683023466615 | Fidelity:0.8750394589571711\n",
      "benign fid:0.834141781826762\n",
      "Epoch:255 | Loss:1.1435569181332121 | Fidelity:0.8745376497822472\n",
      "Test-Epoch:255 | Loss:1.1427830981927516 | Fidelity:0.8751051996851311\n",
      "benign fid:0.834508240273729\n",
      "Epoch:260 | Loss:1.1434578209806017 | Fidelity:0.874610654414877\n",
      "Test-Epoch:260 | Loss:1.1427248489261208 | Fidelity:0.8751476961445432\n",
      "benign fid:0.8355888752317149\n",
      "Epoch:265 | Loss:1.1433211020712277 | Fidelity:0.8747158899458309\n",
      "Test-Epoch:265 | Loss:1.142576847145946 | Fidelity:0.8752625930116688\n",
      "benign fid:0.8359585945697988\n",
      "Epoch:270 | Loss:1.1432251102876467 | Fidelity:0.8747880094230649\n",
      "Test-Epoch:270 | Loss:1.1425703338877533 | Fidelity:0.8752665741510205\n",
      "benign fid:0.837033849592604\n",
      "Epoch:275 | Loss:1.1431135298644584 | Fidelity:0.8748771867802179\n",
      "Test-Epoch:275 | Loss:1.142411421817058 | Fidelity:0.8753910462617956\n",
      "benign fid:0.8364339020890368\n",
      "Epoch:280 | Loss:1.1430039492776747 | Fidelity:0.8749584410895032\n",
      "Test-Epoch:280 | Loss:1.1423541194940254 | Fidelity:0.875432611423918\n",
      "benign fid:0.8376310613751817\n",
      "Epoch:285 | Loss:1.1430125590974245 | Fidelity:0.8749530172257873\n",
      "Test-Epoch:285 | Loss:1.1423132911483627 | Fidelity:0.8754680415882845\n",
      "benign fid:0.838024798002115\n",
      "Epoch:290 | Loss:1.1427749893986874 | Fidelity:0.8751324317239766\n",
      "Test-Epoch:290 | Loss:1.1421684370861396 | Fidelity:0.8755759311293686\n",
      "benign fid:0.8392985488076345\n",
      "Epoch:295 | Loss:1.1426658796986158 | Fidelity:0.8752177322876948\n",
      "Test-Epoch:295 | Loss:1.1420928014810725 | Fidelity:0.8756350784749415\n",
      "benign fid:0.8395275344517603\n",
      "Epoch:300 | Loss:1.1425765574237892 | Fidelity:0.8752846708673314\n",
      "Test-Epoch:300 | Loss:1.1420330356391035 | Fidelity:0.875680147995754\n",
      "benign fid:0.8404136327736066\n",
      "Epoch:305 | Loss:1.1425012900367295 | Fidelity:0.8753427562120908\n",
      "Test-Epoch:305 | Loss:1.1420213367433745 | Fidelity:0.8756877174962244\n",
      "benign fid:0.8408401380509439\n",
      "Epoch:310 | Loss:1.1424106852397773 | Fidelity:0.8754113281932556\n",
      "Test-Epoch:310 | Loss:1.1418702637288791 | Fidelity:0.8758058416693524\n",
      "benign fid:0.8415275971399264\n",
      "Epoch:315 | Loss:1.1422738987993475 | Fidelity:0.8755173354909748\n",
      "Test-Epoch:315 | Loss:1.1418020451885393 | Fidelity:0.8758574754803614\n",
      "benign fid:0.8417697290686684\n",
      "Epoch:320 | Loss:1.1422064492753952 | Fidelity:0.8755681836013463\n",
      "Test-Epoch:320 | Loss:1.1416700869260323 | Fidelity:0.8759595503688885\n",
      "benign fid:0.8420209274651244\n",
      "Epoch:325 | Loss:1.1420950763728746 | Fidelity:0.8756518339879427\n",
      "Test-Epoch:325 | Loss:1.1417326844264672 | Fidelity:0.8759084976876076\n",
      "benign fid:0.8436034152586522\n",
      "Epoch:330 | Loss:1.1419628936257409 | Fidelity:0.8757539810069144\n",
      "Test-Epoch:330 | Loss:1.1415454967461722 | Fidelity:0.8760543242443267\n",
      "benign fid:0.8436510119770089\n",
      "Epoch:335 | Loss:1.1418567333043452 | Fidelity:0.8758351776466325\n",
      "Test-Epoch:335 | Loss:1.1414859930762085 | Fidelity:0.8760991875584656\n",
      "benign fid:0.844200041863286\n",
      "Epoch:340 | Loss:1.1417888740281832 | Fidelity:0.8758877066552352\n",
      "Test-Epoch:340 | Loss:1.1414713623285868 | Fidelity:0.8761095247475277\n",
      "benign fid:0.8445030730738255\n",
      "Epoch:345 | Loss:1.1416723451843767 | Fidelity:0.8759768844629758\n",
      "Test-Epoch:345 | Loss:1.1413076110434575 | Fidelity:0.8762367279738604\n",
      "benign fid:0.8448148396773154\n",
      "Epoch:350 | Loss:1.1415886650824905 | Fidelity:0.8760401889657063\n",
      "Test-Epoch:350 | Loss:1.1412577083130306 | Fidelity:0.876274303411131\n",
      "benign fid:0.8452639912224398\n",
      "Epoch:355 | Loss:1.141500744660331 | Fidelity:0.8761080030367407\n",
      "Test-Epoch:355 | Loss:1.1412161357968682 | Fidelity:0.8763068542801307\n",
      "benign fid:0.8459891552464671\n",
      "Epoch:360 | Loss:1.1414134634856141 | Fidelity:0.8761754752844086\n",
      "Test-Epoch:360 | Loss:1.1411325502781735 | Fidelity:0.8763714750924125\n",
      "benign fid:0.8459999335608942\n",
      "Epoch:365 | Loss:1.1413347655926733 | Fidelity:0.876235670262137\n",
      "Test-Epoch:365 | Loss:1.1410892708754063 | Fidelity:0.8764046973932138\n",
      "benign fid:0.8464436625905665\n",
      "Epoch:370 | Loss:1.1412987499207004 | Fidelity:0.8762616583315672\n",
      "Test-Epoch:370 | Loss:1.1410777900843958 | Fidelity:0.8764115281604244\n",
      "benign fid:0.8467297195086456\n",
      "Epoch:375 | Loss:1.1411851118999032 | Fidelity:0.8763502133116275\n",
      "Test-Epoch:375 | Loss:1.140953930572913 | Fidelity:0.8765088043642246\n",
      "benign fid:0.8467898581740539\n",
      "Epoch:380 | Loss:1.1411265753300655 | Fidelity:0.876394491333765\n",
      "Test-Epoch:380 | Loss:1.1408678674175166 | Fidelity:0.8765751918675138\n",
      "benign fid:0.8469336727318811\n",
      "Epoch:385 | Loss:1.1410638663817703 | Fidelity:0.8764426867479724\n",
      "Test-Epoch:385 | Loss:1.1408543448813178 | Fidelity:0.8765847101717051\n",
      "benign fid:0.8472366027333356\n",
      "Epoch:390 | Loss:1.141007814844072 | Fidelity:0.87648636155466\n",
      "Test-Epoch:390 | Loss:1.1408438146729563 | Fidelity:0.8765928510159068\n",
      "benign fid:0.8473971925183641\n",
      "Epoch:395 | Loss:1.1409445981137 | Fidelity:0.8765346107586448\n",
      "Test-Epoch:395 | Loss:1.1407398179899093 | Fidelity:0.8766739415415021\n",
      "benign fid:0.8475442596811744\n",
      "Epoch:400 | Loss:1.1408936585101628 | Fidelity:0.8765734740710537\n",
      "Test-Epoch:400 | Loss:1.140727903340791 | Fidelity:0.8766824049927501\n",
      "benign fid:0.8479292480757987\n",
      "Epoch:405 | Loss:1.140847697368916 | Fidelity:0.8766093171039888\n",
      "Test-Epoch:405 | Loss:1.140688597449725 | Fidelity:0.8767123742348762\n",
      "benign fid:0.8476389428773957\n",
      "Epoch:410 | Loss:1.1408090595644693 | Fidelity:0.8766382796159358\n",
      "Test-Epoch:410 | Loss:1.140591671843116 | Fidelity:0.8767881784589557\n",
      "benign fid:0.8478038154473058\n",
      "Epoch:415 | Loss:1.1407688028658305 | Fidelity:0.876669552945194\n",
      "Test-Epoch:415 | Loss:1.1405685626415996 | Fidelity:0.8768061748141086\n",
      "benign fid:0.8479790914117681\n",
      "Epoch:420 | Loss:1.1407763518809935 | Fidelity:0.8766647347601549\n",
      "Test-Epoch:420 | Loss:1.1405942216871654 | Fidelity:0.8767874356048339\n",
      "benign fid:0.8481029236722126\n",
      "Epoch:425 | Loss:1.1406760968438563 | Fidelity:0.8767420261496363\n",
      "Test-Epoch:425 | Loss:1.140541794409267 | Fidelity:0.8768261003879098\n",
      "benign fid:0.8479365293800779\n",
      "Epoch:430 | Loss:1.1406484990888306 | Fidelity:0.8767635785507137\n",
      "Test-Epoch:430 | Loss:1.14049126245913 | Fidelity:0.8768658795834808\n",
      "benign fid:0.8478090478729373\n",
      "Epoch:435 | Loss:1.1406552541716843 | Fidelity:0.8767577922140172\n",
      "Test-Epoch:435 | Loss:1.1404648831972306 | Fidelity:0.8768872142137967\n",
      "benign fid:0.8481503622412664\n",
      "Epoch:440 | Loss:1.1405902348850134 | Fidelity:0.876807661423513\n",
      "Test-Epoch:440 | Loss:1.1404919063548637 | Fidelity:0.8768637087206204\n",
      "benign fid:0.8482494629506929\n",
      "Epoch:445 | Loss:1.1405391784693502 | Fidelity:0.876847293267454\n",
      "Test-Epoch:445 | Loss:1.1403793431518119 | Fidelity:0.8769521791529997\n",
      "benign fid:0.8481036765178764\n",
      "Epoch:450 | Loss:1.1405018040178438 | Fidelity:0.8768764887016941\n",
      "Test-Epoch:450 | Loss:1.1404005848566037 | Fidelity:0.8769352881126337\n",
      "benign fid:0.848359830241401\n",
      "Epoch:455 | Loss:1.1405455857142703 | Fidelity:0.8768427173030011\n",
      "Test-Epoch:455 | Loss:1.140489524449093 | Fidelity:0.8768649673011094\n",
      "benign fid:0.8481795577903671\n",
      "Epoch:460 | Loss:1.1404437925837174 | Fidelity:0.8769208899131136\n",
      "Test-Epoch:460 | Loss:1.1403344628287737 | Fidelity:0.8769857651935445\n",
      "benign fid:0.8482071939664745\n",
      "Epoch:465 | Loss:1.140413420008869 | Fidelity:0.8769443083397218\n",
      "Test-Epoch:465 | Loss:1.1403166869206143 | Fidelity:0.8769994495865385\n",
      "benign fid:0.8484263927934723\n",
      "Epoch:470 | Loss:1.1403926003305995 | Fidelity:0.876960302651628\n",
      "Test-Epoch:470 | Loss:1.1402535738387984 | Fidelity:0.8770485805831947\n",
      "benign fid:0.8481090416204762\n",
      "Epoch:475 | Loss:1.1403644567710833 | Fidelity:0.8769823140753782\n",
      "Test-Epoch:475 | Loss:1.140267717907825 | Fidelity:0.8770377117050219\n",
      "benign fid:0.8485219392168728\n",
      "Epoch:480 | Loss:1.1403383641815925 | Fidelity:0.8770026669958789\n",
      "Test-Epoch:480 | Loss:1.1402263704743387 | Fidelity:0.8770698477506959\n",
      "benign fid:0.8483167675764798\n",
      "Epoch:485 | Loss:1.1403223543563086 | Fidelity:0.8770144703729553\n",
      "Test-Epoch:485 | Loss:1.140218165716328 | Fidelity:0.8770759860448192\n",
      "benign fid:0.8486192570247563\n",
      "Epoch:490 | Loss:1.140327996479173 | Fidelity:0.8770113623288489\n",
      "Test-Epoch:490 | Loss:1.1402252584473425 | Fidelity:0.8770719038674734\n",
      "benign fid:0.8485338948984529\n",
      "Epoch:495 | Loss:1.1402768612155705 | Fidelity:0.8770500979580758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-Epoch:495 | Loss:1.140207496605444 | Fidelity:0.8770836602379133\n",
      "benign fid:0.8486460530194847\n"
     ]
    }
   ],
   "source": [
    "loss_hist=[]\n",
    "fid_hist=[]\n",
    "\n",
    "loss_hist_test=[]\n",
    "fid_hist_test=[]\n",
    "\n",
    "benign_fid=[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    batches = iterate_batches(X=training_data, batch_size=batch_size)\n",
    "    for xbatch in batches:\n",
    "        encoder_params = opt.step(cost, encoder_params, X=xbatch)\n",
    "\n",
    "        \n",
    "    if epoch%5 == 0:\n",
    "        \n",
    "        loss_training = cost(encoder_params, X_training )\n",
    "        fidel = fidelity(encoder_params, X_training )\n",
    "        \n",
    "        loss_hist.append(loss_training)\n",
    "        fid_hist.append(fidel)\n",
    "        print(\"Epoch:{} | Loss:{} | Fidelity:{}\".format(epoch, loss_training, fidel))\n",
    "\n",
    "        loss_test = cost(encoder_params, X_tes )\n",
    "        fidel = fidelity(encoder_params, X_tes )\n",
    "        loss_hist_test.append(loss_test)\n",
    "        fid_hist_test.append(fidel)\n",
    "        print(\"Test-Epoch:{} | Loss:{} | Fidelity:{}\".format(epoch, loss_test, fidel))\n",
    "        \n",
    "        b_fidel = fidelity(encoder_params, benign_data )\n",
    "        benign_fid.append(b_fidel)\n",
    "        print(\"benign fid:{}\".format(b_fidel))\n",
    "        \n",
    "        \"\"\"\n",
    "        experiment_parameters={\"autoencoder\":\"e2\",\"params\":encoder_params}\n",
    "        f=open(\"Cancer_encoder_e3-SelectedFeautures/params\"+str(epoch)+\".txt\",\"w\")\n",
    "        f.write(str(experiment_parameters))\n",
    "        f.close()\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rezults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fidelity: 0.8770500979580758\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x for x in range(0,len(loss_hist)*5,5)],np.array(fid_hist),label=\"train fid\")\n",
    "plt.plot([x for x in range(0,len(loss_hist)*5,5)],np.array(fid_hist_test),label=\"test fid\")\n",
    "plt.plot([x for x in range(0,len(loss_hist)*5,5)],np.array(benign_fid),label=\"benign fid\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Malign 2x424->compression fidelity e5\",)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"fid\")\n",
    "\n",
    "print(\"fidelity:\",fid_hist[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.1402768612155705\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x for x in range(0,len(loss_hist)*5,5)],np.array(loss_hist),label=\"train loss\")\n",
    "plt.plot([x for x in range(0,len(loss_hist)*5,5)],np.array(loss_hist_test),label=\"test loss\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Malign 2x424->compression loss e5\",)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "print(\"loss:\",loss_hist[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benign performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign results:\n",
      "fidelity= 0.8482674497374206\n",
      "loss= 1.179201693867523\n"
     ]
    }
   ],
   "source": [
    "np_benign = benign.to_numpy()\n",
    "benign_data = [ torch.tensor([np_benign[i]]) for i in range(len(benign.to_numpy()))]\n",
    "\n",
    "loss = cost(encoder_params, benign_data )\n",
    "fidel = fidelity(encoder_params, benign_data )\n",
    "\n",
    "print(\"Benign results:\")\n",
    "print(\"fidelity=\",fidel)\n",
    "print(\"loss=\",loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifyer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.814772335260057\n",
      "0.8850835613722416\n"
     ]
    }
   ],
   "source": [
    "beningn_flist=[]\n",
    "for b in benign_data:\n",
    "    f=fidelity(encoder_params, [b])\n",
    "    beningn_flist.append(f.item())\n",
    "    \n",
    "print(min(beningn_flist))\n",
    "print(max(beningn_flist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8494620763586773\n",
      "0.9111891585992302\n"
     ]
    }
   ],
   "source": [
    "malign_flist=[]\n",
    "for b in training_data:\n",
    "    f=fidelity(encoder_params, [b])\n",
    "    malign_flist.append(f.item())\n",
    "    \n",
    "print(min(malign_flist))\n",
    "print(max(malign_flist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8501498784085659,\n",
       " 0.8488094280226266,\n",
       " 0.855506220729984,\n",
       " 0.8450291703186508,\n",
       " 0.8565805535394873,\n",
       " 0.8473095927089749,\n",
       " 0.841971794891615,\n",
       " 0.8245574336437866,\n",
       " 0.870068855963084,\n",
       " 0.8477275537668817,\n",
       " 0.8583989159513592,\n",
       " 0.8164767954856313,\n",
       " 0.8444782754895036,\n",
       " 0.8307628289429383,\n",
       " 0.845981793335682,\n",
       " 0.8556057647441634,\n",
       " 0.8540631468624222,\n",
       " 0.8647238753937945,\n",
       " 0.814772335260057,\n",
       " 0.8592547221053533,\n",
       " 0.8499379529602992,\n",
       " 0.8460069901453474,\n",
       " 0.8307823331626737,\n",
       " 0.8353241436754961,\n",
       " 0.8666688840057231,\n",
       " 0.8450583506877811,\n",
       " 0.8850835613722416,\n",
       " 0.8808648781858633,\n",
       " 0.8760003494500024,\n",
       " 0.8474735802428105,\n",
       " 0.8721171046392867,\n",
       " 0.8245065740875661,\n",
       " 0.832446797201401,\n",
       " 0.8234741293175938,\n",
       " 0.8502678948536113,\n",
       " 0.8356584328115987,\n",
       " 0.8167069762178611,\n",
       " 0.8672126859451732,\n",
       " 0.8651692944386232,\n",
       " 0.8772823625343856,\n",
       " 0.8538668858893721,\n",
       " 0.8275010550743933,\n",
       " 0.8339023836974407,\n",
       " 0.8394075280239374,\n",
       " 0.8432505402294277,\n",
       " 0.8549848842325634,\n",
       " 0.8451917815108536,\n",
       " 0.824367279511129,\n",
       " 0.8693906165084836,\n",
       " 0.8558577994612593,\n",
       " 0.825039090668486,\n",
       " 0.8454843762067739,\n",
       " 0.8215361057988345,\n",
       " 0.8386454946764051,\n",
       " 0.8507417743082272,\n",
       " 0.837590046891228,\n",
       " 0.8436249829596862,\n",
       " 0.8391621471499996,\n",
       " 0.842644708724299,\n",
       " 0.843586406793147,\n",
       " 0.848797955228997,\n",
       " 0.8431954096222666,\n",
       " 0.8369932476101237,\n",
       " 0.8486593316768235,\n",
       " 0.8498518607804283,\n",
       " 0.8493242460329141,\n",
       " 0.8722700093555309,\n",
       " 0.8511589627429488,\n",
       " 0.848203095500738,\n",
       " 0.8658931201750476,\n",
       " 0.8517692086566916,\n",
       " 0.8506009841062541,\n",
       " 0.836687764168986,\n",
       " 0.8620811800636441,\n",
       " 0.8234826574161233,\n",
       " 0.8654033220400456,\n",
       " 0.8614234777545914,\n",
       " 0.8466764656199036,\n",
       " 0.844543017973305,\n",
       " 0.866786589357529,\n",
       " 0.8309642484809081,\n",
       " 0.8674238906819552,\n",
       " 0.8459254616319472,\n",
       " 0.8816785696712763,\n",
       " 0.8532248499526256,\n",
       " 0.8278790018565463,\n",
       " 0.8638749596253767,\n",
       " 0.8629606877345074,\n",
       " 0.8180232870326263,\n",
       " 0.8503419685948496,\n",
       " 0.8298374862015496,\n",
       " 0.8486980176567076,\n",
       " 0.8611603155903459,\n",
       " 0.825534291816008,\n",
       " 0.8343638415307442,\n",
       " 0.8547817969004767,\n",
       " 0.8764067790711495,\n",
       " 0.8537191749373204,\n",
       " 0.84659029045739,\n",
       " 0.8472579313443356,\n",
       " 0.8409169865471209,\n",
       " 0.8405845358512433,\n",
       " 0.8667320664321942,\n",
       " 0.8340888698397068,\n",
       " 0.8609395128547312,\n",
       " 0.832608979191008,\n",
       " 0.840875029193546,\n",
       " 0.8442475245675559,\n",
       " 0.8491186462585728,\n",
       " 0.8646884514959421,\n",
       " 0.8695096491585275,\n",
       " 0.8549526273370395,\n",
       " 0.8576136384054757,\n",
       " 0.8422726722569562,\n",
       " 0.8474854505307663,\n",
       " 0.8395332118198946,\n",
       " 0.855194270260073,\n",
       " 0.8412833449058529,\n",
       " 0.8565177570516956,\n",
       " 0.8549841867590375,\n",
       " 0.8456321809738063,\n",
       " 0.8548304059545985,\n",
       " 0.8460994146286048,\n",
       " 0.8442359952724181,\n",
       " 0.8315456360449437,\n",
       " 0.8574740545669693,\n",
       " 0.8405256215611241,\n",
       " 0.8539301807069946,\n",
       " 0.858316509400405,\n",
       " 0.8421411213671762,\n",
       " 0.821638753074664,\n",
       " 0.8402540618314095,\n",
       " 0.8330038563650263,\n",
       " 0.8399109705453344,\n",
       " 0.863432465156347,\n",
       " 0.8483611570996245,\n",
       " 0.8386302679058564,\n",
       " 0.8514221031134696,\n",
       " 0.8600136868995635,\n",
       " 0.8396921236480449,\n",
       " 0.8602157507521897,\n",
       " 0.8529383732258167,\n",
       " 0.8625051339622235,\n",
       " 0.8619787306225495,\n",
       " 0.8512897929821719,\n",
       " 0.8543842418878957,\n",
       " 0.8369178149881973,\n",
       " 0.8360449751953518,\n",
       " 0.8391788029679436,\n",
       " 0.8436866795147187,\n",
       " 0.855890218475111,\n",
       " 0.8245409563227561,\n",
       " 0.8552709874558477,\n",
       " 0.8826040346525843,\n",
       " 0.8511272897672407,\n",
       " 0.8442989803071587,\n",
       " 0.8270230583729979,\n",
       " 0.8333136103334159,\n",
       " 0.8470094881060308,\n",
       " 0.8537507589875484,\n",
       " 0.8550041721792803,\n",
       " 0.8555080684913814,\n",
       " 0.8460634314822992,\n",
       " 0.8371397977617471,\n",
       " 0.8351024303353515,\n",
       " 0.8369689635789616,\n",
       " 0.8439221103074027,\n",
       " 0.8381114139944089,\n",
       " 0.859749812816371,\n",
       " 0.8447933403993326,\n",
       " 0.8582640588866747,\n",
       " 0.8453652267026419,\n",
       " 0.8610992850357334,\n",
       " 0.8595080000728419,\n",
       " 0.8736931180554164,\n",
       " 0.8737443332331459,\n",
       " 0.8534413073500227,\n",
       " 0.8462827639010313,\n",
       " 0.8522687468240899,\n",
       " 0.867937214266767,\n",
       " 0.8241524311991684,\n",
       " 0.8622271376501985,\n",
       " 0.8535115125391496,\n",
       " 0.8441317931308858,\n",
       " 0.8570630080161641,\n",
       " 0.8362405938750653,\n",
       " 0.8488096091105537,\n",
       " 0.86178235739758,\n",
       " 0.8685238892352599,\n",
       " 0.8282899681661912,\n",
       " 0.8394757994924682,\n",
       " 0.8485302874396164,\n",
       " 0.843950802775407,\n",
       " 0.8526183070708891,\n",
       " 0.8191730938430886]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beningn_flist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(beningn_flist, bins = 100 ,label=\"benign\", color = \"skyblue\",alpha=0.4)\n",
    "plt.hist(malign_flist, bins =100 ,label=\"malign\",color = \"red\",alpha=0.4)\n",
    "plt.title(\"Compression fidelity\",)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split: 0.866\n",
      "benign classification accuracy: 0.8923076923076924\n",
      "malign classification accuracy: 0.9098360655737705\n",
      "total accuracy: 0.9020501138952164\n"
     ]
    }
   ],
   "source": [
    "split=0.866\n",
    "\n",
    "\n",
    "print(\"split:\",split)\n",
    "b_e=[]\n",
    "for i in beningn_flist:\n",
    "    if i<split:\n",
    "        b_e.append(1)\n",
    "    else:\n",
    "        b_e.append(0)\n",
    "ab_ac=sum(b_e)/len(b_e)\n",
    "print(\"benign classification accuracy:\",ab_ac)\n",
    "m_e=[]\n",
    "for i in malign_flist:\n",
    "    if i>split:\n",
    "        m_e.append(1)\n",
    "    else:\n",
    "        m_e.append(0)\n",
    "am_ac=sum(m_e)/len(m_e)\n",
    "print(\"malign classification accuracy:\",am_ac)\n",
    "t_ac=(sum(b_e)+sum(m_e))/(len(b_e)+len(m_e))\n",
    "print(\"total accuracy:\",t_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "experiment_parameters={\"autoencoder\":\"e2\",\"params\":encoder_params}\n",
    "f=open(\"Cancer_encoder_e5-SelectedFeautures_params500\"+str(epoch)+\".txt\",\"w\")\n",
    "f.write(str(experiment_parameters))\n",
    "f.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
