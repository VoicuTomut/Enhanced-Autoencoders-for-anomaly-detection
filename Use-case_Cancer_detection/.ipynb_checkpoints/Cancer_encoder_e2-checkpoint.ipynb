{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomut\\anaconda3\\envs\\qhack2022\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\tomut\\anaconda3\\envs\\qhack2022\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "import pandas as pd \n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "#quanutm lib\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "\n",
    "from pennylane.optimize import AdamOptimizer\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path\n",
    "\n",
    "from qencode.initialize import setAB_amplitude, setAux, setEnt\n",
    "from qencode.encoders import e2_classic\n",
    "from qencode.training_circuits import swap_t\n",
    "from qencode.qubits_arrangement import QubitsArrangement\n",
    "\n",
    "from qencode.utils.mnist import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"cancer.csv\", nrows=500)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       500 non-null    int64  \n",
      " 1   diagnosis                500 non-null    object \n",
      " 2   radius_mean              500 non-null    float64\n",
      " 3   texture_mean             500 non-null    float64\n",
      " 4   perimeter_mean           500 non-null    float64\n",
      " 5   area_mean                500 non-null    float64\n",
      " 6   smoothness_mean          500 non-null    float64\n",
      " 7   compactness_mean         500 non-null    float64\n",
      " 8   concavity_mean           500 non-null    float64\n",
      " 9   concave points_mean      500 non-null    float64\n",
      " 10  symmetry_mean            500 non-null    float64\n",
      " 11  fractal_dimension_mean   500 non-null    float64\n",
      " 12  radius_se                500 non-null    float64\n",
      " 13  texture_se               500 non-null    float64\n",
      " 14  perimeter_se             500 non-null    float64\n",
      " 15  area_se                  500 non-null    float64\n",
      " 16  smoothness_se            500 non-null    float64\n",
      " 17  compactness_se           500 non-null    float64\n",
      " 18  concavity_se             500 non-null    float64\n",
      " 19  concave points_se        500 non-null    float64\n",
      " 20  symmetry_se              500 non-null    float64\n",
      " 21  fractal_dimension_se     500 non-null    float64\n",
      " 22  radius_worst             500 non-null    float64\n",
      " 23  texture_worst            500 non-null    float64\n",
      " 24  perimeter_worst          500 non-null    float64\n",
      " 25  area_worst               500 non-null    float64\n",
      " 26  smoothness_worst         500 non-null    float64\n",
      " 27  compactness_worst        500 non-null    float64\n",
      " 28  concavity_worst          500 non-null    float64\n",
      " 29  concave points_worst     500 non-null    float64\n",
      " 30  symmetry_worst           500 non-null    float64\n",
      " 31  fractal_dimension_worst  500 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 129.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.263049e+07</td>\n",
       "      <td>14.224206</td>\n",
       "      <td>19.086320</td>\n",
       "      <td>92.606620</td>\n",
       "      <td>662.844800</td>\n",
       "      <td>0.095978</td>\n",
       "      <td>0.103948</td>\n",
       "      <td>0.089941</td>\n",
       "      <td>0.049446</td>\n",
       "      <td>0.181370</td>\n",
       "      <td>...</td>\n",
       "      <td>25.508500</td>\n",
       "      <td>108.258320</td>\n",
       "      <td>896.003200</td>\n",
       "      <td>0.131972</td>\n",
       "      <td>0.256324</td>\n",
       "      <td>0.276420</td>\n",
       "      <td>0.115980</td>\n",
       "      <td>0.292212</td>\n",
       "      <td>0.083778</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.326933e+08</td>\n",
       "      <td>3.476809</td>\n",
       "      <td>4.164842</td>\n",
       "      <td>23.983476</td>\n",
       "      <td>349.357241</td>\n",
       "      <td>0.013666</td>\n",
       "      <td>0.053096</td>\n",
       "      <td>0.080259</td>\n",
       "      <td>0.038875</td>\n",
       "      <td>0.027716</td>\n",
       "      <td>...</td>\n",
       "      <td>6.063133</td>\n",
       "      <td>33.312706</td>\n",
       "      <td>571.074422</td>\n",
       "      <td>0.022739</td>\n",
       "      <td>0.159147</td>\n",
       "      <td>0.209012</td>\n",
       "      <td>0.065896</td>\n",
       "      <td>0.063366</td>\n",
       "      <td>0.018108</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.062510</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.116700</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.667040e+05</td>\n",
       "      <td>11.807500</td>\n",
       "      <td>16.070000</td>\n",
       "      <td>75.995000</td>\n",
       "      <td>430.550000</td>\n",
       "      <td>0.085992</td>\n",
       "      <td>0.063622</td>\n",
       "      <td>0.028885</td>\n",
       "      <td>0.020245</td>\n",
       "      <td>0.161875</td>\n",
       "      <td>...</td>\n",
       "      <td>21.017500</td>\n",
       "      <td>84.567500</td>\n",
       "      <td>522.600000</td>\n",
       "      <td>0.116200</td>\n",
       "      <td>0.145925</td>\n",
       "      <td>0.114475</td>\n",
       "      <td>0.063302</td>\n",
       "      <td>0.251700</td>\n",
       "      <td>0.071270</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.014320e+05</td>\n",
       "      <td>13.435000</td>\n",
       "      <td>18.680000</td>\n",
       "      <td>86.735000</td>\n",
       "      <td>556.150000</td>\n",
       "      <td>0.095825</td>\n",
       "      <td>0.091280</td>\n",
       "      <td>0.064315</td>\n",
       "      <td>0.033870</td>\n",
       "      <td>0.179550</td>\n",
       "      <td>...</td>\n",
       "      <td>25.240000</td>\n",
       "      <td>97.980000</td>\n",
       "      <td>691.750000</td>\n",
       "      <td>0.131250</td>\n",
       "      <td>0.214850</td>\n",
       "      <td>0.231400</td>\n",
       "      <td>0.100650</td>\n",
       "      <td>0.283100</td>\n",
       "      <td>0.079900</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.910808e+06</td>\n",
       "      <td>16.115000</td>\n",
       "      <td>21.562500</td>\n",
       "      <td>106.225000</td>\n",
       "      <td>800.775000</td>\n",
       "      <td>0.105100</td>\n",
       "      <td>0.130500</td>\n",
       "      <td>0.132150</td>\n",
       "      <td>0.074928</td>\n",
       "      <td>0.195625</td>\n",
       "      <td>...</td>\n",
       "      <td>29.350000</td>\n",
       "      <td>127.150000</td>\n",
       "      <td>1150.750000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.343525</td>\n",
       "      <td>0.389450</td>\n",
       "      <td>0.166850</td>\n",
       "      <td>0.320050</td>\n",
       "      <td>0.092065</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.144700</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count  5.000000e+02   500.000000    500.000000      500.000000   500.000000   \n",
       "mean   3.263049e+07    14.224206     19.086320       92.606620   662.844800   \n",
       "std    1.326933e+08     3.476809      4.164842       23.983476   349.357241   \n",
       "min    8.670000e+03     6.981000      9.710000       43.790000   143.500000   \n",
       "25%    8.667040e+05    11.807500     16.070000       75.995000   430.550000   \n",
       "50%    9.014320e+05    13.435000     18.680000       86.735000   556.150000   \n",
       "75%    8.910808e+06    16.115000     21.562500      106.225000   800.775000   \n",
       "max    9.113205e+08    28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count       500.000000        500.000000      500.000000           500.000000   \n",
       "mean          0.095978          0.103948        0.089941             0.049446   \n",
       "std           0.013666          0.053096        0.080259             0.038875   \n",
       "min           0.062510          0.019380        0.000000             0.000000   \n",
       "25%           0.085992          0.063622        0.028885             0.020245   \n",
       "50%           0.095825          0.091280        0.064315             0.033870   \n",
       "75%           0.105100          0.130500        0.132150             0.074928   \n",
       "max           0.144700          0.345400        0.426800             0.201200   \n",
       "\n",
       "       symmetry_mean  ...  texture_worst  perimeter_worst   area_worst  \\\n",
       "count     500.000000  ...     500.000000       500.000000   500.000000   \n",
       "mean        0.181370  ...      25.508500       108.258320   896.003200   \n",
       "std         0.027716  ...       6.063133        33.312706   571.074422   \n",
       "min         0.116700  ...      12.020000        50.410000   185.200000   \n",
       "25%         0.161875  ...      21.017500        84.567500   522.600000   \n",
       "50%         0.179550  ...      25.240000        97.980000   691.750000   \n",
       "75%         0.195625  ...      29.350000       127.150000  1150.750000   \n",
       "max         0.304000  ...      49.540000       251.200000  4254.000000   \n",
       "\n",
       "       smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "count        500.000000         500.000000       500.000000   \n",
       "mean           0.131972           0.256324         0.276420   \n",
       "std            0.022739           0.159147         0.209012   \n",
       "min            0.071170           0.027290         0.000000   \n",
       "25%            0.116200           0.145925         0.114475   \n",
       "50%            0.131250           0.214850         0.231400   \n",
       "75%            0.146000           0.343525         0.389450   \n",
       "max            0.222600           1.058000         1.252000   \n",
       "\n",
       "       concave points_worst  symmetry_worst  fractal_dimension_worst  \\\n",
       "count            500.000000      500.000000               500.000000   \n",
       "mean               0.115980        0.292212                 0.083778   \n",
       "std                0.065896        0.063366                 0.018108   \n",
       "min                0.000000        0.156500                 0.055040   \n",
       "25%                0.063302        0.251700                 0.071270   \n",
       "50%                0.100650        0.283100                 0.079900   \n",
       "75%                0.166850        0.320050                 0.092065   \n",
       "max                0.291000        0.663800                 0.207500   \n",
       "\n",
       "       Unnamed: 32  \n",
       "count          0.0  \n",
       "mean           NaN  \n",
       "std            NaN  \n",
       "min            NaN  \n",
       "25%            NaN  \n",
       "50%            NaN  \n",
       "75%            NaN  \n",
       "max            NaN  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data seams pretty clean  without any nan value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "      <th>over_average</th>\n",
       "      <th>under_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0  ...      2019.0            0.1622             0.6656           0.7119   \n",
       "1  ...      1956.0            0.1238             0.1866           0.2416   \n",
       "2  ...      1709.0            0.1444             0.4245           0.4504   \n",
       "3  ...       567.7            0.2098             0.8663           0.6869   \n",
       "4  ...      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  Unnamed: 32  \\\n",
       "0                0.2654          0.4601                  0.11890          NaN   \n",
       "1                0.1860          0.2750                  0.08902          NaN   \n",
       "2                0.2430          0.3613                  0.08758          NaN   \n",
       "3                0.2575          0.6638                  0.17300          NaN   \n",
       "4                0.1625          0.2364                  0.07678          NaN   \n",
       "\n",
       "   over_average  under_average  \n",
       "0            13             17  \n",
       "1             0             30  \n",
       "2             1             29  \n",
       "3            12             18  \n",
       "4             0             30  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## engineering two new features to have 32 feutures that can be encoded om 5 qubits.\n",
    "over_average = []\n",
    "under_average = []\n",
    "\n",
    "mean = {}\n",
    "std = {}\n",
    "for col in df:\n",
    "     if col not in [\"id\",\"diagnosis\" ]:\n",
    "        mean[col]=df[col].mean()\n",
    "        std[col]=df[col].std()\n",
    "\n",
    "for index,row in df.iterrows():\n",
    "    o_average=0\n",
    "    u_average=0\n",
    "    for col in df:\n",
    "        if col not in [\"id\",\"diagnosis\" ]:\n",
    "            if  row[col]> mean[col]+2* std[col]:\n",
    "                o_average = o_average + 1\n",
    "            if  row[col]< mean[col]+2* std[col]:\n",
    "                u_average= u_average + 1\n",
    "                \n",
    "    over_average.append(o_average)\n",
    "    under_average.append(u_average)\n",
    "\n",
    "df[\"over_average\"] = over_average\n",
    "df[\"under_average\"] = under_average\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "      <th>over_average</th>\n",
       "      <th>under_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.263049e+07</td>\n",
       "      <td>14.224206</td>\n",
       "      <td>19.086320</td>\n",
       "      <td>92.606620</td>\n",
       "      <td>662.844800</td>\n",
       "      <td>0.095978</td>\n",
       "      <td>0.103948</td>\n",
       "      <td>0.089941</td>\n",
       "      <td>0.049446</td>\n",
       "      <td>0.181370</td>\n",
       "      <td>...</td>\n",
       "      <td>896.003200</td>\n",
       "      <td>0.131972</td>\n",
       "      <td>0.256324</td>\n",
       "      <td>0.276420</td>\n",
       "      <td>0.115980</td>\n",
       "      <td>0.292212</td>\n",
       "      <td>0.083778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>28.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.326933e+08</td>\n",
       "      <td>3.476809</td>\n",
       "      <td>4.164842</td>\n",
       "      <td>23.983476</td>\n",
       "      <td>349.357241</td>\n",
       "      <td>0.013666</td>\n",
       "      <td>0.053096</td>\n",
       "      <td>0.080259</td>\n",
       "      <td>0.038875</td>\n",
       "      <td>0.027716</td>\n",
       "      <td>...</td>\n",
       "      <td>571.074422</td>\n",
       "      <td>0.022739</td>\n",
       "      <td>0.159147</td>\n",
       "      <td>0.209012</td>\n",
       "      <td>0.065896</td>\n",
       "      <td>0.063366</td>\n",
       "      <td>0.018108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.811282</td>\n",
       "      <td>2.811282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.062510</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.116700</td>\n",
       "      <td>...</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.667040e+05</td>\n",
       "      <td>11.807500</td>\n",
       "      <td>16.070000</td>\n",
       "      <td>75.995000</td>\n",
       "      <td>430.550000</td>\n",
       "      <td>0.085992</td>\n",
       "      <td>0.063622</td>\n",
       "      <td>0.028885</td>\n",
       "      <td>0.020245</td>\n",
       "      <td>0.161875</td>\n",
       "      <td>...</td>\n",
       "      <td>522.600000</td>\n",
       "      <td>0.116200</td>\n",
       "      <td>0.145925</td>\n",
       "      <td>0.114475</td>\n",
       "      <td>0.063302</td>\n",
       "      <td>0.251700</td>\n",
       "      <td>0.071270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.014320e+05</td>\n",
       "      <td>13.435000</td>\n",
       "      <td>18.680000</td>\n",
       "      <td>86.735000</td>\n",
       "      <td>556.150000</td>\n",
       "      <td>0.095825</td>\n",
       "      <td>0.091280</td>\n",
       "      <td>0.064315</td>\n",
       "      <td>0.033870</td>\n",
       "      <td>0.179550</td>\n",
       "      <td>...</td>\n",
       "      <td>691.750000</td>\n",
       "      <td>0.131250</td>\n",
       "      <td>0.214850</td>\n",
       "      <td>0.231400</td>\n",
       "      <td>0.100650</td>\n",
       "      <td>0.283100</td>\n",
       "      <td>0.079900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.910808e+06</td>\n",
       "      <td>16.115000</td>\n",
       "      <td>21.562500</td>\n",
       "      <td>106.225000</td>\n",
       "      <td>800.775000</td>\n",
       "      <td>0.105100</td>\n",
       "      <td>0.130500</td>\n",
       "      <td>0.132150</td>\n",
       "      <td>0.074928</td>\n",
       "      <td>0.195625</td>\n",
       "      <td>...</td>\n",
       "      <td>1150.750000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.343525</td>\n",
       "      <td>0.389450</td>\n",
       "      <td>0.166850</td>\n",
       "      <td>0.320050</td>\n",
       "      <td>0.092065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.144700</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count  5.000000e+02   500.000000    500.000000      500.000000   500.000000   \n",
       "mean   3.263049e+07    14.224206     19.086320       92.606620   662.844800   \n",
       "std    1.326933e+08     3.476809      4.164842       23.983476   349.357241   \n",
       "min    8.670000e+03     6.981000      9.710000       43.790000   143.500000   \n",
       "25%    8.667040e+05    11.807500     16.070000       75.995000   430.550000   \n",
       "50%    9.014320e+05    13.435000     18.680000       86.735000   556.150000   \n",
       "75%    8.910808e+06    16.115000     21.562500      106.225000   800.775000   \n",
       "max    9.113205e+08    28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count       500.000000        500.000000      500.000000           500.000000   \n",
       "mean          0.095978          0.103948        0.089941             0.049446   \n",
       "std           0.013666          0.053096        0.080259             0.038875   \n",
       "min           0.062510          0.019380        0.000000             0.000000   \n",
       "25%           0.085992          0.063622        0.028885             0.020245   \n",
       "50%           0.095825          0.091280        0.064315             0.033870   \n",
       "75%           0.105100          0.130500        0.132150             0.074928   \n",
       "max           0.144700          0.345400        0.426800             0.201200   \n",
       "\n",
       "       symmetry_mean  ...   area_worst  smoothness_worst  compactness_worst  \\\n",
       "count     500.000000  ...   500.000000        500.000000         500.000000   \n",
       "mean        0.181370  ...   896.003200          0.131972           0.256324   \n",
       "std         0.027716  ...   571.074422          0.022739           0.159147   \n",
       "min         0.116700  ...   185.200000          0.071170           0.027290   \n",
       "25%         0.161875  ...   522.600000          0.116200           0.145925   \n",
       "50%         0.179550  ...   691.750000          0.131250           0.214850   \n",
       "75%         0.195625  ...  1150.750000          0.146000           0.343525   \n",
       "max         0.304000  ...  4254.000000          0.222600           1.058000   \n",
       "\n",
       "       concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "count       500.000000            500.000000      500.000000   \n",
       "mean          0.276420              0.115980        0.292212   \n",
       "std           0.209012              0.065896        0.063366   \n",
       "min           0.000000              0.000000        0.156500   \n",
       "25%           0.114475              0.063302        0.251700   \n",
       "50%           0.231400              0.100650        0.283100   \n",
       "75%           0.389450              0.166850        0.320050   \n",
       "max           1.252000              0.291000        0.663800   \n",
       "\n",
       "       fractal_dimension_worst  Unnamed: 32  over_average  under_average  \n",
       "count               500.000000          0.0    500.000000     500.000000  \n",
       "mean                  0.083778          NaN      1.250000      28.750000  \n",
       "std                   0.018108          NaN      2.811282       2.811282  \n",
       "min                   0.055040          NaN      0.000000      10.000000  \n",
       "25%                   0.071270          NaN      0.000000      29.000000  \n",
       "50%                   0.079900          NaN      0.000000      30.000000  \n",
       "75%                   0.092065          NaN      1.000000      30.000000  \n",
       "max                   0.207500          NaN     20.000000      30.000000  \n",
       "\n",
       "[8 rows x 34 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "      <th>over_average</th>\n",
       "      <th>under_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.263049e+07</td>\n",
       "      <td>0.506019</td>\n",
       "      <td>0.485904</td>\n",
       "      <td>0.491282</td>\n",
       "      <td>0.265032</td>\n",
       "      <td>0.663292</td>\n",
       "      <td>0.300949</td>\n",
       "      <td>0.210733</td>\n",
       "      <td>0.245754</td>\n",
       "      <td>0.596612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.210626</td>\n",
       "      <td>0.592867</td>\n",
       "      <td>0.242273</td>\n",
       "      <td>0.220783</td>\n",
       "      <td>0.398557</td>\n",
       "      <td>0.440211</td>\n",
       "      <td>0.403749</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.326933e+08</td>\n",
       "      <td>0.123686</td>\n",
       "      <td>0.106030</td>\n",
       "      <td>0.127233</td>\n",
       "      <td>0.139687</td>\n",
       "      <td>0.094446</td>\n",
       "      <td>0.153722</td>\n",
       "      <td>0.188047</td>\n",
       "      <td>0.193216</td>\n",
       "      <td>0.091171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134244</td>\n",
       "      <td>0.102153</td>\n",
       "      <td>0.150423</td>\n",
       "      <td>0.166943</td>\n",
       "      <td>0.226448</td>\n",
       "      <td>0.095459</td>\n",
       "      <td>0.087266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.140564</td>\n",
       "      <td>0.093709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>0.248346</td>\n",
       "      <td>0.247200</td>\n",
       "      <td>0.232308</td>\n",
       "      <td>0.057377</td>\n",
       "      <td>0.431997</td>\n",
       "      <td>0.056109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.383882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043535</td>\n",
       "      <td>0.319721</td>\n",
       "      <td>0.025794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235764</td>\n",
       "      <td>0.265253</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.667040e+05</td>\n",
       "      <td>0.420046</td>\n",
       "      <td>0.409114</td>\n",
       "      <td>0.403156</td>\n",
       "      <td>0.172151</td>\n",
       "      <td>0.594281</td>\n",
       "      <td>0.184199</td>\n",
       "      <td>0.067678</td>\n",
       "      <td>0.100621</td>\n",
       "      <td>0.532484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122849</td>\n",
       "      <td>0.522013</td>\n",
       "      <td>0.137925</td>\n",
       "      <td>0.091434</td>\n",
       "      <td>0.217534</td>\n",
       "      <td>0.379180</td>\n",
       "      <td>0.343470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.014320e+05</td>\n",
       "      <td>0.477944</td>\n",
       "      <td>0.475560</td>\n",
       "      <td>0.460133</td>\n",
       "      <td>0.222371</td>\n",
       "      <td>0.662232</td>\n",
       "      <td>0.264273</td>\n",
       "      <td>0.150691</td>\n",
       "      <td>0.168340</td>\n",
       "      <td>0.590625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162612</td>\n",
       "      <td>0.589623</td>\n",
       "      <td>0.203072</td>\n",
       "      <td>0.184824</td>\n",
       "      <td>0.345876</td>\n",
       "      <td>0.426484</td>\n",
       "      <td>0.385060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.910808e+06</td>\n",
       "      <td>0.573284</td>\n",
       "      <td>0.548943</td>\n",
       "      <td>0.563528</td>\n",
       "      <td>0.320182</td>\n",
       "      <td>0.726330</td>\n",
       "      <td>0.377823</td>\n",
       "      <td>0.309630</td>\n",
       "      <td>0.372403</td>\n",
       "      <td>0.643503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270510</td>\n",
       "      <td>0.655885</td>\n",
       "      <td>0.324693</td>\n",
       "      <td>0.311062</td>\n",
       "      <td>0.573368</td>\n",
       "      <td>0.482148</td>\n",
       "      <td>0.443687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  radius_mean  texture_mean  perimeter_mean   area_mean  \\\n",
       "count  5.000000e+02   500.000000    500.000000      500.000000  500.000000   \n",
       "mean   3.263049e+07     0.506019      0.485904        0.491282    0.265032   \n",
       "std    1.326933e+08     0.123686      0.106030        0.127233    0.139687   \n",
       "min    8.670000e+03     0.248346      0.247200        0.232308    0.057377   \n",
       "25%    8.667040e+05     0.420046      0.409114        0.403156    0.172151   \n",
       "50%    9.014320e+05     0.477944      0.475560        0.460133    0.222371   \n",
       "75%    8.910808e+06     0.573284      0.548943        0.563528    0.320182   \n",
       "max    9.113205e+08     1.000000      1.000000        1.000000    1.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count       500.000000        500.000000      500.000000           500.000000   \n",
       "mean          0.663292          0.300949        0.210733             0.245754   \n",
       "std           0.094446          0.153722        0.188047             0.193216   \n",
       "min           0.431997          0.056109        0.000000             0.000000   \n",
       "25%           0.594281          0.184199        0.067678             0.100621   \n",
       "50%           0.662232          0.264273        0.150691             0.168340   \n",
       "75%           0.726330          0.377823        0.309630             0.372403   \n",
       "max           1.000000          1.000000        1.000000             1.000000   \n",
       "\n",
       "       symmetry_mean  ...  area_worst  smoothness_worst  compactness_worst  \\\n",
       "count     500.000000  ...  500.000000        500.000000         500.000000   \n",
       "mean        0.596612  ...    0.210626          0.592867           0.242273   \n",
       "std         0.091171  ...    0.134244          0.102153           0.150423   \n",
       "min         0.383882  ...    0.043535          0.319721           0.025794   \n",
       "25%         0.532484  ...    0.122849          0.522013           0.137925   \n",
       "50%         0.590625  ...    0.162612          0.589623           0.203072   \n",
       "75%         0.643503  ...    0.270510          0.655885           0.324693   \n",
       "max         1.000000  ...    1.000000          1.000000           1.000000   \n",
       "\n",
       "       concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "count       500.000000            500.000000      500.000000   \n",
       "mean          0.220783              0.398557        0.440211   \n",
       "std           0.166943              0.226448        0.095459   \n",
       "min           0.000000              0.000000        0.235764   \n",
       "25%           0.091434              0.217534        0.379180   \n",
       "50%           0.184824              0.345876        0.426484   \n",
       "75%           0.311062              0.573368        0.482148   \n",
       "max           1.000000              1.000000        1.000000   \n",
       "\n",
       "       fractal_dimension_worst  Unnamed: 32  over_average  under_average  \n",
       "count               500.000000          0.0    500.000000     500.000000  \n",
       "mean                  0.403749          NaN      0.062500       0.958333  \n",
       "std                   0.087266          NaN      0.140564       0.093709  \n",
       "min                   0.265253          NaN      0.000000       0.333333  \n",
       "25%                   0.343470          NaN      0.000000       0.966667  \n",
       "50%                   0.385060          NaN      0.000000       1.000000  \n",
       "75%                   0.443687          NaN      0.050000       1.000000  \n",
       "max                   1.000000          NaN      1.000000       1.000000  \n",
       "\n",
       "[8 rows x 34 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in df:\n",
    "    if col not in [\"id\",\"diagnosis\" ]:\n",
    "        df[col]=df[col]/df[col].max()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "      <th>over_average</th>\n",
       "      <th>under_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>0.639986</td>\n",
       "      <td>0.264257</td>\n",
       "      <td>0.651459</td>\n",
       "      <td>0.400240</td>\n",
       "      <td>0.818245</td>\n",
       "      <td>0.803706</td>\n",
       "      <td>0.703140</td>\n",
       "      <td>0.731113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.474612</td>\n",
       "      <td>0.728661</td>\n",
       "      <td>0.629112</td>\n",
       "      <td>0.568610</td>\n",
       "      <td>0.912027</td>\n",
       "      <td>0.693130</td>\n",
       "      <td>0.573012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>0.731768</td>\n",
       "      <td>0.452393</td>\n",
       "      <td>0.705040</td>\n",
       "      <td>0.530188</td>\n",
       "      <td>0.585625</td>\n",
       "      <td>0.227678</td>\n",
       "      <td>0.203608</td>\n",
       "      <td>0.348757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459803</td>\n",
       "      <td>0.556155</td>\n",
       "      <td>0.176371</td>\n",
       "      <td>0.192971</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.414281</td>\n",
       "      <td>0.429012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>0.700462</td>\n",
       "      <td>0.540988</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.481008</td>\n",
       "      <td>0.757429</td>\n",
       "      <td>0.462942</td>\n",
       "      <td>0.462512</td>\n",
       "      <td>0.635686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401740</td>\n",
       "      <td>0.648697</td>\n",
       "      <td>0.401229</td>\n",
       "      <td>0.359744</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.544290</td>\n",
       "      <td>0.422072</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>0.406261</td>\n",
       "      <td>0.518839</td>\n",
       "      <td>0.411565</td>\n",
       "      <td>0.154378</td>\n",
       "      <td>0.984796</td>\n",
       "      <td>0.821946</td>\n",
       "      <td>0.565604</td>\n",
       "      <td>0.522863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133451</td>\n",
       "      <td>0.942498</td>\n",
       "      <td>0.818809</td>\n",
       "      <td>0.548642</td>\n",
       "      <td>0.884880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>0.721807</td>\n",
       "      <td>0.365071</td>\n",
       "      <td>0.716711</td>\n",
       "      <td>0.518593</td>\n",
       "      <td>0.693158</td>\n",
       "      <td>0.384482</td>\n",
       "      <td>0.463918</td>\n",
       "      <td>0.518390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370240</td>\n",
       "      <td>0.617251</td>\n",
       "      <td>0.193762</td>\n",
       "      <td>0.319489</td>\n",
       "      <td>0.558419</td>\n",
       "      <td>0.356131</td>\n",
       "      <td>0.370024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M     0.639986      0.264257        0.651459   0.400240   \n",
       "1    842517         M     0.731768      0.452393        0.705040   0.530188   \n",
       "2  84300903         M     0.700462      0.540988        0.689655   0.481008   \n",
       "3  84348301         M     0.406261      0.518839        0.411565   0.154378   \n",
       "4  84358402         M     0.721807      0.365071        0.716711   0.518593   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0         0.818245          0.803706        0.703140             0.731113   \n",
       "1         0.585625          0.227678        0.203608             0.348757   \n",
       "2         0.757429          0.462942        0.462512             0.635686   \n",
       "3         0.984796          0.821946        0.565604             0.522863   \n",
       "4         0.693158          0.384482        0.463918             0.518390   \n",
       "\n",
       "   ...  area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0  ...    0.474612          0.728661           0.629112         0.568610   \n",
       "1  ...    0.459803          0.556155           0.176371         0.192971   \n",
       "2  ...    0.401740          0.648697           0.401229         0.359744   \n",
       "3  ...    0.133451          0.942498           0.818809         0.548642   \n",
       "4  ...    0.370240          0.617251           0.193762         0.319489   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  Unnamed: 32  \\\n",
       "0              0.912027        0.693130                 0.573012          NaN   \n",
       "1              0.639175        0.414281                 0.429012          NaN   \n",
       "2              0.835052        0.544290                 0.422072          NaN   \n",
       "3              0.884880        1.000000                 0.833735          NaN   \n",
       "4              0.558419        0.356131                 0.370024          NaN   \n",
       "\n",
       "   over_average  under_average  \n",
       "0          0.65       0.566667  \n",
       "1          0.00       1.000000  \n",
       "2          0.05       0.966667  \n",
       "3          0.60       0.600000  \n",
       "4          0.00       1.000000  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malign=df[df[\"diagnosis\"]==\"M\"]\n",
    "malign.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "      <th>over_average</th>\n",
       "      <th>under_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8510426</td>\n",
       "      <td>B</td>\n",
       "      <td>0.481679</td>\n",
       "      <td>0.365580</td>\n",
       "      <td>0.463979</td>\n",
       "      <td>0.226429</td>\n",
       "      <td>0.675812</td>\n",
       "      <td>0.235350</td>\n",
       "      <td>0.156139</td>\n",
       "      <td>0.237624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167184</td>\n",
       "      <td>0.646900</td>\n",
       "      <td>0.167580</td>\n",
       "      <td>0.190895</td>\n",
       "      <td>0.442612</td>\n",
       "      <td>0.448478</td>\n",
       "      <td>0.349831</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8510653</td>\n",
       "      <td>B</td>\n",
       "      <td>0.465315</td>\n",
       "      <td>0.399949</td>\n",
       "      <td>0.454271</td>\n",
       "      <td>0.207917</td>\n",
       "      <td>0.742916</td>\n",
       "      <td>0.367690</td>\n",
       "      <td>0.107029</td>\n",
       "      <td>0.154573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148213</td>\n",
       "      <td>0.589398</td>\n",
       "      <td>0.262382</td>\n",
       "      <td>0.150958</td>\n",
       "      <td>0.250275</td>\n",
       "      <td>0.479663</td>\n",
       "      <td>0.394361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8510824</td>\n",
       "      <td>B</td>\n",
       "      <td>0.338100</td>\n",
       "      <td>0.316701</td>\n",
       "      <td>0.320106</td>\n",
       "      <td>0.109516</td>\n",
       "      <td>0.707671</td>\n",
       "      <td>0.187956</td>\n",
       "      <td>0.069260</td>\n",
       "      <td>0.103181</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074024</td>\n",
       "      <td>0.594789</td>\n",
       "      <td>0.108507</td>\n",
       "      <td>0.070823</td>\n",
       "      <td>0.213986</td>\n",
       "      <td>0.369087</td>\n",
       "      <td>0.374602</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>854941</td>\n",
       "      <td>B</td>\n",
       "      <td>0.463536</td>\n",
       "      <td>0.468941</td>\n",
       "      <td>0.438249</td>\n",
       "      <td>0.209436</td>\n",
       "      <td>0.620802</td>\n",
       "      <td>0.109033</td>\n",
       "      <td>0.060028</td>\n",
       "      <td>0.145278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128326</td>\n",
       "      <td>0.435804</td>\n",
       "      <td>0.043658</td>\n",
       "      <td>0.038602</td>\n",
       "      <td>0.172268</td>\n",
       "      <td>0.299337</td>\n",
       "      <td>0.297301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>85713702</td>\n",
       "      <td>B</td>\n",
       "      <td>0.291569</td>\n",
       "      <td>0.428717</td>\n",
       "      <td>0.274324</td>\n",
       "      <td>0.080728</td>\n",
       "      <td>0.594333</td>\n",
       "      <td>0.172061</td>\n",
       "      <td>0.037207</td>\n",
       "      <td>0.029409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056935</td>\n",
       "      <td>0.582659</td>\n",
       "      <td>0.128261</td>\n",
       "      <td>0.054952</td>\n",
       "      <td>0.088110</td>\n",
       "      <td>0.467761</td>\n",
       "      <td>0.357060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "19   8510426         B     0.481679      0.365580        0.463979   0.226429   \n",
       "20   8510653         B     0.465315      0.399949        0.454271   0.207917   \n",
       "21   8510824         B     0.338100      0.316701        0.320106   0.109516   \n",
       "37    854941         B     0.463536      0.468941        0.438249   0.209436   \n",
       "46  85713702         B     0.291569      0.428717        0.274324   0.080728   \n",
       "\n",
       "    smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "19         0.675812          0.235350        0.156139             0.237624   \n",
       "20         0.742916          0.367690        0.107029             0.154573   \n",
       "21         0.707671          0.187956        0.069260             0.103181   \n",
       "37         0.620802          0.109033        0.060028             0.145278   \n",
       "46         0.594333          0.172061        0.037207             0.029409   \n",
       "\n",
       "    ...  area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "19  ...    0.167184          0.646900           0.167580         0.190895   \n",
       "20  ...    0.148213          0.589398           0.262382         0.150958   \n",
       "21  ...    0.074024          0.594789           0.108507         0.070823   \n",
       "37  ...    0.128326          0.435804           0.043658         0.038602   \n",
       "46  ...    0.056935          0.582659           0.128261         0.054952   \n",
       "\n",
       "    concave points_worst  symmetry_worst  fractal_dimension_worst  \\\n",
       "19              0.442612        0.448478                 0.349831   \n",
       "20              0.250275        0.479663                 0.394361   \n",
       "21              0.213986        0.369087                 0.374602   \n",
       "37              0.172268        0.299337                 0.297301   \n",
       "46              0.088110        0.467761                 0.357060   \n",
       "\n",
       "    Unnamed: 32  over_average  under_average  \n",
       "19          NaN          0.00       1.000000  \n",
       "20          NaN          0.00       1.000000  \n",
       "21          NaN          0.00       1.000000  \n",
       "37          NaN          0.05       0.966667  \n",
       "46          NaN          0.00       1.000000  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benign=df[df[\"diagnosis\"]!=\"M\"]\n",
    "benign.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomut\\AppData\\Local\\Temp/ipykernel_12416/82957682.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  malign.drop([\"id\",\"diagnosis\",\"Unnamed: 32\"],axis=\"columns\", inplace=True)\n",
      "C:\\Users\\tomut\\AppData\\Local\\Temp/ipykernel_12416/82957682.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  benign.drop([\"id\",\"diagnosis\",\"Unnamed: 32\"],axis=\"columns\", inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>over_average</th>\n",
       "      <th>under_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.639986</td>\n",
       "      <td>0.264257</td>\n",
       "      <td>0.651459</td>\n",
       "      <td>0.400240</td>\n",
       "      <td>0.818245</td>\n",
       "      <td>0.803706</td>\n",
       "      <td>0.703140</td>\n",
       "      <td>0.731113</td>\n",
       "      <td>0.795724</td>\n",
       "      <td>0.807779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.734873</td>\n",
       "      <td>0.474612</td>\n",
       "      <td>0.728661</td>\n",
       "      <td>0.629112</td>\n",
       "      <td>0.568610</td>\n",
       "      <td>0.912027</td>\n",
       "      <td>0.693130</td>\n",
       "      <td>0.573012</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.731768</td>\n",
       "      <td>0.452393</td>\n",
       "      <td>0.705040</td>\n",
       "      <td>0.530188</td>\n",
       "      <td>0.585625</td>\n",
       "      <td>0.227678</td>\n",
       "      <td>0.203608</td>\n",
       "      <td>0.348757</td>\n",
       "      <td>0.596053</td>\n",
       "      <td>0.581589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.632166</td>\n",
       "      <td>0.459803</td>\n",
       "      <td>0.556155</td>\n",
       "      <td>0.176371</td>\n",
       "      <td>0.192971</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.414281</td>\n",
       "      <td>0.429012</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.700462</td>\n",
       "      <td>0.540988</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.481008</td>\n",
       "      <td>0.757429</td>\n",
       "      <td>0.462942</td>\n",
       "      <td>0.462512</td>\n",
       "      <td>0.635686</td>\n",
       "      <td>0.680592</td>\n",
       "      <td>0.615661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.607086</td>\n",
       "      <td>0.401740</td>\n",
       "      <td>0.648697</td>\n",
       "      <td>0.401229</td>\n",
       "      <td>0.359744</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.544290</td>\n",
       "      <td>0.422072</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.406261</td>\n",
       "      <td>0.518839</td>\n",
       "      <td>0.411565</td>\n",
       "      <td>0.154378</td>\n",
       "      <td>0.984796</td>\n",
       "      <td>0.821946</td>\n",
       "      <td>0.565604</td>\n",
       "      <td>0.522863</td>\n",
       "      <td>0.854276</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393591</td>\n",
       "      <td>0.133451</td>\n",
       "      <td>0.942498</td>\n",
       "      <td>0.818809</td>\n",
       "      <td>0.548642</td>\n",
       "      <td>0.884880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833735</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.721807</td>\n",
       "      <td>0.365071</td>\n",
       "      <td>0.716711</td>\n",
       "      <td>0.518593</td>\n",
       "      <td>0.693158</td>\n",
       "      <td>0.384482</td>\n",
       "      <td>0.463918</td>\n",
       "      <td>0.518390</td>\n",
       "      <td>0.595066</td>\n",
       "      <td>0.603756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.605892</td>\n",
       "      <td>0.370240</td>\n",
       "      <td>0.617251</td>\n",
       "      <td>0.193762</td>\n",
       "      <td>0.319489</td>\n",
       "      <td>0.558419</td>\n",
       "      <td>0.356131</td>\n",
       "      <td>0.370024</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0     0.639986      0.264257        0.651459   0.400240         0.818245   \n",
       "1     0.731768      0.452393        0.705040   0.530188         0.585625   \n",
       "2     0.700462      0.540988        0.689655   0.481008         0.757429   \n",
       "3     0.406261      0.518839        0.411565   0.154378         0.984796   \n",
       "4     0.721807      0.365071        0.716711   0.518593         0.693158   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0          0.803706        0.703140             0.731113       0.795724   \n",
       "1          0.227678        0.203608             0.348757       0.596053   \n",
       "2          0.462942        0.462512             0.635686       0.680592   \n",
       "3          0.821946        0.565604             0.522863       0.854276   \n",
       "4          0.384482        0.463918             0.518390       0.595066   \n",
       "\n",
       "   fractal_dimension_mean  ...  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0                0.807779  ...         0.734873    0.474612          0.728661   \n",
       "1                0.581589  ...         0.632166    0.459803          0.556155   \n",
       "2                0.615661  ...         0.607086    0.401740          0.648697   \n",
       "3                1.000000  ...         0.393591    0.133451          0.942498   \n",
       "4                0.603756  ...         0.605892    0.370240          0.617251   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0           0.629112         0.568610              0.912027        0.693130   \n",
       "1           0.176371         0.192971              0.639175        0.414281   \n",
       "2           0.401229         0.359744              0.835052        0.544290   \n",
       "3           0.818809         0.548642              0.884880        1.000000   \n",
       "4           0.193762         0.319489              0.558419        0.356131   \n",
       "\n",
       "   fractal_dimension_worst  over_average  under_average  \n",
       "0                 0.573012          0.65       0.566667  \n",
       "1                 0.429012          0.00       1.000000  \n",
       "2                 0.422072          0.05       0.966667  \n",
       "3                 0.833735          0.60       0.600000  \n",
       "4                 0.370024          0.00       1.000000  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malign.drop([\"id\",\"diagnosis\",\"Unnamed: 32\"],axis=\"columns\", inplace=True)\n",
    "benign.drop([\"id\",\"diagnosis\",\"Unnamed: 32\"],axis=\"columns\", inplace=True)\n",
    "malign.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.63998577, 0.26425662, 0.65145889, ..., 0.57301205, 0.65      ,\n",
       "        0.56666667],\n",
       "       [0.73176805, 0.45239308, 0.70503979, ..., 0.42901205, 0.        ,\n",
       "        1.        ],\n",
       "       [0.70046247, 0.54098778, 0.68965517, ..., 0.42207229, 0.05      ,\n",
       "        0.96666667],\n",
       "       ...,\n",
       "       [0.64069726, 0.52342159, 0.62811671, ..., 0.36746988, 0.        ,\n",
       "        1.        ],\n",
       "       [0.65777303, 0.44602851, 0.64350133, ..., 0.45518072, 0.        ,\n",
       "        1.        ],\n",
       "       [0.73247954, 0.5407332 , 0.73103448, ..., 0.43368675, 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data=malign.to_numpy()\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qubits: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n"
     ]
    }
   ],
   "source": [
    "shots = 2500\n",
    "nr_trash=5\n",
    "nr_latent=1\n",
    "nr_ent=0\n",
    "\n",
    "spec = QubitsArrangement(nr_trash, nr_latent, nr_swap=1, nr_ent=nr_ent)\n",
    "print(\"Qubits:\", spec.qubits)\n",
    "\n",
    "#set up the device \n",
    "dev = qml.device(\"default.qubit\", wires=spec.num_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev)\n",
    "def training_circuit_example(init_params, encoder_params, reinit_state):\n",
    "    #initilaization\n",
    "    setAB_amplitude(spec, init_params)\n",
    "\n",
    "    setAux(spec, reinit_state)\n",
    "\n",
    "    setEnt(spec, inputs=[1 / np.sqrt(2), 0, 0, 1 / np.sqrt(2)])\n",
    "\n",
    "    #encoder\n",
    "\n",
    "    for params in encoder_params:\n",
    "        e2_classic(params, [*spec.latent_qubits, *spec.trash_qubits])\n",
    "\n",
    "    #swap test \n",
    "    swap_t(spec)\n",
    "\n",
    "    return [qml.probs(i) for i in spec.swap_qubits]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "learning_rate = 0.0003\n",
    "batch_size = 2\n",
    "num_samples = 0.8 # proportion of the data used for training \n",
    "\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "opt = AdamOptimizer(learning_rate, beta1=beta1, beta2=beta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fid_func(output):\n",
    "    # Implemented as the Fidelity Loss\n",
    "    # output[0] because we take the probability that the state after the \n",
    "    # SWAP test is ket(0), like the reference state\n",
    "    fidelity_loss = 1 / output[0]\n",
    "    return fidelity_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(encoder_params, X):\n",
    "    reinit_state = [0 for i in range(2 ** len(spec.aux_qubits))]\n",
    "    reinit_state[0] = 1.0\n",
    "    loss = 0.0\n",
    "    for x in X:\n",
    "        output = training_circuit_example(init_params=x[0], encoder_params=encoder_params, reinit_state=reinit_state)[0]\n",
    "        f = fid_func(output)\n",
    "        loss = loss + f\n",
    "    return loss / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fidelity(encoder_params, X):\n",
    "    reinit_state = [0 for i in range(2 ** len(spec.aux_qubits))]\n",
    "    reinit_state[0] = 1.0\n",
    "    loss = 0.0\n",
    "    for x in X:\n",
    "        output = training_circuit_example(init_params=x[0], encoder_params=encoder_params, reinit_state=reinit_state)[0]\n",
    "        f = output[0]\n",
    "        loss = loss + f\n",
    "    return loss / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_batches(X, batch_size):\n",
    "    \n",
    "    random.shuffle(X)\n",
    "\n",
    "    batch_list = []\n",
    "    batch = []\n",
    "    for x in X:\n",
    "        if len(batch) < batch_size:\n",
    "            batch.append(x)\n",
    "\n",
    "        else:\n",
    "            batch_list.append(batch)\n",
    "            batch = []\n",
    "    if len(batch) != 0:\n",
    "        batch_list.append(batch)\n",
    "    return batch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomut\\AppData\\Local\\Temp/ipykernel_12416/3998820717.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_new.cpp:201.)\n",
      "  training_data = [ torch.tensor([input_data[i]]) for i in range(int(len(input_data)*num_samples))]\n"
     ]
    }
   ],
   "source": [
    "training_data = [ torch.tensor([input_data[i]]) for i in range(int(len(input_data)*num_samples))]\n",
    "test_data = [torch.tensor([input_data[i]]) for i in range(int(len(input_data)*num_samples),len(input_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6400, 0.2643, 0.6515, 0.4002, 0.8182, 0.8037, 0.7031, 0.7311, 0.7957,\n",
       "         0.8078, 0.3811, 0.1853, 0.3908, 0.2829, 0.2056, 0.3622, 0.1357, 0.3006,\n",
       "         0.3804, 0.2075, 0.7042, 0.3498, 0.7349, 0.4746, 0.7287, 0.6291, 0.5686,\n",
       "         0.9120, 0.6931, 0.5730, 0.6500, 0.5667]], dtype=torch.float64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training = training_data\n",
    "X_tes = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize random encoder parameters\n",
    "nr_encod_qubits = len(spec.trash_qubits) + len(spec.latent_qubits)\n",
    "nr_par_encoder =  15 * int(nr_encod_qubits*(nr_encod_qubits-1)/2)\n",
    "encoder_params = np.random.uniform(size=(1, nr_par_encoder), requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_benign = benign.to_numpy()\n",
    "benign_data = [ torch.tensor([np_benign[i]]) for i in range(len(benign.to_numpy()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomut\\anaconda3\\envs\\qhack2022\\lib\\site-packages\\pennylane\\math\\multi_dispatch.py:63: UserWarning: Contains tensors of types {'autograd', 'torch'}; dispatch will prioritize TensorFlow and PyTorch over autograd. Consider replacing Autograd with vanilla NumPy.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 | Loss:1.7273751908130153 | Fidelity:0.5789664255560416\n",
      "Test-Epoch:0 | Loss:1.7214372084537939 | Fidelity:0.5809385616775634\n",
      "benign fid:0.5693106212970624\n",
      "Epoch:5 | Loss:1.3808033617030286 | Fidelity:0.7243406399291796\n",
      "Test-Epoch:5 | Loss:1.3785847575662726 | Fidelity:0.7254923352917297\n",
      "benign fid:0.7086766241383777\n",
      "Epoch:10 | Loss:1.1988451641195876 | Fidelity:0.8343908284380589\n",
      "Test-Epoch:10 | Loss:1.1971084589155783 | Fidelity:0.8355660249352468\n",
      "benign fid:0.81146196734371\n",
      "Epoch:15 | Loss:1.1201135667659072 | Fidelity:0.8930774072015814\n",
      "Test-Epoch:15 | Loss:1.118442925552247 | Fidelity:0.894378818097351\n",
      "benign fid:0.8645890855353028\n",
      "Epoch:20 | Loss:1.0826238654368927 | Fidelity:0.9240055589551218\n",
      "Test-Epoch:20 | Loss:1.0813905166201014 | Fidelity:0.9250414164698441\n",
      "benign fid:0.8927545379687113\n",
      "Epoch:25 | Loss:1.0662618700017115 | Fidelity:0.9381770721128486\n",
      "Test-Epoch:25 | Loss:1.0652843630915252 | Fidelity:0.9390287659830084\n",
      "benign fid:0.9054329516768281\n",
      "Epoch:30 | Loss:1.057808170487658 | Fidelity:0.9456634110480318\n",
      "Test-Epoch:30 | Loss:1.057159490824525 | Fidelity:0.9462436453892252\n",
      "benign fid:0.9125228841770437\n",
      "Epoch:35 | Loss:1.0528688459688742 | Fidelity:0.9501057636865365\n",
      "Test-Epoch:35 | Loss:1.0524735483175227 | Fidelity:0.9504592479966422\n",
      "benign fid:0.9167497416313437\n",
      "Epoch:40 | Loss:1.0496645571349699 | Fidelity:0.9530081111236464\n",
      "Test-Epoch:40 | Loss:1.0492905859013404 | Fidelity:0.9533480832029821\n",
      "benign fid:0.9194986843416185\n",
      "Epoch:45 | Loss:1.0474458318119302 | Fidelity:0.9550253892575563\n",
      "Test-Epoch:45 | Loss:1.0471606075619995 | Fidelity:0.9552827066575582\n",
      "benign fid:0.9211491184846705\n",
      "Epoch:50 | Loss:1.0457592570416863 | Fidelity:0.9565741756177235\n",
      "Test-Epoch:50 | Loss:1.0453452970165298 | Fidelity:0.9569482031894504\n",
      "benign fid:0.9224966488918541\n",
      "Epoch:55 | Loss:1.0444813154341563 | Fidelity:0.9577481625664305\n",
      "Test-Epoch:55 | Loss:1.0439113914463125 | Fidelity:0.9582608399714405\n",
      "benign fid:0.9230684919699391\n",
      "Epoch:60 | Loss:1.0433522224920633 | Fidelity:0.9588030051091047\n",
      "Test-Epoch:60 | Loss:1.0429583403353893 | Fidelity:0.9591535675524093\n",
      "benign fid:0.9247089371157181\n",
      "Epoch:65 | Loss:1.042400939275744 | Fidelity:0.9596872724924219\n",
      "Test-Epoch:65 | Loss:1.0424031909321188 | Fidelity:0.9596703173148657\n",
      "benign fid:0.926103308386773\n",
      "Epoch:70 | Loss:1.0415832886155827 | Fidelity:0.9604422013825202\n",
      "Test-Epoch:70 | Loss:1.0415785234092432 | Fidelity:0.9604325614269836\n",
      "benign fid:0.9269319952614835\n",
      "Epoch:75 | Loss:1.040816926483807 | Fidelity:0.9611541508335716\n",
      "Test-Epoch:75 | Loss:1.0405594273093801 | Fidelity:0.9613727012573818\n",
      "benign fid:0.926892556301052\n",
      "Epoch:80 | Loss:1.0402406678769054 | Fidelity:0.9616881027101035\n",
      "Test-Epoch:80 | Loss:1.0395901212442358 | Fidelity:0.9622687749627179\n",
      "benign fid:0.9263881943205803\n",
      "Epoch:85 | Loss:1.0395918146154037 | Fidelity:0.9622911057881669\n",
      "Test-Epoch:85 | Loss:1.0391129361590945 | Fidelity:0.9627078446964151\n",
      "benign fid:0.9271795878296468\n",
      "Epoch:90 | Loss:1.0390630710788942 | Fidelity:0.9627941924750891\n",
      "Test-Epoch:90 | Loss:1.0387099059500096 | Fidelity:0.9630950554557501\n",
      "benign fid:0.9283721859515995\n",
      "Epoch:95 | Loss:1.038563317532538 | Fidelity:0.9632593681092518\n",
      "Test-Epoch:95 | Loss:1.0380038573954475 | Fidelity:0.963750268753931\n",
      "benign fid:0.9282090139344896\n",
      "Epoch:100 | Loss:1.0381062126564102 | Fidelity:0.9636969673084271\n",
      "Test-Epoch:100 | Loss:1.0380492763267557 | Fidelity:0.9637175931752716\n",
      "benign fid:0.9299464400697914\n",
      "Epoch:105 | Loss:1.0376787302330344 | Fidelity:0.9640834370717867\n",
      "Test-Epoch:105 | Loss:1.037300705781566 | Fidelity:0.9644003549630505\n",
      "benign fid:0.9292497002406189\n",
      "Epoch:110 | Loss:1.0372605111081188 | Fidelity:0.9644710458557233\n",
      "Test-Epoch:110 | Loss:1.0365243113094964 | Fidelity:0.9651181252772926\n",
      "benign fid:0.9289190479402162\n",
      "Epoch:115 | Loss:1.0368611416507467 | Fidelity:0.9648501221271248\n",
      "Test-Epoch:115 | Loss:1.0367374496464792 | Fidelity:0.9649315203389873\n",
      "benign fid:0.9305306651710696\n",
      "Epoch:120 | Loss:1.0365336176514464 | Fidelity:0.9651664894139438\n",
      "Test-Epoch:120 | Loss:1.0366206484309108 | Fidelity:0.9650547279950233\n",
      "benign fid:0.93169503326343\n",
      "Epoch:125 | Loss:1.0361316247374899 | Fidelity:0.9655239380686168\n",
      "Test-Epoch:125 | Loss:1.0355846732772136 | Fidelity:0.9659974720789639\n",
      "benign fid:0.9304785089805998\n",
      "Epoch:130 | Loss:1.0357929583233116 | Fidelity:0.9658363915893972\n",
      "Test-Epoch:130 | Loss:1.0351261846929893 | Fidelity:0.9664233073331366\n",
      "benign fid:0.9302152636446028\n",
      "Epoch:135 | Loss:1.0354921972560989 | Fidelity:0.9661292918398612\n",
      "Test-Epoch:135 | Loss:1.0354635042190583 | Fidelity:0.9661202860798012\n",
      "benign fid:0.9318675499465192\n",
      "Epoch:140 | Loss:1.0351757512774538 | Fidelity:0.9664157730522481\n",
      "Test-Epoch:140 | Loss:1.0345614417859939 | Fidelity:0.9669498053695343\n",
      "benign fid:0.9311695032840117\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12416/2477346557.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mbatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miterate_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mxbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mencoder_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\qhack2022\\lib\\site-packages\\pennylane\\optimize\\gradient_descent.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, objective_fn, grad_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m         \"\"\"\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrad_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m         \u001b[0mnew_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\qhack2022\\lib\\site-packages\\pennylane\\optimize\\gradient_descent.py\u001b[0m in \u001b[0;36mcompute_grad\u001b[1;34m(objective_fn, args, kwargs, grad_fn)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \"\"\"\n\u001b[0;32m    157\u001b[0m         \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective_fn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mgrad_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m         \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m         \u001b[0mforward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"forward\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\qhack2022\\lib\\site-packages\\pennylane\\_grad.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \"\"\"Evaluates the gradient function, and saves the function value\n\u001b[0;32m    119\u001b[0m         calculated during the forward pass in :attr:`.forward`.\"\"\"\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mgrad_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_grad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mans\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\qhack2022\\lib\\site-packages\\autograd\\wrap_util.py\u001b[0m in \u001b[0;36mnary_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margnum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0munary_operator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munary_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mnary_op_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mnary_op_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnary_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnary_operator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\qhack2022\\lib\\site-packages\\pennylane\\_grad.py\u001b[0m in \u001b[0;36m_grad_with_forward\u001b[1;34m(fun, x)\u001b[0m\n\u001b[0;32m    143\u001b[0m             )\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m         \u001b[0mgrad_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvjp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mans\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\qhack2022\\lib\\site-packages\\autograd\\core.py\u001b[0m in \u001b[0;36mvjp\u001b[1;34m(g)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mvspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[1;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mbackward_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_node\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvjp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\qhack2022\\lib\\site-packages\\autograd\\core.py\u001b[0m in \u001b[0;36mbackward_pass\u001b[1;34m(g, end_node)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mingrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvjp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mparent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mingrad\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mingrads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0moutgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mparent\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madd_outgrads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutgrads\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mingrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\qhack2022\\lib\\site-packages\\autograd\\core.py\u001b[0m in \u001b[0;36madd_outgrads\u001b[1;34m(prev_g_flagged, g)\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msparse_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\qhack2022\\lib\\site-packages\\autograd\\tracer.py\u001b[0m in \u001b[0;36mf_wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m     \u001b[0mf_wrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mf_wrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_autograd_primitive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\qhack2022\\lib\\site-packages\\autograd\\core.py\u001b[0m in \u001b[0;36msparse_add\u001b[1;34m(vs, x_prev, x_new)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mprimitive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msparse_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m     \u001b[0mx_prev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_prev\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx_prev\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mvs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx_new\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmut_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_prev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\qhack2022\\lib\\site-packages\\autograd\\numpy\\numpy_vspaces.py\u001b[0m in \u001b[0;36mzeros\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_hist=[]\n",
    "fid_hist=[]\n",
    "\n",
    "loss_hist_test=[]\n",
    "fid_hist_test=[]\n",
    "\n",
    "benign_fid=[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    batches = iterate_batches(X=training_data, batch_size=batch_size)\n",
    "    for xbatch in batches:\n",
    "        encoder_params = opt.step(cost, encoder_params, X=xbatch)\n",
    "\n",
    "        \n",
    "    if epoch%5 == 0:\n",
    "        \n",
    "        loss_training = cost(encoder_params, X_training )\n",
    "        fidel = fidelity(encoder_params, X_training )\n",
    "        \n",
    "        loss_hist.append(loss_training)\n",
    "        fid_hist.append(fidel)\n",
    "        print(\"Epoch:{} | Loss:{} | Fidelity:{}\".format(epoch, loss_training, fidel))\n",
    "\n",
    "        loss_test = cost(encoder_params, X_tes )\n",
    "        fidel = fidelity(encoder_params, X_tes )\n",
    "        loss_hist_test.append(loss_test)\n",
    "        fid_hist_test.append(fidel)\n",
    "        print(\"Test-Epoch:{} | Loss:{} | Fidelity:{}\".format(epoch, loss_test, fidel))\n",
    "        \n",
    "        b_fidel = fidelity(encoder_params, benign_data )\n",
    "        benign_fid.append(b_fidel)\n",
    "        print(\"benign fid:{}\".format(b_fidel))\n",
    "        \n",
    "        experiment_parameters={\"autoencoder\":\"e2\",\"params\":encoder_params}\n",
    "        f=open(\"Cancer_encoder_e2/params\"+str(epoch)+\".txt\",\"w\")\n",
    "        f.write(str(experiment_parameters))\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rezults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fidelity: 0.9664157730522481\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x for x in range(0,len(loss_hist)*5,5)],np.array(fid_hist),label=\"train fid\")\n",
    "plt.plot([x for x in range(0,len(loss_hist)*5,5)],np.array(fid_hist_test),label=\"test fid\")\n",
    "plt.plot([x for x in range(0,len(loss_hist)*5,5)],np.array(benign_fid),label=\"benign fid\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Malign 5-1-5->compression fidelity e2\",)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"fid\")\n",
    "\n",
    "print(\"fidelity:\",fid_hist[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.0351757512774538\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x for x in range(0,len(loss_hist)*5,5)],np.array(loss_hist),label=\"train loss\")\n",
    "plt.plot([x for x in range(0,len(loss_hist)*5,5)],np.array(loss_hist_test),label=\"test loss\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Malign 5-1-5->compression loss e2\",)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "print(\"loss:\",loss_hist[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benign performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomut\\anaconda3\\envs\\qhack2022\\lib\\site-packages\\pennylane\\math\\multi_dispatch.py:63: UserWarning: Contains tensors of types {'autograd', 'torch'}; dispatch will prioritize TensorFlow and PyTorch over autograd. Consider replacing Autograd with vanilla NumPy.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign results:\n",
      "fidelity= 0.9313349229608994\n",
      "loss= 1.0745954605293035\n"
     ]
    }
   ],
   "source": [
    "np_benign = benign.to_numpy()\n",
    "benign_data = [ torch.tensor([np_benign[i]]) for i in range(len(benign.to_numpy()))]\n",
    "\n",
    "loss = cost(encoder_params, benign_data )\n",
    "fidel = fidelity(encoder_params, benign_data )\n",
    "\n",
    "print(\"Benign results:\")\n",
    "print(\"fidelity=\",fidel)\n",
    "print(\"loss=\",loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifyer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.816784451524773\n",
      "0.9743233354551684\n"
     ]
    }
   ],
   "source": [
    "beningn_flist=[]\n",
    "for b in benign_data:\n",
    "    f=fidelity(encoder_params, [b])\n",
    "    beningn_flist.append(f.item())\n",
    "    \n",
    "print(min(beningn_flist))\n",
    "print(max(beningn_flist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.860764445207524\n",
      "0.9862436684103991\n"
     ]
    }
   ],
   "source": [
    "malign_flist=[]\n",
    "for b in training_data:\n",
    "    f=fidelity(encoder_params, [b])\n",
    "    malign_flist.append(f.item())\n",
    "    \n",
    "print(min(malign_flist))\n",
    "print(max(malign_flist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9596028123375432,\n",
       " 0.9500972638895628,\n",
       " 0.9074262823551371,\n",
       " 0.9177637050373273,\n",
       " 0.8907123927898155,\n",
       " 0.9449190240166081,\n",
       " 0.958709653302523,\n",
       " 0.9198850019087332,\n",
       " 0.9425919953025527,\n",
       " 0.9256056085770665,\n",
       " 0.9268031757167963,\n",
       " 0.907090314951327,\n",
       " 0.8822113869372217,\n",
       " 0.8918694703439165,\n",
       " 0.8941817421740431,\n",
       " 0.9061584907794715,\n",
       " 0.9109153234954073,\n",
       " 0.9297238025361576,\n",
       " 0.8625013671469068,\n",
       " 0.9300510793755772,\n",
       " 0.8569337976845643,\n",
       " 0.9483949164760108,\n",
       " 0.9291357396327884,\n",
       " 0.9524773018725703,\n",
       " 0.9291962061631008,\n",
       " 0.967159345797626,\n",
       " 0.9430289326527069,\n",
       " 0.9597724277800103,\n",
       " 0.9710812080351726,\n",
       " 0.9519874533935657,\n",
       " 0.9501289650278044,\n",
       " 0.952290723195439,\n",
       " 0.9284355975736769,\n",
       " 0.8864736725566481,\n",
       " 0.9379109483713941,\n",
       " 0.8525076474886399,\n",
       " 0.926950062112587,\n",
       " 0.937828556426188,\n",
       " 0.9179723628045368,\n",
       " 0.950854667468334,\n",
       " 0.940611090233177,\n",
       " 0.9350713626741366,\n",
       " 0.9146772659520424,\n",
       " 0.9522201901226397,\n",
       " 0.9364457038920324,\n",
       " 0.9258987668211593,\n",
       " 0.9136606204796582,\n",
       " 0.9411287971446547,\n",
       " 0.8854618798015765,\n",
       " 0.932680342758135,\n",
       " 0.9604148408792076,\n",
       " 0.956759557626843,\n",
       " 0.9331589853585491,\n",
       " 0.9661452054774221,\n",
       " 0.9403811087738096,\n",
       " 0.9690885214335772,\n",
       " 0.9279584069393396,\n",
       " 0.9399222434888315,\n",
       " 0.9289459441629682,\n",
       " 0.8711286053777652,\n",
       " 0.9308626232453558,\n",
       " 0.9577079990635191,\n",
       " 0.9185168750927191,\n",
       " 0.9263401430378096,\n",
       " 0.9618551629568377,\n",
       " 0.9698254383090084,\n",
       " 0.9434951709300761,\n",
       " 0.9348724370573989,\n",
       " 0.907280969279644,\n",
       " 0.8195714147311117,\n",
       " 0.9137826464862667,\n",
       " 0.9574476746831582,\n",
       " 0.9453368441910721,\n",
       " 0.9577317497093683,\n",
       " 0.9279056749119359,\n",
       " 0.9063969056551165,\n",
       " 0.9485606502290651,\n",
       " 0.9435962305290599,\n",
       " 0.9369782728686171,\n",
       " 0.9012674449845424,\n",
       " 0.9523188950662688,\n",
       " 0.9375075458672775,\n",
       " 0.8980041846301874,\n",
       " 0.8794057616874851,\n",
       " 0.8637300966663346,\n",
       " 0.8965721973601687,\n",
       " 0.8881089448063544,\n",
       " 0.9084046732624338,\n",
       " 0.9330226974445626,\n",
       " 0.8870506145110579,\n",
       " 0.9405336436188539,\n",
       " 0.9163492662554464,\n",
       " 0.9395753880946003,\n",
       " 0.9286010296049665,\n",
       " 0.816784451524773,\n",
       " 0.9469976828474831,\n",
       " 0.9538868124456253,\n",
       " 0.963073198855572,\n",
       " 0.910754583563002,\n",
       " 0.9632161091159778,\n",
       " 0.9538706244502446,\n",
       " 0.9385991256269891,\n",
       " 0.9562284082464465,\n",
       " 0.921625971942838,\n",
       " 0.9457700984730063,\n",
       " 0.9593808304458111,\n",
       " 0.9168633970321418,\n",
       " 0.9494711455475446,\n",
       " 0.9602380807032396,\n",
       " 0.9080784860609462,\n",
       " 0.9703944435182886,\n",
       " 0.954870173646735,\n",
       " 0.8993424202015714,\n",
       " 0.8859383683940347,\n",
       " 0.9036817191528438,\n",
       " 0.9406126381510198,\n",
       " 0.9546087960166258,\n",
       " 0.9517641551087928,\n",
       " 0.9134912065406784,\n",
       " 0.9417893433101805,\n",
       " 0.9483456390573658,\n",
       " 0.9109809520410115,\n",
       " 0.9351262941401092,\n",
       " 0.9445762638585058,\n",
       " 0.9199619363588997,\n",
       " 0.9424267218874123,\n",
       " 0.9328691262851585,\n",
       " 0.9447966588270995,\n",
       " 0.9474726957079347,\n",
       " 0.9406442002700213,\n",
       " 0.9403327573394091,\n",
       " 0.909294743891017,\n",
       " 0.9316634457260791,\n",
       " 0.8995790909360741,\n",
       " 0.9239435695060982,\n",
       " 0.8937201117069613,\n",
       " 0.9292453441956117,\n",
       " 0.9549514055033048,\n",
       " 0.928246520461542,\n",
       " 0.9589042373002683,\n",
       " 0.9025452072125655,\n",
       " 0.9528427256298933,\n",
       " 0.9240333046496719,\n",
       " 0.9094574505155861,\n",
       " 0.9222077335132992,\n",
       " 0.9070507883809086,\n",
       " 0.9730062170115441,\n",
       " 0.94933663096502,\n",
       " 0.9406521890525574,\n",
       " 0.9308953219911452,\n",
       " 0.9309508760198886,\n",
       " 0.9024092556386489,\n",
       " 0.9445223124670543,\n",
       " 0.9043791394776821,\n",
       " 0.9551016179017385,\n",
       " 0.913394403443787,\n",
       " 0.9359200268570843,\n",
       " 0.918712586362777,\n",
       " 0.913728230161432,\n",
       " 0.8734717728128286,\n",
       " 0.9062483818479676,\n",
       " 0.9155391762702829,\n",
       " 0.922093605946453,\n",
       " 0.9323313018288883,\n",
       " 0.9501137077830124,\n",
       " 0.9137162896734754,\n",
       " 0.8307295708500995,\n",
       " 0.9017439887665533,\n",
       " 0.9023632641662042,\n",
       " 0.926064195034484,\n",
       " 0.9029360840551387,\n",
       " 0.9338011098605865,\n",
       " 0.9463526434377659,\n",
       " 0.9357201827148574,\n",
       " 0.9340851115722758,\n",
       " 0.9325243223820046,\n",
       " 0.9055421573810831,\n",
       " 0.960574484644737,\n",
       " 0.8954466095863683,\n",
       " 0.9021820161328282,\n",
       " 0.9147692941388061,\n",
       " 0.9340475217631542,\n",
       " 0.9207256500422298,\n",
       " 0.9743233354551684,\n",
       " 0.935023736295602,\n",
       " 0.9415344181813895,\n",
       " 0.9299854347419612,\n",
       " 0.8956429290558874,\n",
       " 0.9246650604107682,\n",
       " 0.9626280487843477,\n",
       " 0.9219053024607526,\n",
       " 0.9261209968395511,\n",
       " 0.9157512898138367,\n",
       " 0.9231102930301296,\n",
       " 0.9543301323242654,\n",
       " 0.964282444960313,\n",
       " 0.9328794219279894,\n",
       " 0.9114975275747603,\n",
       " 0.9150044753857042,\n",
       " 0.9024694057120173,\n",
       " 0.9419817246031277,\n",
       " 0.9455509537798099,\n",
       " 0.9633802171130985,\n",
       " 0.939747332021018,\n",
       " 0.9502988707472433,\n",
       " 0.9489145418207825,\n",
       " 0.9447532651943948,\n",
       " 0.9678323784396747,\n",
       " 0.9153718266292247,\n",
       " 0.9233017687654267,\n",
       " 0.954805092557849,\n",
       " 0.9476186252524317,\n",
       " 0.9351678019496096,\n",
       " 0.9472256644987279,\n",
       " 0.9547500914694957,\n",
       " 0.9569839307580021,\n",
       " 0.9538081881792883,\n",
       " 0.9326176762819969,\n",
       " 0.9253544776300848,\n",
       " 0.9183450264868529,\n",
       " 0.8678579725335195,\n",
       " 0.9432072680259671,\n",
       " 0.9431857271779415,\n",
       " 0.9676274457951042,\n",
       " 0.9578534347869426,\n",
       " 0.9246493153062182,\n",
       " 0.9365863983790819,\n",
       " 0.9331968192366732,\n",
       " 0.949080679573532,\n",
       " 0.9468817684983432,\n",
       " 0.9217383232989647,\n",
       " 0.936831957989015,\n",
       " 0.9629843983126216,\n",
       " 0.9433740865330544,\n",
       " 0.9483154127606004,\n",
       " 0.9309399921094411,\n",
       " 0.9314618795628471,\n",
       " 0.9048161815113953,\n",
       " 0.973729146822954,\n",
       " 0.9399639044387056,\n",
       " 0.8931737496305573,\n",
       " 0.9348211211835136,\n",
       " 0.9137767595954253,\n",
       " 0.9431356378688966,\n",
       " 0.9671688108216993,\n",
       " 0.9518922595122827,\n",
       " 0.9725406490719433,\n",
       " 0.9055729957350447,\n",
       " 0.8915854755324305,\n",
       " 0.9442611689776917,\n",
       " 0.9344981160506663,\n",
       " 0.9084607932916425,\n",
       " 0.9225198708993723,\n",
       " 0.947289710188701,\n",
       " 0.9521339218253633,\n",
       " 0.9410600617221119,\n",
       " 0.949324227480385,\n",
       " 0.9383353884667281,\n",
       " 0.9400122899297572,\n",
       " 0.9538471913029516,\n",
       " 0.9222520032892548,\n",
       " 0.892499376597896,\n",
       " 0.9484329298125942,\n",
       " 0.9554986600233577,\n",
       " 0.9661774763269675,\n",
       " 0.9408160033781623,\n",
       " 0.9341394875900275,\n",
       " 0.9561935021829651,\n",
       " 0.9439043485978538,\n",
       " 0.9315047865665773,\n",
       " 0.9358132179155252,\n",
       " 0.9290424144022784,\n",
       " 0.9249985386060432,\n",
       " 0.9005831584154809,\n",
       " 0.9340512310972773,\n",
       " 0.9393159576244168,\n",
       " 0.9527168546754823,\n",
       " 0.9529583400374662,\n",
       " 0.9687313891959037,\n",
       " 0.9004153487232799,\n",
       " 0.9513682209700741,\n",
       " 0.9231582171127652,\n",
       " 0.9230940605433318,\n",
       " 0.9638927815852201,\n",
       " 0.8677389359952101,\n",
       " 0.9348107783648114,\n",
       " 0.9547466765435759,\n",
       " 0.9713862943862325,\n",
       " 0.9386402537482221,\n",
       " 0.9398009083810153,\n",
       " 0.9384200997341188,\n",
       " 0.9474118247113326,\n",
       " 0.9562103455928783,\n",
       " 0.9509076546769553,\n",
       " 0.9618007988948352,\n",
       " 0.9477076298163376,\n",
       " 0.956039911285619,\n",
       " 0.9422948061392735,\n",
       " 0.9317005020208944,\n",
       " 0.9453193832069003,\n",
       " 0.903403248809326,\n",
       " 0.9321116234647165,\n",
       " 0.9602181675326129,\n",
       " 0.9621279438195502,\n",
       " 0.951839814228018]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beningn_flist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(beningn_flist, bins = 100 ,label=\"benign\", color = \"skyblue\",alpha=0.4)\n",
    "plt.hist(malign_flist, bins =100 ,label=\"malign\",color = \"red\",alpha=0.4)\n",
    "plt.title(\"Compression fidelity\",)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split: 0.96\n",
      "benign classification accuracy: 0.9016393442622951\n",
      "malign classification accuracy: 0.8076923076923077\n",
      "total accuracy: 0.8698481561822126\n"
     ]
    }
   ],
   "source": [
    "split=0.96\n",
    "\n",
    "\n",
    "print(\"split:\",split)\n",
    "b_e=[]\n",
    "for i in beningn_flist:\n",
    "    if i<split:\n",
    "        b_e.append(1)\n",
    "    else:\n",
    "        b_e.append(0)\n",
    "ab_ac=sum(b_e)/len(b_e)\n",
    "print(\"benign classification accuracy:\",ab_ac)\n",
    "m_e=[]\n",
    "for i in malign_flist:\n",
    "    if i>split:\n",
    "        m_e.append(1)\n",
    "    else:\n",
    "        m_e.append(0)\n",
    "am_ac=sum(m_e)/len(m_e)\n",
    "print(\"malign classification accuracy:\",am_ac)\n",
    "t_ac=(sum(b_e)+sum(m_e))/(len(b_e)+len(m_e))\n",
    "print(\"total accuracy:\",t_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
