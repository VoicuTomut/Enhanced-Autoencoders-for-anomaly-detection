{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomut\\anaconda3\\envs\\qhack2022\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\tomut\\anaconda3\\envs\\qhack2022\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from graphs import plot_correlation_matrix\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "#quanutm lib\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "\n",
    "from pennylane.optimize import AdamOptimizer\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path\n",
    "\n",
    "from qencode.initialize import setAB_amplitude, setAux, setEnt\n",
    "from qencode.encoders import e5_patch\n",
    "from qencode.training_circuits import swap_t\n",
    "from qencode.qubits_arrangement import QubitsArrangement\n",
    "\n",
    "from qencode.utils.mnist import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"cancer.csv\", nrows=500)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## malign and benign aee reverted !!!!!!!!!!!!!\n",
    "\n",
    "diagnosis=[]\n",
    "for d in df.diagnosis:\n",
    "    if d==\"M\":\n",
    "        diagnosis.append(1.0)\n",
    "    else:\n",
    "        diagnosis.append(0.0)\n",
    "df[\"diagnosis\"]=diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malign:  305\n",
      "Benign:  195\n"
     ]
    }
   ],
   "source": [
    "print('Malign: ', df['diagnosis'].value_counts()[0])\n",
    "print('Benign: ', df['diagnosis'].value_counts()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       500 non-null    int64  \n",
      " 1   diagnosis                500 non-null    float64\n",
      " 2   radius_mean              500 non-null    float64\n",
      " 3   texture_mean             500 non-null    float64\n",
      " 4   perimeter_mean           500 non-null    float64\n",
      " 5   area_mean                500 non-null    float64\n",
      " 6   smoothness_mean          500 non-null    float64\n",
      " 7   compactness_mean         500 non-null    float64\n",
      " 8   concavity_mean           500 non-null    float64\n",
      " 9   concave points_mean      500 non-null    float64\n",
      " 10  symmetry_mean            500 non-null    float64\n",
      " 11  fractal_dimension_mean   500 non-null    float64\n",
      " 12  radius_se                500 non-null    float64\n",
      " 13  texture_se               500 non-null    float64\n",
      " 14  perimeter_se             500 non-null    float64\n",
      " 15  area_se                  500 non-null    float64\n",
      " 16  smoothness_se            500 non-null    float64\n",
      " 17  compactness_se           500 non-null    float64\n",
      " 18  concavity_se             500 non-null    float64\n",
      " 19  concave points_se        500 non-null    float64\n",
      " 20  symmetry_se              500 non-null    float64\n",
      " 21  fractal_dimension_se     500 non-null    float64\n",
      " 22  radius_worst             500 non-null    float64\n",
      " 23  texture_worst            500 non-null    float64\n",
      " 24  perimeter_worst          500 non-null    float64\n",
      " 25  area_worst               500 non-null    float64\n",
      " 26  smoothness_worst         500 non-null    float64\n",
      " 27  compactness_worst        500 non-null    float64\n",
      " 28  concavity_worst          500 non-null    float64\n",
      " 29  concave points_worst     500 non-null    float64\n",
      " 30  symmetry_worst           500 non-null    float64\n",
      " 31  fractal_dimension_worst  500 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(32), int64(1)\n",
      "memory usage: 129.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.263049e+07</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>14.224206</td>\n",
       "      <td>19.086320</td>\n",
       "      <td>92.606620</td>\n",
       "      <td>662.844800</td>\n",
       "      <td>0.095978</td>\n",
       "      <td>0.103948</td>\n",
       "      <td>0.089941</td>\n",
       "      <td>0.049446</td>\n",
       "      <td>...</td>\n",
       "      <td>25.508500</td>\n",
       "      <td>108.258320</td>\n",
       "      <td>896.003200</td>\n",
       "      <td>0.131972</td>\n",
       "      <td>0.256324</td>\n",
       "      <td>0.276420</td>\n",
       "      <td>0.115980</td>\n",
       "      <td>0.292212</td>\n",
       "      <td>0.083778</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.326933e+08</td>\n",
       "      <td>0.488238</td>\n",
       "      <td>3.476809</td>\n",
       "      <td>4.164842</td>\n",
       "      <td>23.983476</td>\n",
       "      <td>349.357241</td>\n",
       "      <td>0.013666</td>\n",
       "      <td>0.053096</td>\n",
       "      <td>0.080259</td>\n",
       "      <td>0.038875</td>\n",
       "      <td>...</td>\n",
       "      <td>6.063133</td>\n",
       "      <td>33.312706</td>\n",
       "      <td>571.074422</td>\n",
       "      <td>0.022739</td>\n",
       "      <td>0.159147</td>\n",
       "      <td>0.209012</td>\n",
       "      <td>0.065896</td>\n",
       "      <td>0.063366</td>\n",
       "      <td>0.018108</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.062510</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.667040e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.807500</td>\n",
       "      <td>16.070000</td>\n",
       "      <td>75.995000</td>\n",
       "      <td>430.550000</td>\n",
       "      <td>0.085992</td>\n",
       "      <td>0.063622</td>\n",
       "      <td>0.028885</td>\n",
       "      <td>0.020245</td>\n",
       "      <td>...</td>\n",
       "      <td>21.017500</td>\n",
       "      <td>84.567500</td>\n",
       "      <td>522.600000</td>\n",
       "      <td>0.116200</td>\n",
       "      <td>0.145925</td>\n",
       "      <td>0.114475</td>\n",
       "      <td>0.063302</td>\n",
       "      <td>0.251700</td>\n",
       "      <td>0.071270</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.014320e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.435000</td>\n",
       "      <td>18.680000</td>\n",
       "      <td>86.735000</td>\n",
       "      <td>556.150000</td>\n",
       "      <td>0.095825</td>\n",
       "      <td>0.091280</td>\n",
       "      <td>0.064315</td>\n",
       "      <td>0.033870</td>\n",
       "      <td>...</td>\n",
       "      <td>25.240000</td>\n",
       "      <td>97.980000</td>\n",
       "      <td>691.750000</td>\n",
       "      <td>0.131250</td>\n",
       "      <td>0.214850</td>\n",
       "      <td>0.231400</td>\n",
       "      <td>0.100650</td>\n",
       "      <td>0.283100</td>\n",
       "      <td>0.079900</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.910808e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.115000</td>\n",
       "      <td>21.562500</td>\n",
       "      <td>106.225000</td>\n",
       "      <td>800.775000</td>\n",
       "      <td>0.105100</td>\n",
       "      <td>0.130500</td>\n",
       "      <td>0.132150</td>\n",
       "      <td>0.074928</td>\n",
       "      <td>...</td>\n",
       "      <td>29.350000</td>\n",
       "      <td>127.150000</td>\n",
       "      <td>1150.750000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.343525</td>\n",
       "      <td>0.389450</td>\n",
       "      <td>0.166850</td>\n",
       "      <td>0.320050</td>\n",
       "      <td>0.092065</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.144700</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id   diagnosis  radius_mean  texture_mean  perimeter_mean  \\\n",
       "count  5.000000e+02  500.000000   500.000000    500.000000      500.000000   \n",
       "mean   3.263049e+07    0.390000    14.224206     19.086320       92.606620   \n",
       "std    1.326933e+08    0.488238     3.476809      4.164842       23.983476   \n",
       "min    8.670000e+03    0.000000     6.981000      9.710000       43.790000   \n",
       "25%    8.667040e+05    0.000000    11.807500     16.070000       75.995000   \n",
       "50%    9.014320e+05    0.000000    13.435000     18.680000       86.735000   \n",
       "75%    8.910808e+06    1.000000    16.115000     21.562500      106.225000   \n",
       "max    9.113205e+08    1.000000    28.110000     39.280000      188.500000   \n",
       "\n",
       "         area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "count   500.000000       500.000000        500.000000      500.000000   \n",
       "mean    662.844800         0.095978          0.103948        0.089941   \n",
       "std     349.357241         0.013666          0.053096        0.080259   \n",
       "min     143.500000         0.062510          0.019380        0.000000   \n",
       "25%     430.550000         0.085992          0.063622        0.028885   \n",
       "50%     556.150000         0.095825          0.091280        0.064315   \n",
       "75%     800.775000         0.105100          0.130500        0.132150   \n",
       "max    2501.000000         0.144700          0.345400        0.426800   \n",
       "\n",
       "       concave points_mean  ...  texture_worst  perimeter_worst   area_worst  \\\n",
       "count           500.000000  ...     500.000000       500.000000   500.000000   \n",
       "mean              0.049446  ...      25.508500       108.258320   896.003200   \n",
       "std               0.038875  ...       6.063133        33.312706   571.074422   \n",
       "min               0.000000  ...      12.020000        50.410000   185.200000   \n",
       "25%               0.020245  ...      21.017500        84.567500   522.600000   \n",
       "50%               0.033870  ...      25.240000        97.980000   691.750000   \n",
       "75%               0.074928  ...      29.350000       127.150000  1150.750000   \n",
       "max               0.201200  ...      49.540000       251.200000  4254.000000   \n",
       "\n",
       "       smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "count        500.000000         500.000000       500.000000   \n",
       "mean           0.131972           0.256324         0.276420   \n",
       "std            0.022739           0.159147         0.209012   \n",
       "min            0.071170           0.027290         0.000000   \n",
       "25%            0.116200           0.145925         0.114475   \n",
       "50%            0.131250           0.214850         0.231400   \n",
       "75%            0.146000           0.343525         0.389450   \n",
       "max            0.222600           1.058000         1.252000   \n",
       "\n",
       "       concave points_worst  symmetry_worst  fractal_dimension_worst  \\\n",
       "count            500.000000      500.000000               500.000000   \n",
       "mean               0.115980        0.292212                 0.083778   \n",
       "std                0.065896        0.063366                 0.018108   \n",
       "min                0.000000        0.156500                 0.055040   \n",
       "25%                0.063302        0.251700                 0.071270   \n",
       "50%                0.100650        0.283100                 0.079900   \n",
       "75%                0.166850        0.320050                 0.092065   \n",
       "max                0.291000        0.663800                 0.207500   \n",
       "\n",
       "       Unnamed: 32  \n",
       "count          0.0  \n",
       "mean           NaN  \n",
       "std            NaN  \n",
       "min            NaN  \n",
       "25%            NaN  \n",
       "50%            NaN  \n",
       "75%            NaN  \n",
       "max            NaN  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data seams pretty clean  without any nan value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "      <th>over_average</th>\n",
       "      <th>under_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302        1.0        17.99         10.38          122.80     1001.0   \n",
       "1    842517        1.0        20.57         17.77          132.90     1326.0   \n",
       "2  84300903        1.0        19.69         21.25          130.00     1203.0   \n",
       "3  84348301        1.0        11.42         20.38           77.58      386.1   \n",
       "4  84358402        1.0        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0  ...      2019.0            0.1622             0.6656           0.7119   \n",
       "1  ...      1956.0            0.1238             0.1866           0.2416   \n",
       "2  ...      1709.0            0.1444             0.4245           0.4504   \n",
       "3  ...       567.7            0.2098             0.8663           0.6869   \n",
       "4  ...      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  Unnamed: 32  \\\n",
       "0                0.2654          0.4601                  0.11890          NaN   \n",
       "1                0.1860          0.2750                  0.08902          NaN   \n",
       "2                0.2430          0.3613                  0.08758          NaN   \n",
       "3                0.2575          0.6638                  0.17300          NaN   \n",
       "4                0.1625          0.2364                  0.07678          NaN   \n",
       "\n",
       "   over_average  under_average  \n",
       "0            13             17  \n",
       "1             0             30  \n",
       "2             1             29  \n",
       "3            12             18  \n",
       "4             0             30  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## engineering two new features to have 32 feutures that can be encoded om 5 qubits.\n",
    "over_average = []\n",
    "under_average = []\n",
    "\n",
    "mean = {}\n",
    "std = {}\n",
    "for col in df:\n",
    "     if col not in [\"id\",\"diagnosis\" ]:\n",
    "        mean[col]=df[col].mean()\n",
    "        std[col]=df[col].std()\n",
    "\n",
    "for index,row in df.iterrows():\n",
    "    o_average=0\n",
    "    u_average=0\n",
    "    for col in df:\n",
    "        if col not in [\"id\",\"diagnosis\" ]:\n",
    "            if  row[col]> mean[col]+2* std[col]:\n",
    "                o_average = o_average + 1\n",
    "            if  row[col]< mean[col]+2* std[col]:\n",
    "                u_average= u_average + 1\n",
    "                \n",
    "    over_average.append(o_average)\n",
    "    under_average.append(u_average)\n",
    "\n",
    "df[\"over_average\"] = over_average\n",
    "df[\"under_average\"] = under_average\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "      <th>over_average</th>\n",
       "      <th>under_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>903516</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.61</td>\n",
       "      <td>22.28</td>\n",
       "      <td>144.40</td>\n",
       "      <td>1407.0</td>\n",
       "      <td>0.11670</td>\n",
       "      <td>0.20870</td>\n",
       "      <td>0.28100</td>\n",
       "      <td>0.15620</td>\n",
       "      <td>...</td>\n",
       "      <td>2081.0</td>\n",
       "      <td>0.15020</td>\n",
       "      <td>0.5717</td>\n",
       "      <td>0.70530</td>\n",
       "      <td>0.24220</td>\n",
       "      <td>0.3828</td>\n",
       "      <td>0.10070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>871641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.08</td>\n",
       "      <td>14.71</td>\n",
       "      <td>70.21</td>\n",
       "      <td>372.7</td>\n",
       "      <td>0.10060</td>\n",
       "      <td>0.05743</td>\n",
       "      <td>0.02363</td>\n",
       "      <td>0.02583</td>\n",
       "      <td>...</td>\n",
       "      <td>396.5</td>\n",
       "      <td>0.12160</td>\n",
       "      <td>0.0824</td>\n",
       "      <td>0.03938</td>\n",
       "      <td>0.04306</td>\n",
       "      <td>0.1902</td>\n",
       "      <td>0.07313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>869104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.11</td>\n",
       "      <td>18.05</td>\n",
       "      <td>105.10</td>\n",
       "      <td>813.0</td>\n",
       "      <td>0.09721</td>\n",
       "      <td>0.11370</td>\n",
       "      <td>0.09447</td>\n",
       "      <td>0.05943</td>\n",
       "      <td>...</td>\n",
       "      <td>1233.0</td>\n",
       "      <td>0.13140</td>\n",
       "      <td>0.2236</td>\n",
       "      <td>0.28020</td>\n",
       "      <td>0.12160</td>\n",
       "      <td>0.2792</td>\n",
       "      <td>0.08158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>897880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.05</td>\n",
       "      <td>17.53</td>\n",
       "      <td>64.41</td>\n",
       "      <td>310.8</td>\n",
       "      <td>0.10070</td>\n",
       "      <td>0.07326</td>\n",
       "      <td>0.02511</td>\n",
       "      <td>0.01775</td>\n",
       "      <td>...</td>\n",
       "      <td>384.0</td>\n",
       "      <td>0.14020</td>\n",
       "      <td>0.1402</td>\n",
       "      <td>0.10550</td>\n",
       "      <td>0.06499</td>\n",
       "      <td>0.2894</td>\n",
       "      <td>0.07664</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>88411702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.75</td>\n",
       "      <td>23.77</td>\n",
       "      <td>88.54</td>\n",
       "      <td>590.0</td>\n",
       "      <td>0.08043</td>\n",
       "      <td>0.06807</td>\n",
       "      <td>0.04697</td>\n",
       "      <td>0.02344</td>\n",
       "      <td>...</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.09368</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.13590</td>\n",
       "      <td>0.06106</td>\n",
       "      <td>0.2663</td>\n",
       "      <td>0.06321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  diagnosis  radius_mean  texture_mean  perimeter_mean  \\\n",
       "393    903516        1.0        21.61         22.28          144.40   \n",
       "173    871641        0.0        11.08         14.71           70.21   \n",
       "141    869104        1.0        16.11         18.05          105.10   \n",
       "338    897880        0.0        10.05         17.53           64.41   \n",
       "243  88411702        0.0        13.75         23.77           88.54   \n",
       "\n",
       "     area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "393     1407.0          0.11670           0.20870         0.28100   \n",
       "173      372.7          0.10060           0.05743         0.02363   \n",
       "141      813.0          0.09721           0.11370         0.09447   \n",
       "338      310.8          0.10070           0.07326         0.02511   \n",
       "243      590.0          0.08043           0.06807         0.04697   \n",
       "\n",
       "     concave points_mean  ...  area_worst  smoothness_worst  \\\n",
       "393              0.15620  ...      2081.0           0.15020   \n",
       "173              0.02583  ...       396.5           0.12160   \n",
       "141              0.05943  ...      1233.0           0.13140   \n",
       "338              0.01775  ...       384.0           0.14020   \n",
       "243              0.02344  ...       706.0           0.09368   \n",
       "\n",
       "     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "393             0.5717          0.70530               0.24220          0.3828   \n",
       "173             0.0824          0.03938               0.04306          0.1902   \n",
       "141             0.2236          0.28020               0.12160          0.2792   \n",
       "338             0.1402          0.10550               0.06499          0.2894   \n",
       "243             0.1442          0.13590               0.06106          0.2663   \n",
       "\n",
       "     fractal_dimension_worst  Unnamed: 32  over_average  under_average  \n",
       "393                  0.10070          NaN             8             22  \n",
       "173                  0.07313          NaN             1             29  \n",
       "141                  0.08158          NaN             0             30  \n",
       "338                  0.07664          NaN             0             30  \n",
       "243                  0.06321          NaN             0             30  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1)\n",
    "fraud_df = df.loc[df['diagnosis'] == 0]\n",
    "non_fraud_df = df.loc[df['diagnosis'] == 1][:195]\n",
    "normal_distributed_df = pd.concat([fraud_df, non_fraud_df])\n",
    "sub_sample_df = normal_distributed_df.sample(frac=1, random_state=42)\n",
    "\n",
    "sub_sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_sample_corr = sub_sample_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "      <th>over_average</th>\n",
       "      <th>under_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.263049e+07</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.506019</td>\n",
       "      <td>0.485904</td>\n",
       "      <td>0.491282</td>\n",
       "      <td>0.265032</td>\n",
       "      <td>0.663292</td>\n",
       "      <td>0.300949</td>\n",
       "      <td>0.210733</td>\n",
       "      <td>0.245754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.210626</td>\n",
       "      <td>0.592867</td>\n",
       "      <td>0.242273</td>\n",
       "      <td>0.220783</td>\n",
       "      <td>0.398557</td>\n",
       "      <td>0.440211</td>\n",
       "      <td>0.403749</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.326933e+08</td>\n",
       "      <td>0.488238</td>\n",
       "      <td>0.123686</td>\n",
       "      <td>0.106030</td>\n",
       "      <td>0.127233</td>\n",
       "      <td>0.139687</td>\n",
       "      <td>0.094446</td>\n",
       "      <td>0.153722</td>\n",
       "      <td>0.188047</td>\n",
       "      <td>0.193216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134244</td>\n",
       "      <td>0.102153</td>\n",
       "      <td>0.150423</td>\n",
       "      <td>0.166943</td>\n",
       "      <td>0.226448</td>\n",
       "      <td>0.095459</td>\n",
       "      <td>0.087266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.140564</td>\n",
       "      <td>0.093709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.248346</td>\n",
       "      <td>0.247200</td>\n",
       "      <td>0.232308</td>\n",
       "      <td>0.057377</td>\n",
       "      <td>0.431997</td>\n",
       "      <td>0.056109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043535</td>\n",
       "      <td>0.319721</td>\n",
       "      <td>0.025794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235764</td>\n",
       "      <td>0.265253</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.667040e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420046</td>\n",
       "      <td>0.409114</td>\n",
       "      <td>0.403156</td>\n",
       "      <td>0.172151</td>\n",
       "      <td>0.594281</td>\n",
       "      <td>0.184199</td>\n",
       "      <td>0.067678</td>\n",
       "      <td>0.100621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122849</td>\n",
       "      <td>0.522013</td>\n",
       "      <td>0.137925</td>\n",
       "      <td>0.091434</td>\n",
       "      <td>0.217534</td>\n",
       "      <td>0.379180</td>\n",
       "      <td>0.343470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.014320e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.477944</td>\n",
       "      <td>0.475560</td>\n",
       "      <td>0.460133</td>\n",
       "      <td>0.222371</td>\n",
       "      <td>0.662232</td>\n",
       "      <td>0.264273</td>\n",
       "      <td>0.150691</td>\n",
       "      <td>0.168340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162612</td>\n",
       "      <td>0.589623</td>\n",
       "      <td>0.203072</td>\n",
       "      <td>0.184824</td>\n",
       "      <td>0.345876</td>\n",
       "      <td>0.426484</td>\n",
       "      <td>0.385060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.910808e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.573284</td>\n",
       "      <td>0.548943</td>\n",
       "      <td>0.563528</td>\n",
       "      <td>0.320182</td>\n",
       "      <td>0.726330</td>\n",
       "      <td>0.377823</td>\n",
       "      <td>0.309630</td>\n",
       "      <td>0.372403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270510</td>\n",
       "      <td>0.655885</td>\n",
       "      <td>0.324693</td>\n",
       "      <td>0.311062</td>\n",
       "      <td>0.573368</td>\n",
       "      <td>0.482148</td>\n",
       "      <td>0.443687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id   diagnosis  radius_mean  texture_mean  perimeter_mean  \\\n",
       "count  5.000000e+02  500.000000   500.000000    500.000000      500.000000   \n",
       "mean   3.263049e+07    0.390000     0.506019      0.485904        0.491282   \n",
       "std    1.326933e+08    0.488238     0.123686      0.106030        0.127233   \n",
       "min    8.670000e+03    0.000000     0.248346      0.247200        0.232308   \n",
       "25%    8.667040e+05    0.000000     0.420046      0.409114        0.403156   \n",
       "50%    9.014320e+05    0.000000     0.477944      0.475560        0.460133   \n",
       "75%    8.910808e+06    1.000000     0.573284      0.548943        0.563528   \n",
       "max    9.113205e+08    1.000000     1.000000      1.000000        1.000000   \n",
       "\n",
       "        area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "count  500.000000       500.000000        500.000000      500.000000   \n",
       "mean     0.265032         0.663292          0.300949        0.210733   \n",
       "std      0.139687         0.094446          0.153722        0.188047   \n",
       "min      0.057377         0.431997          0.056109        0.000000   \n",
       "25%      0.172151         0.594281          0.184199        0.067678   \n",
       "50%      0.222371         0.662232          0.264273        0.150691   \n",
       "75%      0.320182         0.726330          0.377823        0.309630   \n",
       "max      1.000000         1.000000          1.000000        1.000000   \n",
       "\n",
       "       concave points_mean  ...  area_worst  smoothness_worst  \\\n",
       "count           500.000000  ...  500.000000        500.000000   \n",
       "mean              0.245754  ...    0.210626          0.592867   \n",
       "std               0.193216  ...    0.134244          0.102153   \n",
       "min               0.000000  ...    0.043535          0.319721   \n",
       "25%               0.100621  ...    0.122849          0.522013   \n",
       "50%               0.168340  ...    0.162612          0.589623   \n",
       "75%               0.372403  ...    0.270510          0.655885   \n",
       "max               1.000000  ...    1.000000          1.000000   \n",
       "\n",
       "       compactness_worst  concavity_worst  concave points_worst  \\\n",
       "count         500.000000       500.000000            500.000000   \n",
       "mean            0.242273         0.220783              0.398557   \n",
       "std             0.150423         0.166943              0.226448   \n",
       "min             0.025794         0.000000              0.000000   \n",
       "25%             0.137925         0.091434              0.217534   \n",
       "50%             0.203072         0.184824              0.345876   \n",
       "75%             0.324693         0.311062              0.573368   \n",
       "max             1.000000         1.000000              1.000000   \n",
       "\n",
       "       symmetry_worst  fractal_dimension_worst  Unnamed: 32  over_average  \\\n",
       "count      500.000000               500.000000          0.0    500.000000   \n",
       "mean         0.440211                 0.403749          NaN      0.062500   \n",
       "std          0.095459                 0.087266          NaN      0.140564   \n",
       "min          0.235764                 0.265253          NaN      0.000000   \n",
       "25%          0.379180                 0.343470          NaN      0.000000   \n",
       "50%          0.426484                 0.385060          NaN      0.000000   \n",
       "75%          0.482148                 0.443687          NaN      0.050000   \n",
       "max          1.000000                 1.000000          NaN      1.000000   \n",
       "\n",
       "       under_average  \n",
       "count     500.000000  \n",
       "mean        0.958333  \n",
       "std         0.093709  \n",
       "min         0.333333  \n",
       "25%         0.966667  \n",
       "50%         1.000000  \n",
       "75%         1.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 35 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in df:\n",
    "    if col not in [\"id\",\"diagnosis\" ]:\n",
    "        df[col]=df[col]/df[col].max()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['concave points_worst', 'under_average', 'perimeter_worst', 'smoothness_se', 'radius_worst', 'symmetry_se', 'concave points_mean', 'texture_se'], [0.7943760186139828, -0.35661340233422306, 0.7802775126194339, -0.02978995032157478, 0.7740326821281189, -0.0001890815372350071, 0.7727922399366887, 0.00337097441705968])\n"
     ]
    }
   ],
   "source": [
    "def find_strongest_correlations(dataframe, qubits):\n",
    "        \n",
    "    class_correlations = dataframe.loc['diagnosis', :]\n",
    "    class_correlations = class_correlations.drop(index = 'diagnosis')\n",
    "    \n",
    "    feature_list = list(class_correlations.index)\n",
    "    correlation_list = [class_correlations[x] for x in feature_list]\n",
    "    \n",
    "    features = []\n",
    "    correlations = []\n",
    "    \n",
    "    for i in range(int(qubits/2)):\n",
    "        \n",
    "        \n",
    "        correlations.append(max(correlation_list))\n",
    "        features.append(feature_list[correlation_list.index(max(correlation_list))])\n",
    "        \n",
    "        del feature_list[correlation_list.index(max(correlation_list))]\n",
    "        del correlation_list[correlation_list.index(max(correlation_list))]                        \n",
    "                                      \n",
    "        correlations.append(min(correlation_list))\n",
    "        features.append(feature_list[correlation_list.index(min(correlation_list))])\n",
    "        \n",
    "        del feature_list[correlation_list.index(min(correlation_list))]\n",
    "        del correlation_list[correlation_list.index(min(correlation_list))] \n",
    "    \n",
    "    return features, correlations\n",
    "    \n",
    "    \n",
    "print(find_strongest_correlations(sub_sample_corr, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list, correlations = find_strongest_correlations(sub_sample_corr, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>under_average</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>texture_se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.440550</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.394108</td>\n",
       "      <td>0.143110</td>\n",
       "      <td>0.420366</td>\n",
       "      <td>0.207853</td>\n",
       "      <td>0.168191</td>\n",
       "      <td>0.276970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.396907</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.367038</td>\n",
       "      <td>0.215837</td>\n",
       "      <td>0.367370</td>\n",
       "      <td>0.237112</td>\n",
       "      <td>0.188419</td>\n",
       "      <td>0.284545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.472165</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.455016</td>\n",
       "      <td>0.167588</td>\n",
       "      <td>0.485572</td>\n",
       "      <td>0.211400</td>\n",
       "      <td>0.294881</td>\n",
       "      <td>0.166940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>0.163643</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.259833</td>\n",
       "      <td>0.351108</td>\n",
       "      <td>0.276942</td>\n",
       "      <td>0.359341</td>\n",
       "      <td>0.118340</td>\n",
       "      <td>0.245650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>0.460137</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.446258</td>\n",
       "      <td>0.131931</td>\n",
       "      <td>0.456437</td>\n",
       "      <td>0.203927</td>\n",
       "      <td>0.151988</td>\n",
       "      <td>0.208393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     concave points_worst  under_average  perimeter_worst  smoothness_se  \\\n",
       "49               0.440550            1.0         0.394108       0.143110   \n",
       "286              0.396907            1.0         0.367038       0.215837   \n",
       "133              0.472165            1.0         0.455016       0.167588   \n",
       "358              0.163643            1.0         0.259833       0.351108   \n",
       "476              0.460137            1.0         0.446258       0.131931   \n",
       "\n",
       "     radius_worst  symmetry_se  concave points_mean  texture_se  \n",
       "49       0.420366     0.207853             0.168191    0.276970  \n",
       "286      0.367370     0.237112             0.188419    0.284545  \n",
       "133      0.485572     0.211400             0.294881    0.166940  \n",
       "358      0.276942     0.359341             0.118340    0.245650  \n",
       "476      0.456437     0.203927             0.151988    0.208393  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malign=df[df[\"diagnosis\"]==0][feature_list]\n",
    "malign.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>under_average</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>texture_se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.912027</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.734873</td>\n",
       "      <td>0.205557</td>\n",
       "      <td>0.704218</td>\n",
       "      <td>0.380367</td>\n",
       "      <td>0.731113</td>\n",
       "      <td>0.185322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>0.835739</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.776274</td>\n",
       "      <td>0.127787</td>\n",
       "      <td>0.767481</td>\n",
       "      <td>0.192274</td>\n",
       "      <td>0.746024</td>\n",
       "      <td>0.143275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.450859</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.516322</td>\n",
       "      <td>0.156666</td>\n",
       "      <td>0.540233</td>\n",
       "      <td>0.194427</td>\n",
       "      <td>0.278976</td>\n",
       "      <td>0.258956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.680412</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.681131</td>\n",
       "      <td>0.194539</td>\n",
       "      <td>0.719478</td>\n",
       "      <td>0.238632</td>\n",
       "      <td>0.527833</td>\n",
       "      <td>0.237666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>0.524399</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.482484</td>\n",
       "      <td>0.337938</td>\n",
       "      <td>0.513596</td>\n",
       "      <td>0.268524</td>\n",
       "      <td>0.325696</td>\n",
       "      <td>0.308291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     concave points_worst  under_average  perimeter_worst  smoothness_se  \\\n",
       "0                0.912027       0.566667         0.734873       0.205557   \n",
       "369              0.835739       0.700000         0.776274       0.127787   \n",
       "132              0.450859       1.000000         0.516322       0.156666   \n",
       "300              0.680412       0.900000         0.681131       0.194539   \n",
       "353              0.524399       1.000000         0.482484       0.337938   \n",
       "\n",
       "     radius_worst  symmetry_se  concave points_mean  texture_se  \n",
       "0        0.704218     0.380367             0.731113    0.185322  \n",
       "369      0.767481     0.192274             0.746024    0.143275  \n",
       "132      0.540233     0.194427             0.278976    0.258956  \n",
       "300      0.719478     0.238632             0.527833    0.237666  \n",
       "353      0.513596     0.268524             0.325696    0.308291  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benign=df[df[\"diagnosis\"]!=0][feature_list]\n",
    "benign.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.44054983, 1.        , 0.39410828, ..., 0.20785307, 0.16819085,\n",
       "        0.27697032],\n",
       "       [0.39690722, 1.        , 0.36703822, ..., 0.2371121 , 0.18841948,\n",
       "        0.28454452],\n",
       "       [0.47216495, 1.        , 0.45501592, ..., 0.21139962, 0.29488072,\n",
       "        0.16693961],\n",
       "       ...,\n",
       "       [0.29505155, 1.        , 0.38248408, ..., 0.16782774, 0.08563618,\n",
       "        0.18902764],\n",
       "       [0.18329897, 0.96666667, 0.28535032, ..., 0.41557948, 0.08836978,\n",
       "        0.29150461],\n",
       "       [0.22707904, 1.        , 0.38339968, ..., 0.33337555, 0.09358847,\n",
       "        0.26591607]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data=malign.to_numpy()\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qubits: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n"
     ]
    }
   ],
   "source": [
    "shots = 2500\n",
    "nr_trash=2\n",
    "nr_latent=2\n",
    "nr_ent=0\n",
    "\n",
    "trash_qubits1=[i for i in range(nr_trash)]\n",
    "latent_qubits1=[i for i in range(nr_trash,nr_trash+nr_latent)]\n",
    "trash_qubits2=[i for i in range(nr_trash+nr_latent,2*nr_trash+nr_latent)]\n",
    "latent_qubits2=[i for i in range(2*nr_trash+nr_latent,2*(nr_trash+nr_latent))]\n",
    "aux_qubits=[i for i in range(2*(nr_trash+nr_latent),2*(nr_trash+nr_latent)+2*nr_trash)]\n",
    "swap_qubit=[2*(nr_trash+nr_latent)+2*nr_trash]\n",
    "\n",
    "qubits=[*trash_qubits1, *latent_qubits1, *trash_qubits2, *latent_qubits2, *aux_qubits, *swap_qubit]\n",
    "\n",
    "print(\"Qubits:\", qubits)\n",
    "\n",
    "#set up the device \n",
    "dev = qml.device(\"default.qubit\", wires=qubits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev)\n",
    "def training_circuit_example(init_params, encoder_params, reinit_state, x):\n",
    "    # Initialization\n",
    "    \n",
    "    \n",
    "    qml.templates.embeddings.AmplitudeEmbedding(\n",
    "        init_params,\n",
    "        wires=[*trash_qubits1, *latent_qubits1],\n",
    "        normalize=True,\n",
    "        pad_with=0.0j,\n",
    "    )\n",
    "  \n",
    "    \n",
    "    qml.templates.embeddings.AngleEmbedding(\n",
    "        init_params[:4], wires=[*trash_qubits2, *latent_qubits2], rotation='X')\n",
    "    qml.templates.embeddings.AngleEmbedding(\n",
    "        init_params[:4], wires=[*trash_qubits2, *latent_qubits2], rotation='Z')\n",
    "    \n",
    "    qml.MottonenStatePreparation(reinit_state, wires=aux_qubits)\n",
    "\n",
    "    #encoder \n",
    "    e5_patch(*encoder_params[0],*encoder_params[1], [*trash_qubits1, *latent_qubits1], [*latent_qubits2, *trash_qubits2])\n",
    "    qml.CNOT(wires=[latent_qubits1[0],trash_qubits2[0]])\n",
    "    qml.CNOT(wires=[latent_qubits2[0],trash_qubits1[0]])\n",
    "    \n",
    "    #swap test \n",
    "    trashes=[*trash_qubits1,*trash_qubits2]\n",
    "    qml.Hadamard(wires=swap_qubit[0])\n",
    "    for i in range(len(trashes)):\n",
    "        qml.CSWAP(wires=[swap_qubit[0], aux_qubits[i], trashes[i]])\n",
    "    qml.Hadamard(wires=swap_qubit[0])\n",
    "\n",
    "    return [qml.probs(i) for i in swap_qubit]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "learning_rate = 0.0003\n",
    "batch_size = 5\n",
    "num_samples = 0.8 # proportion of the data used for training \n",
    "\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "opt = AdamOptimizer(learning_rate, beta1=beta1, beta2=beta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fid_func(output):\n",
    "    # Implemented as the Fidelity Loss\n",
    "    # output[0] because we take the probability that the state after the \n",
    "    # SWAP test is ket(0), like the reference state\n",
    "    fidelity_loss = 1 / output[0]\n",
    "    return fidelity_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(encoder_params, X):\n",
    "    reinit_state = [0 for i in range(2 ** len(aux_qubits))]\n",
    "    reinit_state[0] = 1.0\n",
    "    loss = 0.0\n",
    "    for x in X:\n",
    "        output = training_circuit_example(init_params=x[0], encoder_params=encoder_params, reinit_state=reinit_state,x=x[0][1])[0]\n",
    "        f = fid_func(output)\n",
    "        loss = loss + f\n",
    "    return loss / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fidelity(encoder_params, X):\n",
    "    reinit_state = [0 for _ in range(2 ** len(aux_qubits))]\n",
    "    reinit_state[0] = 1.0\n",
    "    loss = 0.0\n",
    "    for x in X:\n",
    "        output =  training_circuit_example(init_params=x[0], encoder_params=encoder_params, reinit_state=reinit_state,x=x[0][1])[0]\n",
    "       \n",
    "        f = output[0]\n",
    "        loss = loss + f\n",
    "    return loss / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_batches(X, batch_size):\n",
    "    \n",
    "    random.shuffle(X)\n",
    "\n",
    "    batch_list = []\n",
    "    batch = []\n",
    "    for x in X:\n",
    "        if len(batch) < batch_size:\n",
    "            batch.append(x)\n",
    "\n",
    "        else:\n",
    "            batch_list.append(batch)\n",
    "            batch = []\n",
    "    if len(batch) != 0:\n",
    "        batch_list.append(batch)\n",
    "    return batch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomut\\AppData\\Local\\Temp/ipykernel_16228/3998820717.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_new.cpp:201.)\n",
      "  training_data = [ torch.tensor([input_data[i]]) for i in range(int(len(input_data)*num_samples))]\n"
     ]
    }
   ],
   "source": [
    "training_data = [ torch.tensor([input_data[i]]) for i in range(int(len(input_data)*num_samples))]\n",
    "test_data = [torch.tensor([input_data[i]]) for i in range(int(len(input_data)*num_samples),len(input_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches=iterate_batches(training_data, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training = training_data\n",
    "X_tes = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_encod_qubits = nr_trash + nr_latent\n",
    "nr_par_encoder =  15 * int(nr_encod_qubits*(nr_encod_qubits-1)/2)\n",
    "encoder_params = [np.random.uniform(size=(1, nr_par_encoder), requires_grad=True),np.random.uniform(size=(1, nr_par_encoder), requires_grad=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.09075912, 0.43083438, 0.61104191, 0.98140128, 0.25916799,\n",
       "          0.19127658, 0.73801206, 0.75994369, 0.49570623, 0.22337904,\n",
       "          0.38290263, 0.979896  , 0.76047812, 0.56600444, 0.73228928,\n",
       "          0.93751677, 0.51956001, 0.04816204, 0.16931909, 0.534288  ,\n",
       "          0.13641588, 0.80369072, 0.8293342 , 0.65430993, 0.14405095,\n",
       "          0.27119131, 0.55490971, 0.29333833, 0.9997208 , 0.65201246,\n",
       "          0.58802442, 0.19784574, 0.91822301, 0.41495821, 0.82805115,\n",
       "          0.42098419, 0.03064296, 0.79588406, 0.38978271, 0.16030516,\n",
       "          0.54942394, 0.49227646, 0.07936756, 0.88438489, 0.4513883 ,\n",
       "          0.87050712, 0.02449582, 0.94120391, 0.85761813, 0.56772217,\n",
       "          0.66257483, 0.82942069, 0.50472169, 0.25880231, 0.44968381,\n",
       "          0.85549735, 0.36922135, 0.27193812, 0.59981726, 0.58904543,\n",
       "          0.49931935, 0.99603338, 0.05688344, 0.9712426 , 0.85166285,\n",
       "          0.33571091, 0.60787448, 0.02162765, 0.92907753, 0.7058599 ,\n",
       "          0.80389319, 0.47483617, 0.8034911 , 0.12834766, 0.17854201,\n",
       "          0.21575491, 0.12799529, 0.08848444, 0.97946228, 0.99576366,\n",
       "          0.26860353, 0.18616463, 0.03527528, 0.77762457, 0.14742196,\n",
       "          0.60233703, 0.21913181, 0.15207669, 0.213657  , 0.56791625]], requires_grad=True),\n",
       " tensor([[0.79854443, 0.84492978, 0.39630676, 0.33699438, 0.60762316,\n",
       "          0.97016491, 0.03411064, 0.84317306, 0.58096982, 0.07192366,\n",
       "          0.50491446, 0.43061741, 0.43883065, 0.09502069, 0.49875444,\n",
       "          0.95617762, 0.67243603, 0.90267947, 0.68997562, 0.11556514,\n",
       "          0.97651995, 0.69757122, 0.3251355 , 0.3995478 , 0.91321647,\n",
       "          0.80638431, 0.21688154, 0.30436981, 0.09693463, 0.24411585,\n",
       "          0.88048386, 0.56022515, 0.75892278, 0.00819889, 0.86589017,\n",
       "          0.78567528, 0.25224704, 0.85425739, 0.40349023, 0.50774781,\n",
       "          0.00784405, 0.27659115, 0.94262875, 0.73869169, 0.87021575,\n",
       "          0.34152578, 0.6114391 , 0.89954813, 0.61614819, 0.28903466,\n",
       "          0.3739968 , 0.57994075, 0.51796499, 0.11266399, 0.7121062 ,\n",
       "          0.16587138, 0.47868861, 0.64325326, 0.4736807 , 0.99063979,\n",
       "          0.2127319 , 0.885514  , 0.28340779, 0.73122092, 0.13995093,\n",
       "          0.39502066, 0.51147303, 0.09345921, 0.56568558, 0.62040643,\n",
       "          0.21701505, 0.85202809, 0.10449475, 0.63845199, 0.2204474 ,\n",
       "          0.28424521, 0.57705456, 0.40280283, 0.63205897, 0.24553217,\n",
       "          0.70305265, 0.23325614, 0.33752395, 0.36391522, 0.11273986,\n",
       "          0.14668287, 0.39682091, 0.42706574, 0.52906846, 0.65047691]], requires_grad=True)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.09075912, 0.43083438, 0.61104191, 0.98140128, 0.25916799,\n",
       "         0.19127658, 0.73801206, 0.75994369, 0.49570623, 0.22337904,\n",
       "         0.38290263, 0.979896  , 0.76047812, 0.56600444, 0.73228928,\n",
       "         0.93751677, 0.51956001, 0.04816204, 0.16931909, 0.534288  ,\n",
       "         0.13641588, 0.80369072, 0.8293342 , 0.65430993, 0.14405095,\n",
       "         0.27119131, 0.55490971, 0.29333833, 0.9997208 , 0.65201246,\n",
       "         0.58802442, 0.19784574, 0.91822301, 0.41495821, 0.82805115,\n",
       "         0.42098419, 0.03064296, 0.79588406, 0.38978271, 0.16030516,\n",
       "         0.54942394, 0.49227646, 0.07936756, 0.88438489, 0.4513883 ,\n",
       "         0.87050712, 0.02449582, 0.94120391, 0.85761813, 0.56772217,\n",
       "         0.66257483, 0.82942069, 0.50472169, 0.25880231, 0.44968381,\n",
       "         0.85549735, 0.36922135, 0.27193812, 0.59981726, 0.58904543,\n",
       "         0.49931935, 0.99603338, 0.05688344, 0.9712426 , 0.85166285,\n",
       "         0.33571091, 0.60787448, 0.02162765, 0.92907753, 0.7058599 ,\n",
       "         0.80389319, 0.47483617, 0.8034911 , 0.12834766, 0.17854201,\n",
       "         0.21575491, 0.12799529, 0.08848444, 0.97946228, 0.99576366,\n",
       "         0.26860353, 0.18616463, 0.03527528, 0.77762457, 0.14742196,\n",
       "         0.60233703, 0.21913181, 0.15207669, 0.213657  , 0.56791625]], requires_grad=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_params[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_benign = benign.to_numpy()\n",
    "benign_data = [ torch.tensor([np_benign[i]]) for i in range(len(benign.to_numpy()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomut\\anaconda3\\envs\\qhack2022\\lib\\site-packages\\pennylane\\_grad.py:95: UserWarning: Starting with PennyLane v0.21.0, when using Autograd, inputs have to explicitly specify requires_grad=True (or the argnum argument must be passed) in order for trainable parameters to be identified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tomut\\anaconda3\\envs\\qhack2022\\lib\\site-packages\\pennylane\\math\\multi_dispatch.py:63: UserWarning: Contains tensors of types {'torch', 'autograd'}; dispatch will prioritize TensorFlow and PyTorch over autograd. Consider replacing Autograd with vanilla NumPy.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 | Loss:1.7001964166363608 | Fidelity:0.5882618397430397\n",
      "Test-Epoch:0 | Loss:1.7027630661825996 | Fidelity:0.5873531158083523\n",
      "benign fid:0.5858936051505066\n",
      "Epoch:5 | Loss:1.3535133196643896 | Fidelity:0.7389725100041398\n",
      "Test-Epoch:5 | Loss:1.3538413315024203 | Fidelity:0.738755298089553\n",
      "benign fid:0.7091491362904917\n",
      "Epoch:10 | Loss:1.2429724008097722 | Fidelity:0.8046708143127466\n",
      "Test-Epoch:10 | Loss:1.2417048387636707 | Fidelity:0.8054316796743306\n",
      "benign fid:0.7622107531485887\n",
      "Epoch:15 | Loss:1.19891603625708 | Fidelity:0.8342311024576119\n",
      "Test-Epoch:15 | Loss:1.1963537307529575 | Fidelity:0.8359468897273952\n",
      "benign fid:0.7813937301644875\n",
      "Epoch:20 | Loss:1.1801478264470295 | Fidelity:0.8475044664236261\n",
      "Test-Epoch:20 | Loss:1.1766340722361306 | Fidelity:0.8499530407009908\n",
      "benign fid:0.7873665967189715\n",
      "Epoch:25 | Loss:1.1725992455550873 | Fidelity:0.8529689910103918\n",
      "Test-Epoch:25 | Loss:1.1684613529032637 | Fidelity:0.8558979835902781\n",
      "benign fid:0.7888332636727862\n",
      "Epoch:30 | Loss:1.169693507621653 | Fidelity:0.8551009111602147\n",
      "Test-Epoch:30 | Loss:1.1650580231859295 | Fidelity:0.85839898085921\n",
      "benign fid:0.7876753670249405\n",
      "Epoch:35 | Loss:1.168614507002602 | Fidelity:0.8558931445073734\n",
      "Test-Epoch:35 | Loss:1.1638021610570985 | Fidelity:0.8593279610219983\n",
      "benign fid:0.7876619749889217\n",
      "Epoch:40 | Loss:1.168111558133905 | Fidelity:0.8562656156834533\n",
      "Test-Epoch:40 | Loss:1.1631539814504674 | Fidelity:0.8598064435322214\n",
      "benign fid:0.7870967515580347\n",
      "Epoch:45 | Loss:1.1678378011383328 | Fidelity:0.8564682953196607\n",
      "Test-Epoch:45 | Loss:1.162792615435314 | Fidelity:0.860073722095298\n",
      "benign fid:0.7867395405853106\n",
      "Epoch:50 | Loss:1.1676449796913002 | Fidelity:0.8566096670813542\n",
      "Test-Epoch:50 | Loss:1.1626229638372525 | Fidelity:0.8601960329268228\n",
      "benign fid:0.7867425542278766\n",
      "Epoch:55 | Loss:1.1674170076776955 | Fidelity:0.8567680902693228\n",
      "Test-Epoch:55 | Loss:1.162509743222149 | Fidelity:0.8602768255703146\n",
      "benign fid:0.7879793289408371\n",
      "Epoch:60 | Loss:1.167174520928346 | Fidelity:0.8569413941695816\n",
      "Test-Epoch:60 | Loss:1.162280161249177 | Fidelity:0.8604474276893044\n",
      "benign fid:0.7884904571187374\n",
      "Epoch:65 | Loss:1.1669154529483772 | Fidelity:0.8571306106499808\n",
      "Test-Epoch:65 | Loss:1.1620343915189695 | Fidelity:0.8606265288067813\n",
      "benign fid:0.7885778158850364\n",
      "Epoch:70 | Loss:1.166676689879201 | Fidelity:0.8573001424274048\n",
      "Test-Epoch:70 | Loss:1.1618176085926437 | Fidelity:0.8607866202049981\n",
      "benign fid:0.7892205931938766\n",
      "Epoch:75 | Loss:1.1663317174825516 | Fidelity:0.8575462098594547\n",
      "Test-Epoch:75 | Loss:1.1616339443968988 | Fidelity:0.8609182737283363\n",
      "benign fid:0.7904842543488939\n",
      "Epoch:80 | Loss:1.166019638088983 | Fidelity:0.8577695756691587\n",
      "Test-Epoch:80 | Loss:1.1613786315723331 | Fidelity:0.8611064745848338\n",
      "benign fid:0.7913727322546521\n",
      "Epoch:85 | Loss:1.1656787189286328 | Fidelity:0.8580178333945154\n",
      "Test-Epoch:85 | Loss:1.1611245764179754 | Fidelity:0.861291476931283\n",
      "benign fid:0.7920354669405671\n",
      "Epoch:90 | Loss:1.1653209486906144 | Fidelity:0.8582772366212859\n",
      "Test-Epoch:90 | Loss:1.160898799014265 | Fidelity:0.8614575366437901\n",
      "benign fid:0.7928522670812145\n",
      "Epoch:95 | Loss:1.1650141533169889 | Fidelity:0.8584959876901049\n",
      "Test-Epoch:95 | Loss:1.1607092190404191 | Fidelity:0.8615955231783264\n",
      "benign fid:0.7940744954653973\n",
      "Epoch:100 | Loss:1.1646498001737198 | Fidelity:0.8587655944357545\n",
      "Test-Epoch:100 | Loss:1.1603992296574925 | Fidelity:0.8618264698820722\n",
      "benign fid:0.7943245791371643\n",
      "Epoch:105 | Loss:1.1643563259909808 | Fidelity:0.8589771665311073\n",
      "Test-Epoch:105 | Loss:1.160179556458174 | Fidelity:0.8619877443630621\n",
      "benign fid:0.7953085121632538\n",
      "Epoch:110 | Loss:1.164069407798251 | Fidelity:0.8591858563121126\n",
      "Test-Epoch:110 | Loss:1.159961443514854 | Fidelity:0.8621495368186393\n",
      "benign fid:0.7960685970626793\n",
      "Epoch:115 | Loss:1.1637947101224755 | Fidelity:0.8593876650114987\n",
      "Test-Epoch:115 | Loss:1.159756952871804 | Fidelity:0.8623005777723756\n",
      "benign fid:0.7966600798229058\n",
      "Epoch:120 | Loss:1.163559103526667 | Fidelity:0.8595601290679159\n",
      "Test-Epoch:120 | Loss:1.1595576145653717 | Fidelity:0.8624488138323035\n",
      "benign fid:0.7970646556151906\n",
      "Epoch:125 | Loss:1.1633754923910948 | Fidelity:0.8596941097605107\n",
      "Test-Epoch:125 | Loss:1.15951900694158 | Fidelity:0.8624764108137205\n",
      "benign fid:0.7979727345007623\n",
      "Epoch:130 | Loss:1.163198139209021 | Fidelity:0.8598238884831103\n",
      "Test-Epoch:130 | Loss:1.159326199965015 | Fidelity:0.8626200653020932\n",
      "benign fid:0.7980674634547742\n",
      "Epoch:135 | Loss:1.1630287735766838 | Fidelity:0.8599528583476042\n",
      "Test-Epoch:135 | Loss:1.1591053447923911 | Fidelity:0.8627869168063876\n",
      "benign fid:0.7974861942584169\n",
      "Epoch:140 | Loss:1.1629074347340027 | Fidelity:0.8600470312671874\n",
      "Test-Epoch:140 | Loss:1.1589136928725574 | Fidelity:0.8629311195970326\n",
      "benign fid:0.797051794535024\n",
      "Epoch:145 | Loss:1.162785593254248 | Fidelity:0.8601348081819705\n",
      "Test-Epoch:145 | Loss:1.158863270351852 | Fidelity:0.8629674928129284\n",
      "benign fid:0.7976271051503565\n",
      "Epoch:150 | Loss:1.1627141577706421 | Fidelity:0.8601887179693904\n",
      "Test-Epoch:150 | Loss:1.1587300946452266 | Fidelity:0.8630671208273739\n",
      "benign fid:0.7974930141746438\n",
      "Epoch:155 | Loss:1.1626627223735038 | Fidelity:0.8602233086683367\n",
      "Test-Epoch:155 | Loss:1.1588364206824704 | Fidelity:0.8629864847626233\n",
      "benign fid:0.798233714885172\n",
      "Epoch:160 | Loss:1.1625093952639107 | Fidelity:0.8603379367724033\n",
      "Test-Epoch:160 | Loss:1.1587303144234578 | Fidelity:0.8630654853271428\n",
      "benign fid:0.798309403915019\n",
      "Epoch:165 | Loss:1.1624523925271837 | Fidelity:0.860385099935418\n",
      "Test-Epoch:165 | Loss:1.1584914834985356 | Fidelity:0.8632460398529761\n",
      "benign fid:0.7971114006121404\n",
      "Epoch:170 | Loss:1.1624057780472095 | Fidelity:0.8604165790705066\n",
      "Test-Epoch:170 | Loss:1.1585171889860315 | Fidelity:0.8632254224240493\n",
      "benign fid:0.7976678339535735\n",
      "Epoch:175 | Loss:1.1623474876565643 | Fidelity:0.8604563345723447\n",
      "Test-Epoch:175 | Loss:1.1585613745216223 | Fidelity:0.8631903569137745\n",
      "benign fid:0.7985284883559809\n",
      "Epoch:180 | Loss:1.1622837698376867 | Fidelity:0.8605087462300554\n",
      "Test-Epoch:180 | Loss:1.1583822182723664 | Fidelity:0.8633265688456663\n",
      "benign fid:0.797519609849313\n",
      "Epoch:185 | Loss:1.1622561361139252 | Fidelity:0.8605299588692097\n",
      "Test-Epoch:185 | Loss:1.1583745596501613 | Fidelity:0.8633319080944886\n",
      "benign fid:0.7975371173301239\n",
      "Epoch:190 | Loss:1.162203398394856 | Fidelity:0.8605703759493749\n",
      "Test-Epoch:190 | Loss:1.1583211573544532 | Fidelity:0.8633726625507265\n",
      "benign fid:0.7972426904669563\n",
      "Epoch:195 | Loss:1.162162151650372 | Fidelity:0.8605991601172726\n",
      "Test-Epoch:195 | Loss:1.1583071252490629 | Fidelity:0.8633814529109947\n",
      "benign fid:0.797690151388208\n",
      "Epoch:200 | Loss:1.1621441716243233 | Fidelity:0.860616233631615\n",
      "Test-Epoch:200 | Loss:1.1582185714625128 | Fidelity:0.8634486327627208\n",
      "benign fid:0.7973362826094034\n",
      "Epoch:205 | Loss:1.1620983011576675 | Fidelity:0.8606495970119395\n",
      "Test-Epoch:205 | Loss:1.1582248608970451 | Fidelity:0.8634440041630081\n",
      "benign fid:0.7973215417915851\n",
      "Epoch:210 | Loss:1.1620733135718946 | Fidelity:0.8606684104171058\n",
      "Test-Epoch:210 | Loss:1.1581909919977673 | Fidelity:0.8634692283544374\n",
      "benign fid:0.797333064499823\n",
      "Epoch:215 | Loss:1.1620609685000132 | Fidelity:0.8606712039457338\n",
      "Test-Epoch:215 | Loss:1.1583193777441017 | Fidelity:0.8633719603824704\n",
      "benign fid:0.7982279019492587\n",
      "Epoch:220 | Loss:1.1620348643363836 | Fidelity:0.8606954026231615\n",
      "Test-Epoch:220 | Loss:1.1581379071396485 | Fidelity:0.8635083625817276\n",
      "benign fid:0.7974890046787022\n",
      "Epoch:225 | Loss:1.162003987540944 | Fidelity:0.860718478282039\n",
      "Test-Epoch:225 | Loss:1.1581652565545963 | Fidelity:0.8634881333497969\n",
      "benign fid:0.7975268722668817\n",
      "Epoch:230 | Loss:1.1619848029053306 | Fidelity:0.8607299217043756\n",
      "Test-Epoch:230 | Loss:1.158219239042471 | Fidelity:0.8634466043769912\n",
      "benign fid:0.7980168514580745\n",
      "Epoch:235 | Loss:1.1619773858301163 | Fidelity:0.860734284688042\n",
      "Test-Epoch:235 | Loss:1.1582089981321504 | Fidelity:0.8634540963931937\n",
      "benign fid:0.7980103152072622\n",
      "Epoch:240 | Loss:1.1619776721331088 | Fidelity:0.8607449003668517\n",
      "Test-Epoch:240 | Loss:1.157976886923626 | Fidelity:0.8636310170182756\n",
      "benign fid:0.7963120087601889\n",
      "Epoch:245 | Loss:1.16193310877392 | Fidelity:0.8607718092592905\n",
      "Test-Epoch:245 | Loss:1.158067327795076 | Fidelity:0.863561463514694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benign fid:0.7974740712920172\n",
      "Epoch:250 | Loss:1.161914345389392 | Fidelity:0.86078428244283\n",
      "Test-Epoch:250 | Loss:1.158131447865189 | Fidelity:0.8635127677450742\n",
      "benign fid:0.7979767452548617\n",
      "Epoch:255 | Loss:1.1618968448635316 | Fidelity:0.8608001606873685\n",
      "Test-Epoch:255 | Loss:1.1580291072871152 | Fidelity:0.863589943796076\n",
      "benign fid:0.797467443810489\n",
      "Epoch:260 | Loss:1.1618825649793292 | Fidelity:0.8608109685436931\n",
      "Test-Epoch:260 | Loss:1.1580230601259225 | Fidelity:0.8635948176345788\n",
      "benign fid:0.797371086468798\n",
      "Epoch:265 | Loss:1.1618949526411764 | Fidelity:0.860798462995461\n",
      "Test-Epoch:265 | Loss:1.1581280469443809 | Fidelity:0.8635147560069962\n",
      "benign fid:0.7982243603937011\n",
      "Epoch:270 | Loss:1.1618971365599537 | Fidelity:0.8608062393535847\n",
      "Test-Epoch:270 | Loss:1.1578728232573086 | Fidelity:0.863709109396778\n",
      "benign fid:0.7963801552499149\n",
      "Epoch:275 | Loss:1.161882762241982 | Fidelity:0.8608074333912437\n",
      "Test-Epoch:275 | Loss:1.158075244033647 | Fidelity:0.8635544295938136\n",
      "benign fid:0.7981063130451524\n",
      "Epoch:280 | Loss:1.161855985409747 | Fidelity:0.8608329748501579\n",
      "Test-Epoch:280 | Loss:1.1579128180008254 | Fidelity:0.8636780142041064\n",
      "benign fid:0.7968616370835409\n",
      "Epoch:285 | Loss:1.1618481152133389 | Fidelity:0.8608379830443894\n",
      "Test-Epoch:285 | Loss:1.1579236860422093 | Fidelity:0.8636698383132124\n",
      "benign fid:0.7972527298231102\n",
      "Epoch:290 | Loss:1.1618663527383966 | Fidelity:0.8608196575535482\n",
      "Test-Epoch:290 | Loss:1.1581303143706507 | Fidelity:0.8635130816476152\n",
      "benign fid:0.7984003822566894\n",
      "Epoch:295 | Loss:1.16183149508554 | Fidelity:0.8608518136500048\n",
      "Test-Epoch:295 | Loss:1.157919390449155 | Fidelity:0.863672843967289\n",
      "benign fid:0.7970826458594775\n",
      "Epoch:300 | Loss:1.1618181901764635 | Fidelity:0.8608596691589179\n",
      "Test-Epoch:300 | Loss:1.1579267908140007 | Fidelity:0.8636666877802048\n",
      "benign fid:0.7973758061053646\n",
      "Epoch:305 | Loss:1.1618688496064287 | Fidelity:0.8608166881304335\n",
      "Test-Epoch:305 | Loss:1.1581357193582784 | Fidelity:0.8635086155976041\n",
      "benign fid:0.7985016017454181\n",
      "Epoch:310 | Loss:1.1618122663554686 | Fidelity:0.8608637611374853\n",
      "Test-Epoch:310 | Loss:1.1579252989979039 | Fidelity:0.8636687275095688\n",
      "benign fid:0.7973076489572162\n",
      "Epoch:315 | Loss:1.1618899084039702 | Fidelity:0.8608059097756681\n",
      "Test-Epoch:315 | Loss:1.1579884841396548 | Fidelity:0.8636217198132562\n",
      "benign fid:0.7975149075450482\n",
      "Epoch:320 | Loss:1.161792240623655 | Fidelity:0.8608773827202509\n",
      "Test-Epoch:320 | Loss:1.1579612833830641 | Fidelity:0.8636406380263139\n",
      "benign fid:0.7978352322212579\n",
      "Epoch:325 | Loss:1.1618055289988591 | Fidelity:0.8608664825914903\n",
      "Test-Epoch:325 | Loss:1.158045491778847 | Fidelity:0.8635770363074712\n",
      "benign fid:0.7982466514999816\n",
      "Epoch:330 | Loss:1.1618183594698612 | Fidelity:0.8608641544745619\n",
      "Test-Epoch:330 | Loss:1.157822522976151 | Fidelity:0.8637466538057758\n",
      "benign fid:0.7966576376025365\n",
      "Epoch:335 | Loss:1.1617673760881915 | Fidelity:0.8608998881369996\n",
      "Test-Epoch:335 | Loss:1.157832425122506 | Fidelity:0.86373848006278\n",
      "benign fid:0.7971750363411915\n",
      "Epoch:340 | Loss:1.1617959876871193 | Fidelity:0.8608753625709554\n",
      "Test-Epoch:340 | Loss:1.1579310998037151 | Fidelity:0.8636641287572551\n",
      "benign fid:0.7976736584097447\n",
      "Epoch:345 | Loss:1.1617642707779376 | Fidelity:0.8609037529378746\n",
      "Test-Epoch:345 | Loss:1.1578105969617556 | Fidelity:0.8637551541118096\n",
      "benign fid:0.7970043730508288\n",
      "Epoch:350 | Loss:1.1617755884071972 | Fidelity:0.8608897819129089\n",
      "Test-Epoch:350 | Loss:1.1579895614357192 | Fidelity:0.8636189685249106\n",
      "benign fid:0.7981788409176791\n",
      "Epoch:355 | Loss:1.161755040545802 | Fidelity:0.8609086091070016\n",
      "Test-Epoch:355 | Loss:1.1578192567497105 | Fidelity:0.8637479528508736\n",
      "benign fid:0.79741224065694\n",
      "Epoch:360 | Loss:1.1617813950861893 | Fidelity:0.8608926105124438\n",
      "Test-Epoch:360 | Loss:1.1577895409958663 | Fidelity:0.8637709862152128\n",
      "benign fid:0.7968075476852747\n",
      "Epoch:365 | Loss:1.1617459150427976 | Fidelity:0.8609138300177487\n",
      "Test-Epoch:365 | Loss:1.1578570621345259 | Fidelity:0.8637197913076904\n",
      "benign fid:0.7975140659684467\n",
      "Epoch:370 | Loss:1.1617525747706954 | Fidelity:0.8609050458367115\n",
      "Test-Epoch:370 | Loss:1.1580150420221678 | Fidelity:0.8636000474538041\n",
      "benign fid:0.7984105821078233\n",
      "Epoch:375 | Loss:1.1617617806716212 | Fidelity:0.8609006131618344\n",
      "Test-Epoch:375 | Loss:1.1579189985105212 | Fidelity:0.863673448961289\n",
      "benign fid:0.7978040344307471\n",
      "Epoch:380 | Loss:1.161746147051365 | Fidelity:0.8609128900341011\n",
      "Test-Epoch:380 | Loss:1.1578921882166942 | Fidelity:0.8636933486503626\n",
      "benign fid:0.7977038820051195\n",
      "Epoch:385 | Loss:1.1617264663448215 | Fidelity:0.8609254189133937\n",
      "Test-Epoch:385 | Loss:1.1579545379203733 | Fidelity:0.8636456980024767\n",
      "benign fid:0.7982781366235125\n",
      "Epoch:390 | Loss:1.1617212675039654 | Fidelity:0.8609336811860957\n",
      "Test-Epoch:390 | Loss:1.1578309620374927 | Fidelity:0.8637391723661744\n",
      "benign fid:0.7975797030031998\n",
      "Epoch:395 | Loss:1.1617503778347649 | Fidelity:0.8609105897728524\n",
      "Test-Epoch:395 | Loss:1.1579338813870568 | Fidelity:0.863661364043294\n",
      "benign fid:0.7980656936635945\n",
      "Epoch:400 | Loss:1.1617264697452645 | Fidelity:0.8609283786759805\n",
      "Test-Epoch:400 | Loss:1.157907354931678 | Fidelity:0.8636820184328852\n",
      "benign fid:0.7980091487760641\n",
      "Epoch:405 | Loss:1.161729026351036 | Fidelity:0.8609249919259836\n",
      "Test-Epoch:405 | Loss:1.1579269301407498 | Fidelity:0.8636661855735152\n",
      "benign fid:0.7983576215273249\n",
      "Epoch:410 | Loss:1.1617295395731828 | Fidelity:0.8609265488724395\n",
      "Test-Epoch:410 | Loss:1.157854767506724 | Fidelity:0.863722114079135\n",
      "benign fid:0.7975510655981919\n",
      "Epoch:415 | Loss:1.1617479294168385 | Fidelity:0.8609096408480169\n",
      "Test-Epoch:415 | Loss:1.1580032243692286 | Fidelity:0.8636088294769714\n",
      "benign fid:0.7986883351748663\n",
      "Epoch:420 | Loss:1.1617284228002303 | Fidelity:0.8609239792204284\n",
      "Test-Epoch:420 | Loss:1.1579878483833934 | Fidelity:0.8636204426939925\n",
      "benign fid:0.7986999562256645\n",
      "Epoch:425 | Loss:1.1617102757363518 | Fidelity:0.8609381789641553\n",
      "Test-Epoch:425 | Loss:1.1579212245953883 | Fidelity:0.8636707819339874\n",
      "benign fid:0.7983827185184746\n",
      "Epoch:430 | Loss:1.1617125277358484 | Fidelity:0.8609355408356192\n",
      "Test-Epoch:430 | Loss:1.1579637092593473 | Fidelity:0.8636388070138001\n",
      "benign fid:0.7985419720324838\n",
      "Epoch:435 | Loss:1.1617045181945262 | Fidelity:0.8609451965447842\n",
      "Test-Epoch:435 | Loss:1.157890462791791 | Fidelity:0.8636946858941994\n",
      "benign fid:0.7980751126578569\n",
      "Epoch:440 | Loss:1.1617133091732923 | Fidelity:0.8609419896290851\n",
      "Test-Epoch:440 | Loss:1.1577489466679953 | Fidelity:0.8638019420563875\n",
      "benign fid:0.7972589212089114\n",
      "Epoch:445 | Loss:1.161740641776771 | Fidelity:0.8609222471360392\n",
      "Test-Epoch:445 | Loss:1.1577710570541246 | Fidelity:0.863786509257749\n",
      "benign fid:0.7969015388560075\n",
      "Epoch:450 | Loss:1.1616942116808389 | Fidelity:0.8609501406454351\n",
      "Test-Epoch:450 | Loss:1.1579197968413253 | Fidelity:0.8636716814639717\n",
      "benign fid:0.7984895080210223\n",
      "Epoch:455 | Loss:1.161731943735605 | Fidelity:0.860926022621716\n",
      "Test-Epoch:455 | Loss:1.1578409320759078 | Fidelity:0.8637324501321227\n",
      "benign fid:0.7976234160593589\n",
      "Epoch:460 | Loss:1.1616949364121998 | Fidelity:0.8609555443399112\n",
      "Test-Epoch:460 | Loss:1.1577659745808748 | Fidelity:0.8637890723548982\n",
      "benign fid:0.7974913050513186\n",
      "Epoch:465 | Loss:1.1617153329285022 | Fidelity:0.8609358347340954\n",
      "Test-Epoch:465 | Loss:1.1579463182745362 | Fidelity:0.8636517497891495\n",
      "benign fid:0.7985976743552358\n",
      "Epoch:470 | Loss:1.1616967095644817 | Fidelity:0.8609519154678169\n",
      "Test-Epoch:470 | Loss:1.1578437454178268 | Fidelity:0.8637301146048385\n",
      "benign fid:0.7977943718899339\n",
      "Epoch:475 | Loss:1.1617017479047622 | Fidelity:0.8609502594324052\n",
      "Test-Epoch:475 | Loss:1.1578004830811242 | Fidelity:0.8637626498425053\n",
      "benign fid:0.7976035130632786\n",
      "Epoch:480 | Loss:1.161697279903462 | Fidelity:0.8609479303850349\n",
      "Test-Epoch:480 | Loss:1.15790117363746 | Fidelity:0.8636863164060476\n",
      "benign fid:0.798422409221963\n",
      "Epoch:485 | Loss:1.1616806390511607 | Fidelity:0.8609607487734007\n",
      "Test-Epoch:485 | Loss:1.1579100034475034 | Fidelity:0.8636796994083519\n",
      "benign fid:0.7983280325085285\n",
      "Epoch:490 | Loss:1.161691487141125 | Fidelity:0.8609587125541082\n",
      "Test-Epoch:490 | Loss:1.157744175354126 | Fidelity:0.8638057967662142\n",
      "benign fid:0.7974376142317663\n",
      "Epoch:495 | Loss:1.1617147474032532 | Fidelity:0.8609424846861528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-Epoch:495 | Loss:1.1577441554330763 | Fidelity:0.8638061542404104\n",
      "benign fid:0.7972551678152525\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loss_hist=[]\n",
    "fid_hist=[]\n",
    "\n",
    "loss_hist_test=[]\n",
    "fid_hist_test=[]\n",
    "\n",
    "benign_fid=[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    batches = iterate_batches(X=training_data, batch_size=batch_size)\n",
    "    for xbatch in batches:\n",
    "        encoder_params = opt.step(cost, encoder_params, X=xbatch)\n",
    "\n",
    "        \n",
    "    if epoch%5 == 0:\n",
    "        \n",
    "        loss_training = cost(encoder_params, X_training )\n",
    "        fidel = fidelity(encoder_params, X_training )\n",
    "        \n",
    "        loss_hist.append(loss_training)\n",
    "        fid_hist.append(fidel)\n",
    "        print(\"Epoch:{} | Loss:{} | Fidelity:{}\".format(epoch, loss_training, fidel))\n",
    "\n",
    "        loss_test = cost(encoder_params, X_tes )\n",
    "        fidel = fidelity(encoder_params, X_tes )\n",
    "        loss_hist_test.append(loss_test)\n",
    "        fid_hist_test.append(fidel)\n",
    "        print(\"Test-Epoch:{} | Loss:{} | Fidelity:{}\".format(epoch, loss_test, fidel))\n",
    "        \n",
    "        b_fidel = fidelity(encoder_params, benign_data )\n",
    "        benign_fid.append(b_fidel)\n",
    "        print(\"benign fid:{}\".format(b_fidel))\n",
    "        \n",
    "        \"\"\"\n",
    "        experiment_parameters={\"autoencoder\":\"e2\",\"params\":encoder_params}\n",
    "        f=open(\"Cancer_encoder_e3-SelectedFeautures/params\"+str(epoch)+\".txt\",\"w\")\n",
    "        f.write(str(experiment_parameters))\n",
    "        f.close()\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rezults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fidelity: 0.8609424846861528\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x for x in range(0,len(loss_hist)*5,5)],np.array(fid_hist),label=\"train fid\")\n",
    "plt.plot([x for x in range(0,len(loss_hist)*5,5)],np.array(fid_hist_test),label=\"test fid\")\n",
    "plt.plot([x for x in range(0,len(loss_hist)*5,5)],np.array(benign_fid),label=\"benign fid\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Malign 2x424->compression fidelity e2\",)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"fid\")\n",
    "\n",
    "print(\"fidelity:\",fid_hist[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.1617147474032532\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAArdUlEQVR4nO3de3xcdZ3/8dfnzEySXtL0FhAoWBDk0gsFChaBX1tZsYCC/vCG3KoosvpT96e/bmFVwMuusGWFRUVErVy34npXQAoIFF0QSilQbKFcpVToBZI2bZPM5fP743wnmaZJmqaZTJLzfj4e88jMOd9zzvd7ZjLv+X7PmTPm7oiISHJFla6AiIhUloJARCThFAQiIgmnIBARSTgFgYhIwikIREQSTkGQAGY20czczNLh8Z1mdl6l6yUDg5n9i5n9qAzrnWtmf+rr9UrfUxAMcGb2kpm1mtn4DtMfD2/uE3d1ne5+srvf2GeVbK/TDDO728zeMLP1ZvbfZrZXL9Zzb4fg2sPMFpnZWjNrNLM/m9k7ulh2YVj2wN1tT1K4+7+5+ycrXY9yMrMrzWy1mW02s1Vmdm6l6zSQKAgGhxeBM4sPzGwKMLxy1enSGOB6YCLwVmAz8JNdWYGZnQVkOkweCTwKHAWMBW4EbjezkR2WPR54Ww+2MdbMOm5jUCiGo+yyLcD7gDrgPOA/zeydla3SAOLuug3gG/AS8BXg0ZJpVwJfBhyYGKadCjwObAJeAS4rKT8xlE2Hx/cDnwz3U8B/ABuIA+f/dFL2G8Cfid/YFwPje1j3I4HN4X4VsBz4XMl2/wxcUlK+DngWmFFahy7WvQk4quRxOrR/alj2wG6W/Qjwemj35G7KpYB/AZ4PbX8M2DfMeydxODWGv+8sWe5+4JvA/wBNwO+AccCtod6PFp+3UN6BzwMvhOdhARCFeXPDfroK2BjWWx1eA38L7bgOGBbKjwd+DzQAbwAPlqxrPvBqaMszwIlh+mXALSX1OQ14OqzjfuDQDq/H/wc8Gdp+G1DTxf6bC/yp5HF3+2xuaP9m4tfhWWH6gcADYZkNwG3dPF8zwj5vAJ4AZnVT9rfAlyr9/z1QbhWvgG47eYLif7x/CP+4h4Y3pzXEn7hLg2AWMIW4lzc1vEG8P8ybSNdBcCHwV2AC8Sf6ezop+zzwdmBYeHx5D+v+T8DDJY8nA2+GdnwZeBhIlcz/HvB/O9a3k/VOA5qBupJp84D/DPe7DYKSuiwA1oY3pc8AYzqUmQc8BRwMGHA48Rv62NCOc4gD6MzweFzJPnuOuHdSF/bvs+F5TAM3AT8p2Y4D94X17hfKFp+fuUAO+FxYdhhxKPw2lK8lDppvhfLfIg6GTLidEOp+MPEHhL1LXhNvC/cvIwRBeJ63AO8Oy/9zaEtVyevxEWDvsP2VwIVd7OO5hCDobp8BI4gD8uBQdi9gUri/KLxWIqAGOL6Lbe1DHJSnhLLvDo/rOyk7DPg7MKfS/98D5VbxCui2kyeoPQi+Ev7J5wB3h3+mtiDoZLmrgavC/Yl0HQR/BD5dstw/dFL2KyXzPwP8oQf1nkr8ifSEDtO/RBxqbwIHlUyfTtxjSHesb4flRxG/OV9cMm3f8GZVFx7vNAhKlk0R96Z+RvxJ8qfAqDDvGeD0TpY5B3ikw7SHgLkl++zLJfP+A7iz5PH7gOUlj730TSns43vD/bnA30rmGfEb9dtKph0LvBjufx34Tcf2E3+yXhee30yHeZfRHgRfBX5WMi8i7kXMKnk9nl0y/9+B67rYt3NpD4Iu9xlxEDQAZxB6NiVlbiIebpywk+dxPnBzh2l3Aed1UvZG4A+A9fX/62C96RjB4HEz8DHif5ybOs40s3eY2X3hIG0j8Sf98R3LdWJv4k+KRa90Uua1kvtbicfsuxQO1N4JfMHdH+ww+0bi3swd7r46lI+Aa0P5XDfrHUb86fdhd/9Wyayrga+7e2Mny5xlZk3hdmfH+e6eJw6WJ4iDazLtxyj2Je4NdbQ38HKHaS8Tfyoter3k/rZOHnfch6X7/eWwjc7m1RMfH3rMzBrMrIH4Ta0+zF9AHIqLzewFM7sotPM54h7aZcA6M/upmZVuo9O2uXshbL+0bbv0euhsvcHLwD7uvoV4uO5C4O9mdruZHRLK/DNx+D1iZk+b2Se6WP9bgQ8V90nYL8cT9y7amNkC4uf4wx5SQXSweNBw95eJx05PAX7ZSZH/Ih4u2Nfd64iHB6wHq/478bBQ0b67U08zeyvx8NI33P3mTopcSzyG/Z5wcBfiT/nTgdvM7DXioRqANWZ2QlhvNfBr4mGxT3dY54nAAjN7LSwP8JCZfczdb3X3keF2ckk9R4bTG/8ILCN+o/uIu092942h2Ct0fvB5LfEbT6n9iD8591bpft8vbKOo9A1rA3GQTHL30eFW5+4jAdx9s7t/yd0PIB7r/6KZnRjm/Ze7H0/7sOIVO2ubmVmo2+60bYf1Bm37zN3vcvd3E79xrwJ+GKa/5u6fcve9iZ/3a7s4I+wV4h7B6JLbCHe/vKQtXwNOBk5y90272Z4hRUEwuJwPvCt8guqoFnjD3ZvN7Bji3kNP/Az4gpntY2ajibvYvWJm+xAPNX3X3a/rZP45xGf+zCU+OHpjOPOnkfgT47RwOyUschTwl3CGz8+J3wDPC59SS72dePy+uDzEwy+/6qKec4jfmD4C/ID4U+ln3P3RDkV/BHzDzA6y2FQzGwfcAbzdzD5mZmkz+whwGHHA9dY8MxtjZvsCXyA+CLuD0PYfAleZ2R6hPfuY2XvC/fea2YHhDbwRyAMFMzvYzN4VArWZeF923I8Qvx5ONbMTw37/EtBCfBB2d3S5z8xsTzM73cxGhG01FetmZh8ys+IHlTeJA6yzet8CvM/M3mNmKTOrMbNZxWXN7GLi/4l/KAl6CRQEg4i7P+/uS7uY/Rng62a2GbiE+B+6J35IfCbQk8Rn3dxBfHAy34sqfhI4ALisZDimCcDM9iMewjnX3Zvc/b+ApcTHMTx88nvN3V8D1of1ve7urcRnm7wXOAloKFn3CQDuvq7D8gAb3H1bF/V8BjjE4+9T3ObuLV2U+zbxflxMfDDzx8Rj2BtDfb5EfEDyn4H3uvuGXuyzot8Qn5W0HLg9bKsr84mHfx42s03EPbCDw7yDwuMm4jH4a939PuIzjS4n7lG8BuwBXNxxxe7+DHA28J1Q9n3A+8Lz0Gs72WcR8EXicH4DmAn8Y1j0aOIPA03EPd4vuPsLnaz/FeB04rO81hP3EObR/h73b8Q9kOdKXj//sjttGkpMw2RSysxOJj7417EbL2ViZk584Py5StdFkkk9goQzs2Fmdkroru8DXEoXQyoiMjQpCMSArxGPvz5OfF74JRWtkYj0Kw0NiYgknHoEIiIJN+guYDV+/HifOHFipashIjKoPPbYYxvcvb6zeYMuCCZOnMjSpV2dQSkiIp0xs47f7G6joSERkYRTEIiIJJyCQEQk4QbdMQIRGbqy2Sxr1qyhubm50lUZtGpqapgwYQKZTM9/hE9BICIDxpo1a6itrWXixInE182TXeHubNy4kTVr1rD//vv3eDkNDYnIgNHc3My4ceMUAr1kZowbN26Xe1RlCwIzW2hm68xsRRfz55nZ8nBbYWZ5MxtbrvqIyOCgENg9vdl/5ewR3ED8s4qdcvcF7j7N3acRXw73AXd/o2y1ef2v8MdvwpbduVKwiMjQU7YgcPclxNcW74kziX+kumz+9uxyWLKAjes6+yVGERFoaGjg2muv7dWyp5xyCg0NDT0uf9lll3HllVf2alt9reLHCMxsOHHP4RfdlLnAzJaa2dL169d3Vaxb67bGF9fb3NTVb5WISNJ1FwS5XJc/pw3AHXfcwejRo8tQq/KreBAQ/wLSn7sbFnL36919urtPr6/v9FIZOxWlqwDIZbv6MSoRSbqLLrqI559/nmnTpjFv3jzuv/9+TjjhBE477TQOO+wwAN7//vdz1FFHMWnSJK6//vq2ZSdOnMiGDRt46aWXOPTQQ/nUpz7FpEmTOOmkk9i2rfsPoMuXL2fGjBlMnTqVD3zgA7z55psAXHPNNRx22GFMnTqVj370owA88MADTJs2jWnTpnHEEUewefPm3W73QDh99KOUeVgIIJWpBiCf1fnJIoPB1373NH9d27e/MX/Y3qO49H2Tupx/+eWXs2LFCpYvXw7A/fffz7Jly1ixYkXb6ZgLFy5k7NixbNu2jaOPPpozzjiDcePGbbee1atXs2jRIn74wx/y4Q9/mF/84hecffbZXW733HPP5Tvf+Q4zZ87kkksu4Wtf+xpXX301l19+OS+++CLV1dVtw05XXnkl3/ve9zjuuONoamqipqZm93YKFe4RmFkd8e+T/qbc24oycY+goB6BiOyCY445Zrtz8q+55hoOP/xwZsyYwSuvvMLq1at3WGb//fdn2rRpABx11FG89NJLXa6/sbGRhoYGZs6cCcB5553HkiVLAJg6dSpnnXUWt9xyC+l0/Ln9uOOO44tf/CLXXHMNDQ0NbdN3R9l6BGa2CJgFjDezNcQ/gZgBcPfrQrEPAIvdfUu56lHU3iPYrd/gFpF+0t0n9/40YsSItvv3338/99xzDw899BDDhw9n1qxZnZ6zX11d3XY/lUrtdGioK7fffjtLlizhd7/7Hf/6r//KU089xUUXXcSpp57KHXfcwXHHHcddd93FIYcc0qv1F5UtCNz9zB6UuYH4NNOyS6XjJ6aQU49ARDpXW1vb7Zh7Y2MjY8aMYfjw4axatYqHH354t7dZV1fHmDFjePDBBznhhBO4+eabmTlzJoVCgVdeeYXZs2dz/PHH89Of/pSmpiY2btzIlClTmDJlCo8++iirVq0auEEw0KSrFAQi0r1x48Zx3HHHMXnyZE4++WROPfXU7ebPmTOH6667jkMPPZSDDz6YGTNm9Ml2b7zxRi688EK2bt3KAQccwE9+8hPy+Txnn302jY2NuDuf//znGT16NF/96le57777iKKISZMmcfLJJ+/29gfdbxZPnz7de/PDNC+tXsHEW49j2VHf4sj3faYMNROR3bVy5UoOPfTQSldj0OtsP5rZY+4+vbPyA+H00X6RqYqPrBd0jEBEZDuJCYJ0VXzWkOcVBCIipRITBJlMONc2pyAQESmVmCBIh9O5XAeLRUS2k5ggqArHCDQ0JCKyvcQEQSZTRd4N8tlKV0VEZEBJTBCkIiNLGlOPQES6sDuXoQa4+uqr2bp1a6fzZs2aRW9Ofe8PiQkCQEEgIt0qZxAMZMkKAkuDgkBEutDxMtQACxYs4Oijj2bq1KlceumlAGzZsoVTTz2Vww8/nMmTJ3PbbbdxzTXXsHbtWmbPns3s2bO73c6iRYuYMmUKkydPZv78+QDk83nmzp3L5MmTmTJlCldddRXQ+aWo+1piLjEBkCWDFXSMQGRQuPMieO2pvl3nW6bAyZd3ObvjZagXL17M6tWreeSRR3B3TjvtNJYsWcL69evZe++9uf3224H4GkR1dXV8+9vf5r777mP8+PFdbmPt2rXMnz+fxx57jDFjxnDSSSfx61//mn333ZdXX32VFSvin3kvXna6s0tR97VE9QhyCgIR2QWLFy9m8eLFHHHEERx55JGsWrWK1atXM2XKFO6++27mz5/Pgw8+SF1dXY/X+eijjzJr1izq6+tJp9OcddZZLFmyhAMOOIAXXniBz33uc/zhD39g1KhRQOeXou5rieoR5CytIBAZLLr55N5f3J2LL76YT3/60zvMW7ZsGXfccQdf+cpXOPHEE7nkkkt2a1tjxozhiSee4K677uK6667jZz/7GQsXLuz0UtR9HQiJ6hHkLU2kYwQi0oWOl6F+z3vew8KFC2lqagLg1VdfZd26daxdu5bhw4dz9tlnM2/ePJYtW9bp8p055phjeOCBB9iwYQP5fJ5FixYxc+ZMNmzYQKFQ4IwzzuCb3/wmy5Yt2+5S1FdccQWNjY1tdelLCesRZIjUIxCRLnS8DPWCBQtYuXIlxx57LAAjR47klltu4bnnnmPevHlEUUQmk+H73/8+ABdccAFz5sxh77335r777ut0G3vttReXX345s2fPxt059dRTOf3003niiSf4+Mc/TqFQAOBb3/pWl5ei7muJuQw1wMpvziCfHsbkizp/gkSksnQZ6r6hy1B3I28ZUuoRiIhsJ1lBEGVIuY4RiIiUSlQQFCxDynOVroaIdGOwDVcPNL3Zf8kKgkhDQyIDWU1NDRs3blQY9JK7s3HjRmpqanZpuUSdNVSIMqRRj0BkoJowYQJr1qxh/fr1la7KoFVTU8OECRN2aZnEBUHK1SMQGagymQz7779/pauROIkaGvJUFRkFgYjIdpIVBBoaEhHZQbKCIFVFRkEgIrKdZAVBlCGj00dFRLZTtiAws4Vmts7MVnRTZpaZLTezp83sgXLVpW176SqqLAc6NU1EpE05ewQ3AHO6mmlmo4FrgdPcfRLwoTLWBYiHhgAKOX27WESkqGxB4O5LgDe6KfIx4Jfu/rdQfl256lJkIQhaW5vLvSkRkUGjkscI3g6MMbP7zewxMzu37FsMQZBtbSn7pkREBotKfqEsDRwFnAgMAx4ys4fd/dmOBc3sAuACgP3226/XG7R0HAQ5BYGISJtK9gjWAHe5+xZ33wAsAQ7vrKC7X+/u0919en19fa83aKlqAHJZDQ2JiBRVMgh+AxxvZmkzGw68A1hZzg1aOgOoRyAiUqpsQ0NmtgiYBYw3szXApUAGwN2vc/eVZvYH4EmgAPzI3bs81bQvRJm4R6BjBCIi7coWBO5+Zg/KLAAWlKsOHUXpOAjyOQWBiEhRor5ZHIWDxXmdPioi0iZZQRCGhvJZ9QhERIqSFQTFHkFW3ywWESlKVBCkq4o9AgWBiEhRooIgFYaGCjpYLCLSJplBoGMEIiJtEhUE6bYegYaGRESKEhUEmaoaADyvIBARKUpUELT1CHSwWESkTbKCIJw1RF7HCEREihIVBJm2IFCPQESkKGFBEI4R6GCxiEibZAVBpoqCmw4Wi4iUSFQQpFIRWdJYPlvpqoiIDBiJCgIgBIF6BCIiRckLAkvrYLGISInkBQEZrKChIRGRosQFQU5DQyIi20leEFiaqKAgEBEpSlwQ5C1DVMhVuhoiIgNG4oIgZ2lMPQIRkTaJC4K8ZUi5DhaLiBQlMgg0NCQi0i55QRBlSLmGhkREihIXBAXLkNL3CERE2iQuCPJRFSnX0JCISFHigsCjDGkUBCIiRYkLgkKUIa1jBCIibcoWBGa20MzWmdmKLubPMrNGM1sebpeUqy6lPMqQ1tCQiEibdBnXfQPwXeCmbso86O7vLWMdduCpDBkNDYmItClbj8DdlwBvlGv9veWpKh0jEBEpUeljBMea2RNmdqeZTeqqkJldYGZLzWzp+vXrd2uDnqoio6EhEZE2lQyCZcBb3f1w4DvAr7sq6O7Xu/t0d59eX1+/e1uNMlRbFtx3bz0iIkNExYLA3Te5e1O4fweQMbPxZd9wqgqAfE5fKhMRgQoGgZm9xcws3D8m1GVj2TecrgYg29pc9k2JiAwGZTtryMwWAbOA8Wa2BrgUyAC4+3XAB4F/NLMcsA34qHv5x2ss9Ahasy3UlHtjIiKDQNmCwN3P3Mn87xKfXtqvLB0HQa5lW39vWkRkQKr0WUP9ri0IWvXtYhERSGIQFA8WZ1sqXBMRkYEheUGQCccIWhUEIiKQwCCIUvFZQ+oRiIjEEhcEqUxxaEinj4qIQAKDIMqoRyAiUip5QZBWEIiIlEpcEKSq4qGhgi4xISICJDAI0un4+8QFHSMQEQESGATFHkE+py+UiYhAAoMgHQ4We07HCEREIIlBUFUcGlKPQEQEEhgEmRAEntfBYhER6GEQmNkXzGyUxX5sZsvM7KRyV64c2oeGdLBYRAR63iP4hLtvAk4CxgDnAJeXrVZllA4Hi9HpoyIiQM+DwMLfU4Cb3f3pkmmDSvvQkI4RiIhAz4PgMTNbTBwEd5lZLVAoX7XKpyoMDaEgEBEBev4LZecD04AX3H2rmY0FPl62WpVRlIpo9bSCQEQk6GmP4FjgGXdvMLOzga8AjeWrVnllSWMKAhERoOdB8H1gq5kdDnwJeB64qWy1KrOspbGCDhaLiEDPgyDn7g6cDnzX3b8H1JavWuWVJaOhIRGRoKfHCDab2cXEp42eYGYRkClftcorh3oEIiJFPe0RfARoIf4+wWvABGBB2WpVZjnLEKlHICIC9DAIwpv/rUCdmb0XaHb3QXuMIGdpIvUIRESAnl9i4sPAI8CHgA8DfzGzD5azYuWUt4yCQEQk6Okxgi8DR7v7OgAzqwfuAX5eroqVU84yRK4gEBGBnh8jiIohEGzchWUHnIKlSalHICIC9PzN/A9mdpeZzTWzucDtwB3dLWBmC81snZmt2Em5o80s159DTfkoQ0o9AhERoOcHi+cB1wNTw+16d5+/k8VuAOZ0V8DMUsAVwOKe1KOvFCINDYmIFPX0GAHu/gvgF7tQfomZTdxJsc+FdR7d0/X2hbxVkS7k+nOTIiIDVrdBYGabAe9sFuDuPqq3GzazfYAPALPZSRCY2QXABQD77bdfbzfZphBlSKEegYgI7CQI3L2cl5G4Gpjv7gWz7n/awN2vJx6aYvr06Z0F0y7xVIaMhoZERIBdGBoqg+nAT0MIjAdOMbOcu/+63Bv2KEPKNTQkIgIVDAJ3379438xuAH7fHyEAcRBkUBCIiEAZg8DMFgGzgPFmtga4lHChOne/rlzb7YlCqpq0jhGIiABlDAJ3P3MXys4tVz06lcpQpaEhERFgEH87eLdEVfHQkO/2cWcRkUEvmUGQqiIyJ59Xr0BEJJFB4OkqALKtzRWuiYhI5SUyCCwVB0Fra0uFayIiUnmJDIKo2CNo2VbhmoiIVF4ig4AQBLmsegQiIokMgigMDeVb9bvFIiKJDALLVAOQ1TECEZFkBkHxGEFOZw2JiCQ7CPI59QhERBIZBKkwNJTPqkcgIpLIIMiMGA1AtqmhovUQERkIEhkEI0fvAUDr5vUVromISOUlMghqx74FgHzTxgrXRESk8pIZBKPGkPUUvu2NSldFRKTiEhkEUSqi0WqJFAQiIskMAoCmqJZMS0OlqyEiUnGJDYKtqTqqsg2VroaISMUlNghaqkYzItdY6WqIiFRcYoMgWzWakYVNla6GiEjFJTYICsPGMso344VCpasiIlJRiQ0Cho+jyvI0bW6odE1ERCoqsUGQGjEWgE0b11W4JiIilZXYIKiqrQegqUFBICLJltggqKmLg6C5UUEgIsmW2CAYMToOgtbNGypcExGRykpsEIxqu/CcgkBEkq1sQWBmC81snZmt6GL+6Wb2pJktN7OlZnZ8uerSmZF14yi44Vt0vSERSbZy9ghuAOZ0M/9e4HB3nwZ8AvhRGeuygyidZpONwJoVBCKSbGULAndfAnT5LuvuTe7u4eEIwLsqWy6bozoyLW/292ZFRAaUih4jMLMPmNkq4HbiXkFX5S4Iw0dL16/vu18V25oaRVVrQ5+tT0RkMKpoELj7r9z9EOD9wDe6KXe9u0939+n19fV9tv3mTB3DcrrekIgk24A4aygMIx1gZuP7c7vZ6jHUFnQFUhFJtooFgZkdaGYW7h8JVAP9+iPC+eox8YXnvN8PT4iIDBjpcq3YzBYBs4DxZrYGuBTIALj7dcAZwLlmlgW2AR/x/n5HHj6OYdbK5qZN1NbW9eumRUQGirIFgbufuZP5VwBXlGv7PZEaMQ6AzW+sUxCISGINiGMElZKpDUHwpq43JCLJleggqKnbA4BtjX13SqqIyGCT6CAYMToOgtbNCgIRSa5EB0HtmPg7CbnN/XqykojIgJLwINgTAN+q6w2JSHIlOgiiTBWbGY5tU49ARJIr0UEAsNlGkW5pqHQ1REQqJvFBsDU9iupWXYFURJIr8UGwLV3HsJyuNyQiyZX4IMhWjWFEXlcgFZHkSnwQ5IeNoU4XnhORBEt8EDBsLCNtG1u2bat0TUREKiLxQRCFC881btT1hkQkmRIfBJna+Ldwmt58vcI1ERGpjMQHQc2oOAi2NqpHICLJlPggGLfHPgBsev2VCtdERKQyEh8EY/c7jBwpcq89XemqiIhUROKDwDI1rM3sx6iGlZWuiohIRSQ+CAA21R3CvtkXaMnlK10VEZF+pyAAbK+pvMXe5IWXXqp0VURE+p2CABj3tqMAeP3ZRytcExGR/qcgAPY4cDoALWueqHBNRET6n4IAiEaOY0M0nmEb/1rpqoiI9DsFQbCx9mD2bn6OfEEXnxORZFEQBIU9JjORtbz02oZKV0VEpF8pCILaiUeStgJrnllW6aqIiPQrBUGw59uPBqDp5ccrXBMRkf5VtiAws4Vmts7MVnQx/ywze9LMnjKz/zGzw8tVl57IjNufrTaMzPpOqysiMmSVs0dwAzCnm/kvAjPdfQrwDeD6MtZl56KI14cdRP2WZ/VrZSKSKGULAndfArzRzfz/cfc3w8OHgQnlqktPtYw/jIP8ZdY2bK10VURE+s1AOUZwPnBnpSsxbN9pjLRmnntGw0MikhwVDwIzm00cBPO7KXOBmS01s6Xr168vW132Ojg+YLzqsQfKtg0RkYGmokFgZlOBHwGnu/vGrsq5+/XuPt3dp9fX15etPlX7HM6WzDgOeu12nlvXVLbtiIgMJBULAjPbD/glcI67P1upemwnlYGjP8G7Usv59b1LKl0bEZF+Uc7TRxcBDwEHm9kaMzvfzC40swtDkUuAccC1ZrbczJaWqy67YsSxnyJnaepX3siGppZKV0dEpOzS5Vqxu5+5k/mfBD5Zru33Wu2ebDvoNP73M3dy04NP89mTj6x0jUREyqriB4sHotqZ/4da20bTIzezrVW/WiYiQ5uCoDP7HMXm8Ufwofwd/MddK/UFMxEZ0hQEXRj5vz7LAdFrrH3oNub9/Emy+UKlqyQiUhYKgi7YpPfje07impofsOHx33P+jUtp3JqtdLVERPqcgqArqQx27u9I73EwP67+NiOev5Oj/+0ePn3zUn73xFrWbWrWkJGIDAk22N7Mpk+f7kuX9uOZptsa4JYz8LWP8+Ce5/DvG97JiqaRAFSnIyaMGUZ9bTW1NRlqa9KMqEpTnY6ozkRUp1NkUhGZlJFJRVSnI6qKt1T8tzqdojoTP67JRFSlUmF6xLCqFNXpCDPrv/aKyJBkZo+5+/RO5ykIeqBlM/zqQlj1e9wiGvaZzaraY3m+8BZWNNfzYnMtjS15Njfn2NqaoyVXoDmbpy9+9dIMhmVS1GRS1KQjaqpSDMukGF4VTxseHg+rSodyUXgc34rzqzMpakLotP3NxEFT/JuOTKEjMkR1FwRl+x7BkFJdCx+9Fd54EVt2E2Mev4Vj19zLscX5FsGwsTByLNTUQWY4VI2gkKrGozR5y1CwFHmMPCnypMhZhqxlyBLfWq2KVtK0eppWMrR4iuZCRHM+YmsuxRZPsSWfYUs+xZZcik25FI1bU/y9MWJT1mjKQnM2DqBcLxPIjLaeSrEnk47aezTptmlGOhUHRyrc0m1/I8wgMiMKfwl/i2Uyqe3LmFnbYyP8DdOjkulWUtYoLhvfL+aXhbLAduu20MDietraHEoXyxTXV1yJhXW2l99xn3WsQ/s863SZnjwPxfV1XLb0mW1vi21Xwr29XFQy390pODhOyowoMiKztiHOjq+a0ueidJ3bb7vz+sfb27FNPVbS9uJ+dPdO61haplR37eruOd1hPR3WV9xecR8UvH1e6fSOn7F39hmrs/3j4fks1mPfMcM4oH7kTmq869Qj6I1CATavhY3PwYbV0PQ6bN0Y35o3QXYrtG6FXDMUspDPQiEHhXz733wL5Fv7rk4WQaoKUlV4lMbT1RRSw8inaihEVeSiKvKWIRdlyJGJg4g0OdK0kqLV02SJb62eIu+QL0AOI+vx/BZP0xLKNhfSYZmIVk+R84icQ64AOSJyniLrhnkh3PLk3MgWjJaCkfU0LcTryRH/17h723+Pe4GCW6hjijxRyT+04RiF8LftHzU8zhOR7+Twl4d/tAgnTZ6IAgUisqTwTg+Xla69dB3qNUllXDjzbVx08iG9WlY9gr4WRVA3Ib4dMKv363GPwyAXQiHXHP62hqDIhSAJ03LN4dbS/jffEgdNcR2FHJZrwfItRNltpLPb2uflWyG3JS6fbwnbKb2Fbe3wGaoMiu+lqfJvqifcihWJw6hjALSVw/BUNaSrcYuwQh68EN8oxMu641EElsItor2xHsrHX1L0VBWeqsajDFbIYYVWrJDDLYVHaYjSbbUwgEIWy2exQhYswqMqPJUJ2yBsO48Vslj4kOGpqricRXGbPI5Pb18reB4rBnCUCcu0vzW4e1uY44W4XVEaN8MKYXueb6t3vGyoU9tH43gfxeVzcRsAolT7vjdrD1ovYBTCc5PGoxQQf7CI61toez52UNznZnHZQh7zXIfnMYrLmbU956XLu0VxvaJ03K7i/gMoFDDPYYVc+/6wqG05LP7QEhWycVs9F7ZXWs5Ce+J9Gren/aO/R6n4uYjSoT2xlqqPAb0Lgu4oCCrJDNLxm8qAUsiHfwwPvZhse9gUsiVBld0+PIpviIV8e+/HIohS4cXs7fPagqklvIkS/imt/a8XwrZzbW+eQNiOt29zu+mFuMfmeToOmbQtE6VDnVKhh5Zre+Ns237pm8l2b+Rx0JJriddl8T942zLhn9Y8H+rR4fsnxX1hVrIfWyHKxD26KB3XvdiLLBV6fKTS8XqLy5e+iUXp+PWUysSPi2FfyJU8D+HND+Jli/sC3/5DQen+a6t31P4cez7sy3DzQqh3tuT58fblzOL1RJn2+hXXU1oeD/u0w2vGC2H5MK+t3b7dc4SXPtfxm3nbc1Rsc/G1U8h3eN1R0r5CvN/y2fb9RXieU5mSepS85oqvQffwXIVy25Upvm5DO6OS10+xfl4oeR7an99h9eX5/S4FgewoKvmYnsoANRWrioiUn75HICKScAoCEZGEUxCIiCScgkBEJOEUBCIiCacgEBFJOAWBiEjCKQhERBJu0F1ryMzWAy/3cvHxwIY+rM5gkcR2J7HNkMx2J7HNsOvtfqu713c2Y9AFwe4ws6VdXXRpKEtiu5PYZkhmu5PYZujbdmtoSEQk4RQEIiIJl7QguL7SFaiQJLY7iW2GZLY7iW2GPmx3oo4RiIjIjpLWIxARkQ4UBCIiCZeYIDCzOWb2jJk9Z2YXVbo+fcnMFprZOjNbUTJtrJndbWarw98xYbqZ2TVhPzxpZkdWrua9Z2b7mtl9ZvZXM3vazL4Qpg/ZdptZjZk9YmZPhDZ/LUzf38z+Etp2m5lVhenV4fFzYf7EijZgN5hZysweN7Pfh8dJaPNLZvaUmS03s6VhWlle34kIAjNLAd8DTgYOA840s8MqW6s+dQMwp8O0i4B73f0g4N7wGOJ9cFC4XQB8v5/q2NdywJfc/TBgBvDZ8JwO5Xa3AO9y98OBacAcM5sBXAFc5e4HAm8C54fy5wNvhulXhXKD1ReAlSWPk9BmgNnuPq3k+wLleX27+5C/AccCd5U8vhi4uNL16uM2TgRWlDx+Btgr3N8LeCbc/wFwZmflBvMN+A3w7qS0GxgOLAPeQfzt0nSY3vZaB+4Cjg3306GcVbruvWjrhPCm9y7g98Q/UDyk2xzq/xIwvsO0sry+E9EjAPYBXil5vCZMG8r2dPe/h/uvAXuG+0NuX4Tu/xHAXxji7Q5DJMuBdcDdwPNAg7sXf+m+tF1tbQ7zG4Fx/VrhvnE18M9AITwex9BvM8S/Wr/YzB4zswvCtLK8vvXj9Qng7m5mQ/I8YTMbCfwC+Cd332RmbfOGYrvdPQ9MM7PRwK+AQypbo/Iys/cC69z9MTObVeHq9Lfj3f1VM9sDuNvMVpXO7MvXd1J6BK8C+5Y8nhCmDWWvm9leAOHvujB9yOwLM8sQh8Ct7v7LMHnItxvA3RuA+4iHRUabWfFDXWm72toc5tcBG/u3prvtOOA0M3sJ+Cnx8NB/MrTbDIC7vxr+riMO/WMo0+s7KUHwKHBQONOgCvgo8NsK16ncfgucF+6fRzyGXpx+bjjLYAbQWNLVHDQs/uj/Y2Clu3+7ZNaQbbeZ1YeeAGY2jPiYyEriQPhgKNaxzcV98UHgjx4GkAcLd7/Y3Se4+0Ti/9s/uvtZDOE2A5jZCDOrLd4HTgJWUK7Xd6UPiPTjgZdTgGeJx1S/XOn69HHbFgF/B7LEY4PnE4+L3gusBu4BxoayRnwG1fPAU8D0Ste/l20+nngM9UlgebidMpTbDUwFHg9tXgFcEqYfADwCPAf8N1AdpteEx8+F+QdUug272f5ZwO+T0ObQvifC7enie1a5Xt+6xISISMIlZWhIRES6oCAQEUk4BYGISMIpCEREEk5BICKScAoCkX5kZrOKV9AUGSgUBCIiCacgEOmEmZ0drv2/3Mx+EC721mRmV4XfArjXzOpD2Wlm9nC4DvyvSq4Rf6CZ3RN+P2CZmb0trH6kmf3czFaZ2a1WeoEkkQpQEIh0YGaHAh8BjnP3aUAeOAsYASx190nAA8ClYZGbgPnuPpX4W53F6bcC3/P49wPeSfztb4ivlPpPxL+NcQDx9XREKkZXHxXZ0YnAUcCj4cP6MOKLexWA20KZW4BfmlkdMNrdHwjTbwT+O1wnZh93/xWAuzcDhPU94u5rwuPlxL8l8aeyt0qkCwoCkR0ZcKO7X7zdRLOvdijX2+uztJTcz6P/Q6kwDQ2J7Ohe4IPhOvDF34l9K/H/S/GKlx8D/uTujcCbZnZCmH4O8IC7bwbWmNn7wzqqzWx4fzZCpKf0SUSkA3f/q5l9hfjXoSLiq7p+FtgCHBPmrSM+jgDx5YCvC2/0LwAfD9PPAX5gZl8P6/hQPzZDpMd09VGRHjKzJncfWel6iPQ1DQ2JiCScegQiIgmnHoGISMIpCEREEk5BICKScAoCEZGEUxCIiCTc/we322ZZrTRrKAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x for x in range(0,len(loss_hist)*5,5)],np.array(loss_hist),label=\"train loss\")\n",
    "plt.plot([x for x in range(0,len(loss_hist)*5,5)],np.array(loss_hist_test),label=\"test loss\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Malign 2x424->compression loss e2\",)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "print(\"loss:\",loss_hist[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benign performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign results:\n",
      "fidelity= 0.7983760321522455\n",
      "loss= 1.2550159677852606\n"
     ]
    }
   ],
   "source": [
    "np_benign = benign.to_numpy()\n",
    "benign_data = [ torch.tensor([np_benign[i]]) for i in range(len(benign.to_numpy()))]\n",
    "\n",
    "loss = cost(encoder_params, benign_data )\n",
    "fidel = fidelity(encoder_params, benign_data )\n",
    "\n",
    "print(\"Benign results:\")\n",
    "print(\"fidelity=\",fidel)\n",
    "print(\"loss=\",loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifyer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6833258225888227\n",
      "0.8617865939720931\n"
     ]
    }
   ],
   "source": [
    "beningn_flist=[]\n",
    "for b in benign_data:\n",
    "    f=fidelity(encoder_params, [b])\n",
    "    beningn_flist.append(f.item())\n",
    "    \n",
    "print(min(beningn_flist))\n",
    "print(max(beningn_flist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8226940476819373\n",
      "0.886700458890945\n"
     ]
    }
   ],
   "source": [
    "malign_flist=[]\n",
    "for b in training_data:\n",
    "    f=fidelity(encoder_params, [b])\n",
    "    malign_flist.append(f.item())\n",
    "    \n",
    "print(min(malign_flist))\n",
    "print(max(malign_flist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7295445725582378,\n",
       " 0.7496433166313937,\n",
       " 0.8340177692980565,\n",
       " 0.7839552440922116,\n",
       " 0.8221575452352788,\n",
       " 0.834704207912059,\n",
       " 0.8263469711356692,\n",
       " 0.824996520127753,\n",
       " 0.8267103525269436,\n",
       " 0.7804025511752479,\n",
       " 0.8469947864137036,\n",
       " 0.7738023700280366,\n",
       " 0.7666928882860106,\n",
       " 0.8318511963196791,\n",
       " 0.8044857824194797,\n",
       " 0.8008099919096234,\n",
       " 0.8272276418585979,\n",
       " 0.8066255650894607,\n",
       " 0.860900862406528,\n",
       " 0.7975665358181376,\n",
       " 0.8080727789805457,\n",
       " 0.8012836501041314,\n",
       " 0.797216944488812,\n",
       " 0.7809007302360536,\n",
       " 0.8428611478903449,\n",
       " 0.7959778543522438,\n",
       " 0.7938730764899102,\n",
       " 0.8086916383027783,\n",
       " 0.7629460153894557,\n",
       " 0.8019146477185065,\n",
       " 0.7941785784009149,\n",
       " 0.8617865939720931,\n",
       " 0.6839613402757123,\n",
       " 0.8134894019784032,\n",
       " 0.8054456110012499,\n",
       " 0.8122724098804732,\n",
       " 0.8033130767534562,\n",
       " 0.6959820479492101,\n",
       " 0.817180773781955,\n",
       " 0.8360220561312005,\n",
       " 0.8451161589424392,\n",
       " 0.8025490225542636,\n",
       " 0.8479510528313631,\n",
       " 0.8030797375011046,\n",
       " 0.8344533356768684,\n",
       " 0.8202555077128431,\n",
       " 0.8426437123188166,\n",
       " 0.8046781134340404,\n",
       " 0.8007748736047389,\n",
       " 0.8107713988291427,\n",
       " 0.7778792897250107,\n",
       " 0.7015457764044507,\n",
       " 0.7318328303550791,\n",
       " 0.7878714832040997,\n",
       " 0.8080387169488464,\n",
       " 0.8130779447283383,\n",
       " 0.7525753901558324,\n",
       " 0.7769557392160503,\n",
       " 0.8593671988080455,\n",
       " 0.7643654180844281,\n",
       " 0.796874545947762,\n",
       " 0.8528950312266408,\n",
       " 0.7891264970128463,\n",
       " 0.8098555500624308,\n",
       " 0.7948062603336454,\n",
       " 0.8167367759601512,\n",
       " 0.8487120087461422,\n",
       " 0.7028744891056024,\n",
       " 0.734209745256134,\n",
       " 0.8355271508614758,\n",
       " 0.8271861680478583,\n",
       " 0.8232492952698267,\n",
       " 0.7131582389907676,\n",
       " 0.8465139468135865,\n",
       " 0.7793756643794542,\n",
       " 0.7396404672201188,\n",
       " 0.8435119246401535,\n",
       " 0.823426922284927,\n",
       " 0.795093386233896,\n",
       " 0.7655234156913377,\n",
       " 0.827441390007163,\n",
       " 0.7733986748779981,\n",
       " 0.7331882388900566,\n",
       " 0.8243731863549458,\n",
       " 0.8101883110622651,\n",
       " 0.8048738912054905,\n",
       " 0.8343256865965645,\n",
       " 0.7937787869632804,\n",
       " 0.7710021717791861,\n",
       " 0.8348213096854038,\n",
       " 0.7593001871541699,\n",
       " 0.8341168061489096,\n",
       " 0.8251247722899698,\n",
       " 0.8386420060436304,\n",
       " 0.8351100521663913,\n",
       " 0.7062503928590717,\n",
       " 0.770110676839384,\n",
       " 0.8417895573045839,\n",
       " 0.789481443503335,\n",
       " 0.7635976932400717,\n",
       " 0.7683339290448509,\n",
       " 0.7833224140012365,\n",
       " 0.7769798924315203,\n",
       " 0.7796265143599285,\n",
       " 0.8450193026085394,\n",
       " 0.8210861865005754,\n",
       " 0.8299582878635472,\n",
       " 0.7758318447157924,\n",
       " 0.8142714516632443,\n",
       " 0.8027204171131279,\n",
       " 0.8524430641088888,\n",
       " 0.7740491723648325,\n",
       " 0.8250650218242177,\n",
       " 0.7995510811101515,\n",
       " 0.7928889052938618,\n",
       " 0.7902214238048016,\n",
       " 0.8081152065061363,\n",
       " 0.8167616573280219,\n",
       " 0.7994360019750038,\n",
       " 0.7856263309592932,\n",
       " 0.7865036150826019,\n",
       " 0.8102847798925246,\n",
       " 0.8011436191939344,\n",
       " 0.7992550725596369,\n",
       " 0.7670968430921463,\n",
       " 0.7842364572868099,\n",
       " 0.827214329002405,\n",
       " 0.8128277150933249,\n",
       " 0.7844567290534838,\n",
       " 0.8096416263190528,\n",
       " 0.7660305384045434,\n",
       " 0.80404508191927,\n",
       " 0.7799194797344018,\n",
       " 0.7269388726906093,\n",
       " 0.8118699801108271,\n",
       " 0.7415914787002205,\n",
       " 0.7765127688848588,\n",
       " 0.8470463063847299,\n",
       " 0.8406840980620562,\n",
       " 0.7943863203535543,\n",
       " 0.8596700048113467,\n",
       " 0.8232485365391016,\n",
       " 0.7799029664533575,\n",
       " 0.8108969695611842,\n",
       " 0.825302254933194,\n",
       " 0.8174187920273333,\n",
       " 0.7889337846977443,\n",
       " 0.8100095932475209,\n",
       " 0.8016322856420481,\n",
       " 0.8224417921089192,\n",
       " 0.8190032704855208,\n",
       " 0.7617615216159529,\n",
       " 0.8238424655254147,\n",
       " 0.7861055449640063,\n",
       " 0.7921038466489854,\n",
       " 0.7394599831623655,\n",
       " 0.7995366998149751,\n",
       " 0.7807434612257471,\n",
       " 0.7871892186311256,\n",
       " 0.7690307859258555,\n",
       " 0.7981766682867479,\n",
       " 0.7873182807026788,\n",
       " 0.798630290709446,\n",
       " 0.8112422793548139,\n",
       " 0.7678519059765898,\n",
       " 0.8141706761218807,\n",
       " 0.8126246919447977,\n",
       " 0.8001159059162926,\n",
       " 0.7960503044817493,\n",
       " 0.7978105663706407,\n",
       " 0.7988377681528284,\n",
       " 0.7394212083436947,\n",
       " 0.8458823611534256,\n",
       " 0.8027112496972544,\n",
       " 0.7681721548809276,\n",
       " 0.8388306734005843,\n",
       " 0.7987334544782773,\n",
       " 0.7853865188814769,\n",
       " 0.8057001540528248,\n",
       " 0.6833258225888227,\n",
       " 0.7830117187189353,\n",
       " 0.8086078072946317,\n",
       " 0.7772425902842846,\n",
       " 0.753759541540277,\n",
       " 0.7899959289822279,\n",
       " 0.8098456213344749,\n",
       " 0.7612877113885396,\n",
       " 0.7930544230756736,\n",
       " 0.7990541717168637,\n",
       " 0.8040761431274017,\n",
       " 0.8033892845810143,\n",
       " 0.7569946217150448,\n",
       " 0.841295245154409,\n",
       " 0.8435722048353116,\n",
       " 0.8541162596107916]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beningn_flist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAcFklEQVR4nO3de5RU5Znv8e/DRfCCotAapUVwws2WFRx7HJTxiBqEGEddBowIRge1Z0y8e8a7x8tRT+YcJxJXmONqjwbRAHHIeDROnNHEMBEPyNACykW8IGIriQ0aIiqGluf8sd8im6K6u7puXS/8PmvV6l378u6ndlf9atfeu94yd0dEROLTrasLEBGRwijARUQipQAXEYmUAlxEJFIKcBGRSCnARUQipQAXAcxsi5kdWYZ2h5nZMjP7xMyuNLMHzey2duZ3M/tqHu2ONbPm1P2VZja2NFVLLHp0dQFSvczsfOBaYDjwCbAMuMfdF3RlXeXg7vuVqenrgV+7+6gytQ+Au9dlhs3sDuCr7j61nOuUrqc9cMnJzK4FpgP3AocAA4F/As7qwrIws9h2Oo4AVnZ1EbKbcnfddNvpBhwAbAEmtTNPL5KA/yDcpgO9wrSxQDPJ3ueHwAbgbOB04A3gI+DmVFt3APOAn5Ls6b8CfC01fR1wA/Aq8AXJJ8fRwP8Dfg8sB8am5r8IWBvaegeYEsZ/FfgPYDOwEfhpahkn2WvNPP5ZQAvwLnAr0C3V9gLgPuDj0P432thGLwBfAlvD9hwKzATuTs3z92H7fABMy6qjV1jPeuB3wIPA3ultnLWNvg5MAP4IbAvrXA5MApqyarsWeKqrn2u6Ffla7eoCdKu+WwiBVqBHO/PcBSwCDgZqQpj+9zBtbFj+vwE9gUtDGM4G+gB1wOfA4DD/HSFwJob5/2sIxp5h+jqSwzeHA3sDA4BNJG8I3YBx4X4NsC/wB2BYWPZQoC4MzwFuCcv0Bv4q9XjSwTkLeCrUOojkTefiMO2iUOulQHfgshC+1sZ2mg9ckrq/I8DDdv4dcHSoe3ZWHfcDTwMHhVp+DvyP1DbeJcBT2/Px1LReJG+aI1LjlgLf6urnmm7F3XQIRXLpB2x099Z25pkC3OXuH7p7C3AncEFq+jaS4+XbgLlAf+CH7v6Ju68EVgFfS83f5O7zwvw/IAnY0anpD7j7e+7+OTAV+IW7/8Ldt7v788ASkkAH2A4cbWZ7u/uGsL5MTUcAh7n7Vs9xLN/MugPnATeFWtcB/5j12N5194fc/UvgUZI3iUPa2VZtORf4sbuvcPdPSYI3U4cBDcA17v6Ru39CcjjrvM6uxN2/IPl0MzW0XUfyxvRMATVLFVGASy6bgP4dHG8+jOTwQsa7YdyONkLAQbK3DcneJqlx6ROH72UG3H07ySGYw3JNJwnhSWb2+8wN+Cvg0BCE3wb+DthgZv9qZsPDctcDBiwOV21My/G4+pN8Csh+bANS93+bqvWzMFjISdDDsh5Xep01wD5AU+ox/lsYX4hHgfPDG8MFwBMh2CViCnDJZSHJseaz25nnA5IgzRgYxhXq8MyAmXUDarPaS3eb+R7wmLv3Td32dffvA7j7v7v7OJI949eBh8L437r7pe5+GPC3wD/luGRvI3/aU08/tveLeGxt2UDqcYf1pOv4nOTwT+YxHuD5XS2zSxej7r6I5Nj4icD5wGOFly3VQgEuu3D3zSTHr2eY2dlmto+Z9TSzb5jZ/wyzzQFuNbMaM+sf5n+8iNUea2bnhL3+q0neQBa1Me/jwF+b2Xgz625mvcN10bVmdoiZnWVm+4Y2tpAcUsHMJplZbWjjY5Kg25712L8EngDuMbM+ZnYEyQm/Yh5bW54ALjKzo8xsH+D2VB3bSd547jezg0P9A8xsfB7t/g4YFN4I02YBPwK25Tp8JPFRgEtO7v6PJMF1K8kJyPeAy4H/G2a5m+S486vAayRXjtxdxCqfIjn08THJR/xzwvHwXLW9R3I5482p2v6e5PncLdT9AcmJu5NITjQC/AXwspltITk5eJW7r82xiiuAT0muZFlAcnLxkSIeW07u/izJ1TsvAG+Fv2k3hPGLzOwPwC+BYXk0/c/h7yYzeyU1/jGSE6bleDOSLmDu+kEH6Vr64kllmNneJJd1/rm7v9nV9UjxtAcusue4DPhPhffuI7ZvtYlIAcxsHckVOGd3bSVSSjqEIiISKR1CERGJVEUPofTv398HDRpUyVWKiESvqalpo7vv8iWuigb4oEGDWLJkSSVXKSISPTN7N9d4HUIREYmUAlxEJFIKcBGRSHX5deDbtm2jubmZrVu3dnUpVaN3797U1tbSs2fPri5FRKpYlwd4c3Mzffr0YdCgQSQ9Xe7Z3J1NmzbR3NzM4MGDu7ocEaliXX4IZevWrfTr10/hHZgZ/fr10ycSEelQhwFuZo+Y2YdmtiLHtOvMzEN3ogVTeO9M20NE8pHPHvhMkt/u24mZHQ6cRvKDqyIiUmEdHgN399+Y2aAck+4n+Ymqp0pZ0LKNpT10MKp/7w7nWbduHWeccQYrVuzyIaNTlixZwqxZs3jggQeKakdEJB8FHQM3s7OA9919eR7zNpjZEjNb0tLSUsjqolFfX6/wFulKjY1dXUFFdTrAw08/3UzyE1odcvdGd6939/qamkJ/j7X8WltbmTJlCiNGjGDixIl89tlnNDU1cdJJJ3Hssccyfvx4NmzYAMDYsWO54YYbOO644xg6dCgvvvgiAPPnz+eMM84AoKWlhXHjxlFXV8cll1zCEUccwcaNG1m3bh0jRozg0ksvpa6ujtNOO43PP/+8zbpERNpSyB74nwGDgeWhj+Fa4BUz+0opC6u0NWvW8N3vfpfVq1ez//77M2PGDK644grmzZtHU1MT06ZN45Zbbtkxf2trK4sXL2b69Onceeedu7R35513csopp7By5UomTpzI+vV/OlXw5ptv8r3vfY+VK1fSt29ffvazn1XkMYrI7qXT14G7+2vAwZn7IcTr3X1jCeuquMMPP5wxY8YAMHXqVO69915WrFjBuHHjAPjyyy859NBDd8x/zjnnAHDssceybt26XdpbsGABTz75JAATJkzgwAMP3DFt8ODBjBo1qt3lRUQ60mGAm9kcYCzQ38yagdvd/eFyF1Zp2Zfu9enTh7q6OhYuXJhz/l69egHQvXt3WltbO7WuzLKZ5XUIRUQK0eEhFHef7O6HuntPd6/NDm93HxT73jfA+vXrd4T17NmzGT16NC0tLTvGbdu2jZUrV+bd3pgxY3jiiScAeO655/j4449LX7SI7NG6/Kv02fK57K8chg0bxowZM5g2bRpHHXUUV1xxBePHj+fKK69k8+bNtLa2cvXVV1NXV5dXe7fffjuTJ0/mscce4/jjj+crX/kKffr0YcuWLWV+JCKyp6job2LW19d79g86rF69mhEjRlSshkr54osv6N69Oz169GDhwoVcdtllLFu2LO/ld9ftIlJWjY3Q0NDVVZScmTW5e332+KrbA99drF+/nnPPPZft27ez11578dBDD3V1SSKym1GAl8mQIUNYunRpV5chIruxLu+NUERECqMAFxGJlAJcRCRSCnARkUhV30nMUvcmVuZLiubPn899993HM888w9NPP82qVau48cYby7pOERHQHnhJnXnmmQpvkWqxB3QtqwAn+UGH4cOHc9FFFzF06FCmTJnCL3/5S8aMGcOQIUNYvHgxixcv5vjjj+eYY47hhBNOYM2aNbu0M3PmTC6//HIA3n77bUaPHs3IkSO59dZb2W+//YBkj33s2LFMnDiR4cOHM2XKFCr5ZSoR2X0owIO33nqL6667jtdff53XX3+d2bNns2DBAu677z7uvfdehg8fzosvvsjSpUu56667uPnmm9tt76qrruKqq67itddeo7a2dqdpS5cuZfr06axatYq1a9fy0ksvlfOhichuSgEeDB48mJEjR9KtWzfq6uo49dRTMTNGjhzJunXr2Lx5M5MmTeLoo4/mmmuu6bBjq4ULFzJp0iQAzj///J2mHXfccdTW1tKtWzdGjRql7mRFpCAK8CDdxWu3bt123O/WrRutra3cdtttnHzyyaxYsYKf//znbN1a+G93Zncn29nuaEVEQAGet82bNzNgwAAgOdbdkdGjR+/4pZ25c+eWszQR2UNV32WEVdqT2PXXX8+FF17I3XffzTe/+c0O558+fTpTp07lnnvuYcKECRxwwAEVqFJE9iTqTrZMPvvsM/bee2/MjLlz5zJnzhyeeuqpvJffXbeLSFmlu5PdjbqWVXeyFdbU1MTll1+Ou9O3b18eeeSRri5JRHYzCvAyOfHEE1m+fHlXlyEiu7GqOImpL7LsTNtDRPLRYYCb2SNm9qGZrUiN+19m9rqZvWpmT5pZ30IL6N27N5s2bVJoBe7Opk2b6N27a34bVETikc8hlJnAj4BZqXHPAze5e6uZ/QNwE3BDIQXU1tbS3NxMS0tLIYvvlnr37r3LtzdFRLJ1GODu/hszG5Q17rnU3UXAxEIL6NmzJ4MHDy50cRGRPVYpjoFPA55ta6KZNZjZEjNbor1sEZHSKSrAzewWoBX4SVvzuHuju9e7e31NTU0xqxMRkZSCLyM0s4uAM4BTXWcgRUQqrqAAN7MJwPXASe7+WWlLEhGRfORzGeEcYCEwzMyazexikqtS+gDPm9kyM3uwzHWKiEiWfK5CmZxj9MNlqEVERDqhKr6JKSIinacAFxGJlAJcRCRSCnARkUgpwEVEIqUAFxGJlAJcRCRSCnARkUgpwEVEIqUAF5E9T2NjV1dQEgpwEZFIKcBFRCKlABcRiZQCXEQkUgpwEZFIKcBFRCKlABcRiZQCXEQkUgpwEZFIKcBFRCKlABcRiVSHAW5mj5jZh2a2IjXuIDN73szeDH8PLG+ZIiKSLZ898JnAhKxxNwK/cvchwK/CfRERqaAOA9zdfwN8lDX6LODRMPwocHZpyxIRkY4Uegz8EHffEIZ/CxzS1oxm1mBmS8xsSUtLS4GrExEp0m7ShWxa0Scx3d0Bb2d6o7vXu3t9TU1NsasTEZGg0AD/nZkdChD+fli6kkREJB+FBvjTwIVh+ELgqdKUIyIi+crnMsI5wEJgmJk1m9nFwPeBcWb2JvD1cF9ERCqoR0czuPvkNiadWuJaRESkE/RNTBGRSCnARUQipQAXEYmUAlxEJFIKcBGRSCnARUQipQAXEYmUAlxEJFIKcBGRSCnARWT3lelCdjfsShYU4CIi0VKAi4hESgEuIhIpBbiISKQU4CIikVKAi4hESgEuIhIpBbiISKQU4CIikVKAi4hEqqgAN7NrzGylma0wszlm1rtUhYmISPsKDnAzGwBcCdS7+9FAd+C8UhUmIiLtK/YQSg9gbzPrAewDfFB8SSIiko+CA9zd3wfuA9YDG4DN7v5c9nxm1mBmS8xsSUtLS+GVikRi2catO25SAbl6HNxNex/MVswhlAOBs4DBwGHAvmY2NXs+d29093p3r6+pqSm8UhER2Ukxh1C+Drzj7i3uvg34F+CE0pQlIiIdKSbA1wOjzWwfMzPgVGB1acoSEZGOFHMM/GVgHvAK8Fpoa8848CQiUgV6FLOwu98O3F6iWkREpBP0TUwRkUgpwEVEIqUAFxGJlAJcRCRSCnARkUgpwEVEIqUAFxGJlAJcRCRSCnARkUgV9U1MEclPW13LjuqvH7Equ924a1ntgYuIREoBLiISKQW4iEikFOAiIpFSgIuIREoBLiISKQW4iEikFOAiIpFSgIuIREoBLiISKQW4iEikigpwM+trZvPM7HUzW21mx5eqMBERaV+xnVn9EPg3d59oZnsB+5SgJhERyUPBAW5mBwD/BbgIwN3/CPyxNGWJiEhHzN0LW9BsFNAIrAK+BjQBV7n7p1nzNQANAAMHDjz23XffLaZekarXVtexueTqTja9fGZ6rnGl0Jl2M/NWTRe4hXQT29Cw63INDaWpp4zMrMnd67PHF3MMvAfw58D/dvdjgE+BG7NncvdGd6939/qampoiViciImnFBHgz0OzuL4f780gCXUREKqDgAHf33wLvmdmwMOpUksMpIiJSAcVehXIF8JNwBcpa4G+KL0lERPJRVIC7+zJglwPrIiJSfvompohIpBTgIiKRUoCLiERKAS4iEikFuIhIpBTgIiKRUoCLiERKAS4iEikFuIhIpIr9Kr1I1Slld6xd3YVqZ7qm7co2K66QrmQ7Wq6xMYquZdO0By4iEikFuIhIpBTgIiKRUoCLiERKAS4iEikFuIhIpBTgIiKRUoCLiERKAS4iEikFuIhIpIoOcDPrbmZLzeyZUhQkIiL5KcUe+FXA6hK0IyIinVBUgJtZLfBN4P+UphwREclXsXvg04Hrge3FlyIiIp1RcHeyZnYG8KG7N5nZ2HbmawAaAAYOHFjo6mQPUmjXr8WuK991xtjFa1d1Ibts41b6zXqYTd+5uOiufYHydPkaYTeyGcXsgY8BzjSzdcBc4BQzezx7JndvdPd6d6+vqakpYnUiIpJWcIC7+03uXuvug4DzgBfcfWrJKhMRkXbpOnARkUiV5CfV3H0+ML8UbYmISH60By4iEikFuIhIpBTgIiKRUoCLiERKAS4iEikFuIhIpBTgIiKRUoCLiERKAS4iEikF+B5o2catO27VrqM6y/E4Krl9yr2edPv9Zj1c0jbbqrvd6Y2NOwbbrKexcaf5dhquhGLXV8F6FeAiIpFSgIuIREoBLiISKQW4iEikFOAiIpFSgIuIREoBLiISKQW4iEikFOAiIpFSgIuIREoBLiISqYID3MwON7Nfm9kqM1tpZleVsjAREWlfjyKWbQWuc/dXzKwP0GRmz7v7qhLVJiIi7Sh4D9zdN7j7K2H4E2A1MKBUhYmISPuK2QPfwcwGAccAL+eY1gA0AAwcOLDgdaS7phzVv3fB7VTbukolpppzdTPaUc2FPr4YusztrIo+psZGaGjIa3pHdS3buJV+W7btMg6SrmUP36/nzutqbOS9zPw/mJFMz6wzeC+rPeBP83VGR13A5toOHW2bCij6JKaZ7Qf8DLja3f+QPd3dG9293t3ra2pqil2diIgERQW4mfUkCe+fuPu/lKYkERHJRzFXoRjwMLDa3X9QupJERCQfxeyBjwEuAE4xs2XhdnqJ6hIRkQ4UfBLT3RcAVsJaRESkE/RNTBGRSCnARUQipQAXEYmUAlxEJFIKcBGRSCnARUQipQAXEYmUAlxEJFIKcBGRSJWkO9nYFNI1aWeWKUfXrm111Zmr/UJqLWUXrem28u36tDNdpOaat9jly7FMLPrNejgZuPZ7wM6Ptd+WbWzKeuz9Zj3Mpu9c/KcRqW5VM9N2tJm9jhzrzm4rVxexFZPdrWy6y9jMtIaGnedLj8/VVmb+MnQ9qz1wEZFIKcBFRCKlABcRiZQCXEQkUgpwEZFIKcBFRCKlABcRiZQCXEQkUgpwEZFIKcBFRCKlABcRiVRRAW5mE8xsjZm9ZWY3lqooERHpWMEBbmbdgRnAN4CjgMlmdlSpChMRkfYVswd+HPCWu6919z8Cc4GzSlOWiIh0xNy9sAXNJgIT3P2ScP8C4C/d/fKs+RqATD+Kw4A1Ybg/sLGglZdPNdYE1VmXaspfNdZVjTVBddZVDTUd4e412SPL3h+4uzcCjdnjzWyJu9eXe/2dUY01QXXWpZryV411VWNNUJ11VWNNGcUcQnkfODx1vzaMExGRCigmwP8TGGJmg81sL+A84OnSlCUiIh0p+BCKu7ea2eXAvwPdgUfcfWUnmtjlsEoVqMaaoDrrUk35q8a6qrEmqM66qrEmoIiTmCIi0rX0TUwRkUgpwEVEIlWSAM/nK/Vmdq6ZrTKzlWY2O4w72cyWpW5bzezsMG2mmb2Tmjaq1HWZ2f2p9t8ws9+npl1oZm+G24Wp8cea2WuhzQfMzCpRk5mNMrOFYfu9ambfTi1T1LYqcjt9mZr2dGr8YDN7ObT503Ciu1OK2FZle17lUdNAM/u1mS0N/6fTU9NuCsutMbPx+bZZzrrMbJyZNYXndJOZnZJaZn5oM7OtDq5QTYPM7PPUeh9MLVPu119bNU3Jek5tzzx3it1ORXH3om4kJzDfBo4E9gKWA0dlzTMEWAocGO4fnKOdg4CPgH3C/ZnAxHLWlTX/FSQnYjO1rA1/DwzDmdoXA6MBA54FvlGhmoYCQ8LwYcAGoG+x26qYmsL9LW3M9wRwXhh+ELisknWV43mV53O9MfNYSbqYWJcaXg70AgaHdrp39nGWoa5jgMPC8NHA+6ll5gP1XbCtBgEr2mi3rK+/tmrKmmck8HYptlOxt1LsgefzlfpLgRnu/jGAu3+Yo52JwLPu/lkJasq3rrTJwJwwPB543t0/CjU/D0wws0OB/d19kSf/uVnA2ZWoyd3fcPc3w/AHwIfALt/MKkAx2ymnsFd0CjAvjHqUzm2nUtZVyudVPjU5sH8YPgD4IAyfBcx19y/c/R3grdBeKbqkKLgud18ank8AK4G9zaxXJ9df0praUqHXXz41TQ7LdrlSBPgA4L3U/eYwLm0oMNTMXjKzRWY2IUc757HrC/Ce8DHm/gKeVPnUBYCZHUGyV/RCB8sOCMMdtlmGmtLTjiPZg3g7NbrQbVVsTb3NbEn4v54dxvUDfu/urR21Wca6Mkr5vMqnpjuAqWbWDPyC5JNBe8vm/TjLVFfat4BX3P2L1Lgfh8MCt3XycEWxNQ0OhzH+w8xOTLVZ7tdfezVlfJtdn1OFbqeiVOokZg+SwyhjSd69HjKzvpmJ4Z11JMk15Rk3AcOBvyD5GHxDGes7D5jn7l+WcR2dlbOmsK0eA/7G3beH0ZXaVrlqOsKTrxmfD0w3sz8r07o7W1dXPa8mAzPdvRY4HXjMzKrhYoF26zKzOuAfgL9NLTPF3UcCJ4bbBRWqaQMw0N2PAa4FZpvZ/u20U4maADCzvwQ+c/cVqWXKvZ3aVIonVj5fqW8Gnnb3beHj4xskgZ5xLvCku2/LjHD3DZ74AvgxycefUteVkb2X1tay74fhfNosdU2EJ/G/Are4+6LM+CK3VVE1ufv74e9akmOBxwCbgL5mlvmiWCHdLBRVV1Dq51U+NV1Mcvwfd18I9CbpDKm951SxXVIUUxdmVgs8CXzH3Xd8qkv9bz8BZlOhbRUOM20K45tIPmkOpTKvvza3U9Dea6CQ7VScYg+ik+xdryX5CJs5MVCXNc8E4NEw3J/kY0y/1PRFwMlZyxwa/howHfh+qesK8w0H1hG+1BTGHQS8Q3IC88AwfJDnPolyeoVq2gv4FXB1jvkL3lZF1nQg0Cv1f32TcFII+Gd2Pon53Ur9/8r1vMrzuf4scFEYHkFyDNWAOnY+ibmW5KRaXo+zjHX1DfOfk6PN/mG4J8n5jL+rUE01QPcw/kiSkK3I66+tmsL9bqGWI0u1nYq9laaR5KPGGyTvlLeEcXcBZ6ZeLD8AVgGvEV7YYdqgsFG6ZbX5Qph3BfA4sF+p6wr37yDHixiYRnKi6S2SwxWZ8fWhpreBH5EjOMpREzAV2AYsS91GlWJbFVHTCWG9y8Pfi1PTjgwvtrdIwrxXhf9/ZXle5fFcPwp4KWyTZcBpqWVvCcutIXX1RK42y/AazFkXcCvwadbz6mBgX6AJeJXk5OYPCaFagZq+Fda5DHgF+OtKvf46+P+NBRZltVf0dirmpq/Si4hEqhpOroiISAEU4CIikVKAi4hESgEuIhIpBbiISKQU4CIikVKAi4hE6v8D+y/c3J6YIqEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(beningn_flist, bins = 100 ,label=\"benign\", color = \"skyblue\",alpha=0.4)\n",
    "plt.hist(malign_flist, bins =100 ,label=\"malign\",color = \"red\",alpha=0.4)\n",
    "plt.title(\"Compression fidelity\",)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split: 0.845\n",
      "benign classification accuracy: 0.9230769230769231\n",
      "malignification accuracy: 0.9098360655737705\n",
      "total accuracy: 0.9157175398633257\n"
     ]
    }
   ],
   "source": [
    "split=0.845\n",
    "\n",
    "\n",
    "print(\"split:\",split)\n",
    "b_e=[]\n",
    "for i in beningn_flist:\n",
    "    if i<split:\n",
    "        b_e.append(1)\n",
    "    else:\n",
    "        b_e.append(0)\n",
    "ab_ac=sum(b_e)/len(b_e)\n",
    "print(\"benign classification accuracy:\",ab_ac)\n",
    "m_e=[]\n",
    "for i in malign_flist:\n",
    "    if i>split:\n",
    "        m_e.append(1)\n",
    "    else:\n",
    "        m_e.append(0)\n",
    "am_ac=sum(m_e)/len(m_e)\n",
    "print(\"malignification accuracy:\",am_ac)\n",
    "t_ac=(sum(b_e)+sum(m_e))/(len(b_e)+len(m_e))\n",
    "print(\"total accuracy:\",t_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "experiment_parameters={\"autoencoder\":\"e2\",\"params\":encoder_params}\n",
    "f=open(\"Cancer_encoder_e5-SelectedFeautures-ent_params500\"+str(epoch)+\".txt\",\"w\")\n",
    "f.write(str(experiment_parameters))\n",
    "f.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
